{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc3959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda7e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_differenced(periods, df_original, df_differences):\n",
    "    '''\n",
    "    from: https://stackoverflow.com/questions/34918013/undo-a-series-diff\n",
    "    '''\n",
    "    restored = df_original.copy()\n",
    "    restored.iloc[periods:] = np.nan\n",
    "    for d, val in df_differences.iloc[periods:].iterrows():\n",
    "        restored.iloc[d] = restored.iloc[d - periods] + val\n",
    "    return restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca82f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_score_function(actual, predicted, var):\n",
    "    '''\n",
    "    Function that calculates the log scoring function:\n",
    "    \n",
    "    L = 0.5 * sum_j (ln(var_j) + (y - y_hat)^2 / var_j)\n",
    "    \n",
    "    '''\n",
    "    var[var == 0] = np.nan\n",
    "    const = np.log(2 * np.pi)\n",
    "    L = 0.5 * np.nansum(np.log(var) + (actual - predicted)**2 / var + const, axis=1)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b565a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sys_VAR = 100\n",
    "n_data_VAR = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289e6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('../../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime')\n",
    "uk_pv = pd.read_csv('../../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "data_multiple = data.iloc[:, :n_sys_VAR][:n_data_VAR]\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.reset_index().columns)].set_index('ss_id_string')['kwp'].values * 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215266b3",
   "metadata": {},
   "source": [
    "# Do the same for other benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f38004",
   "metadata": {},
   "source": [
    "## Uncertainty Intervals\n",
    "\n",
    "By using a state space formulation, we can perform simulations of future values. The mathematical details are described in Hyndman and Athanasopoulos [2] and in the documentation of HoltWintersResults.simulate.\n",
    "\n",
    "Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles and practice, 2nd edition. OTexts, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37fa96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for persistence\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.00 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.01 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.02 secs\n",
      "persistence calculation time: 0.03 secs\n",
      "persistence calculation time: 0.03 secs\n",
      "Getting results for yesterday\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.00 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.01 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.02 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "yesterday calculation time: 0.03 secs\n",
      "Getting results for hourly_average\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.00 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.01 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.02 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.03 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "hourly_average calculation time: 0.04 secs\n",
      "Getting results for VAR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR calculation time: 0.19 secs\n",
      "VAR calculation time: 0.38 secs\n",
      "VAR calculation time: 0.61 secs\n",
      "VAR calculation time: 0.80 secs\n",
      "VAR calculation time: 0.99 secs\n",
      "VAR calculation time: 1.20 secs\n",
      "VAR calculation time: 1.42 secs\n",
      "VAR calculation time: 1.62 secs\n",
      "VAR calculation time: 1.83 secs\n",
      "VAR calculation time: 2.03 secs\n",
      "VAR calculation time: 2.22 secs\n",
      "VAR calculation time: 2.45 secs\n",
      "VAR calculation time: 2.66 secs\n",
      "VAR calculation time: 2.85 secs\n",
      "VAR calculation time: 3.06 secs\n",
      "VAR calculation time: 3.26 secs\n",
      "VAR calculation time: 3.50 secs\n",
      "VAR calculation time: 3.81 secs\n",
      "VAR calculation time: 4.01 secs\n",
      "VAR calculation time: 4.21 secs\n",
      "VAR calculation time: 4.41 secs\n",
      "VAR calculation time: 4.60 secs\n",
      "VAR calculation time: 4.79 secs\n",
      "VAR calculation time: 5.04 secs\n",
      "VAR calculation time: 5.24 secs\n",
      "VAR calculation time: 5.44 secs\n",
      "VAR calculation time: 5.65 secs\n",
      "VAR calculation time: 5.85 secs\n",
      "VAR calculation time: 6.05 secs\n",
      "VAR calculation time: 6.37 secs\n",
      "VAR calculation time: 6.88 secs\n",
      "VAR calculation time: 7.17 secs\n",
      "VAR calculation time: 7.69 secs\n",
      "VAR calculation time: 8.07 secs\n",
      "VAR calculation time: 8.46 secs\n",
      "VAR calculation time: 8.65 secs\n",
      "VAR calculation time: 8.84 secs\n",
      "VAR calculation time: 9.03 secs\n",
      "VAR calculation time: 9.23 secs\n",
      "VAR calculation time: 9.42 secs\n",
      "VAR calculation time: 9.64 secs\n",
      "VAR calculation time: 9.84 secs\n",
      "VAR calculation time: 10.03 secs\n",
      "VAR calculation time: 10.22 secs\n",
      "VAR calculation time: 10.40 secs\n",
      "VAR calculation time: 10.59 secs\n",
      "VAR calculation time: 10.78 secs\n",
      "VAR calculation time: 10.98 secs\n",
      "VAR calculation time: 11.23 secs\n",
      "VAR calculation time: 11.67 secs\n",
      "VAR calculation time: 11.97 secs\n",
      "VAR calculation time: 12.18 secs\n",
      "VAR calculation time: 12.37 secs\n",
      "VAR calculation time: 12.61 secs\n",
      "VAR calculation time: 12.84 secs\n",
      "VAR calculation time: 13.05 secs\n",
      "VAR calculation time: 13.26 secs\n",
      "VAR calculation time: 13.46 secs\n",
      "VAR calculation time: 13.66 secs\n",
      "VAR calculation time: 13.86 secs\n",
      "VAR calculation time: 14.05 secs\n",
      "VAR calculation time: 14.24 secs\n",
      "VAR calculation time: 14.43 secs\n",
      "VAR calculation time: 14.61 secs\n",
      "VAR calculation time: 14.80 secs\n",
      "VAR calculation time: 15.05 secs\n",
      "VAR calculation time: 15.25 secs\n",
      "VAR calculation time: 15.48 secs\n",
      "VAR calculation time: 15.69 secs\n",
      "VAR calculation time: 15.90 secs\n",
      "VAR calculation time: 16.29 secs\n",
      "VAR calculation time: 16.52 secs\n",
      "VAR calculation time: 16.72 secs\n",
      "VAR calculation time: 16.94 secs\n",
      "VAR calculation time: 17.14 secs\n",
      "VAR calculation time: 17.33 secs\n",
      "VAR calculation time: 17.51 secs\n",
      "VAR calculation time: 17.70 secs\n",
      "VAR calculation time: 17.94 secs\n",
      "VAR calculation time: 18.13 secs\n",
      "Getting results for SimpleExpSmoothing\n",
      "SimpleExpSmoothing calculation time: 0.37 secs\n",
      "SimpleExpSmoothing calculation time: 0.71 secs\n",
      "SimpleExpSmoothing calculation time: 1.06 secs\n",
      "SimpleExpSmoothing calculation time: 1.38 secs\n",
      "SimpleExpSmoothing calculation time: 1.69 secs\n",
      "SimpleExpSmoothing calculation time: 2.04 secs\n",
      "SimpleExpSmoothing calculation time: 2.41 secs\n",
      "SimpleExpSmoothing calculation time: 2.78 secs\n",
      "SimpleExpSmoothing calculation time: 3.11 secs\n",
      "SimpleExpSmoothing calculation time: 3.43 secs\n",
      "SimpleExpSmoothing calculation time: 3.74 secs\n",
      "SimpleExpSmoothing calculation time: 4.05 secs\n",
      "SimpleExpSmoothing calculation time: 4.40 secs\n",
      "SimpleExpSmoothing calculation time: 4.71 secs\n",
      "SimpleExpSmoothing calculation time: 5.02 secs\n",
      "SimpleExpSmoothing calculation time: 5.36 secs\n",
      "SimpleExpSmoothing calculation time: 5.69 secs\n",
      "SimpleExpSmoothing calculation time: 6.04 secs\n",
      "SimpleExpSmoothing calculation time: 6.39 secs\n",
      "SimpleExpSmoothing calculation time: 6.71 secs\n",
      "SimpleExpSmoothing calculation time: 7.01 secs\n",
      "SimpleExpSmoothing calculation time: 7.33 secs\n",
      "SimpleExpSmoothing calculation time: 7.65 secs\n",
      "SimpleExpSmoothing calculation time: 8.00 secs\n",
      "SimpleExpSmoothing calculation time: 8.34 secs\n",
      "SimpleExpSmoothing calculation time: 8.65 secs\n",
      "SimpleExpSmoothing calculation time: 9.00 secs\n",
      "SimpleExpSmoothing calculation time: 9.34 secs\n",
      "SimpleExpSmoothing calculation time: 9.67 secs\n",
      "SimpleExpSmoothing calculation time: 10.17 secs\n",
      "SimpleExpSmoothing calculation time: 10.61 secs\n",
      "SimpleExpSmoothing calculation time: 10.97 secs\n",
      "SimpleExpSmoothing calculation time: 11.31 secs\n",
      "SimpleExpSmoothing calculation time: 11.62 secs\n",
      "SimpleExpSmoothing calculation time: 11.95 secs\n",
      "SimpleExpSmoothing calculation time: 12.30 secs\n",
      "SimpleExpSmoothing calculation time: 12.70 secs\n",
      "SimpleExpSmoothing calculation time: 13.06 secs\n",
      "SimpleExpSmoothing calculation time: 13.39 secs\n",
      "SimpleExpSmoothing calculation time: 13.73 secs\n",
      "SimpleExpSmoothing calculation time: 14.05 secs\n",
      "SimpleExpSmoothing calculation time: 14.38 secs\n",
      "SimpleExpSmoothing calculation time: 14.76 secs\n",
      "SimpleExpSmoothing calculation time: 15.11 secs\n",
      "SimpleExpSmoothing calculation time: 15.43 secs\n",
      "SimpleExpSmoothing calculation time: 15.76 secs\n",
      "SimpleExpSmoothing calculation time: 16.09 secs\n",
      "SimpleExpSmoothing calculation time: 16.42 secs\n",
      "SimpleExpSmoothing calculation time: 16.73 secs\n",
      "SimpleExpSmoothing calculation time: 17.06 secs\n",
      "SimpleExpSmoothing calculation time: 17.39 secs\n",
      "SimpleExpSmoothing calculation time: 17.72 secs\n",
      "SimpleExpSmoothing calculation time: 18.04 secs\n",
      "SimpleExpSmoothing calculation time: 18.37 secs\n",
      "SimpleExpSmoothing calculation time: 18.69 secs\n",
      "SimpleExpSmoothing calculation time: 19.02 secs\n",
      "SimpleExpSmoothing calculation time: 19.35 secs\n",
      "SimpleExpSmoothing calculation time: 19.71 secs\n",
      "SimpleExpSmoothing calculation time: 20.04 secs\n",
      "SimpleExpSmoothing calculation time: 20.35 secs\n",
      "SimpleExpSmoothing calculation time: 20.66 secs\n",
      "SimpleExpSmoothing calculation time: 20.98 secs\n",
      "SimpleExpSmoothing calculation time: 21.31 secs\n",
      "SimpleExpSmoothing calculation time: 21.62 secs\n",
      "SimpleExpSmoothing calculation time: 21.95 secs\n",
      "SimpleExpSmoothing calculation time: 22.26 secs\n",
      "SimpleExpSmoothing calculation time: 22.57 secs\n",
      "SimpleExpSmoothing calculation time: 22.89 secs\n",
      "SimpleExpSmoothing calculation time: 23.21 secs\n",
      "SimpleExpSmoothing calculation time: 23.51 secs\n",
      "SimpleExpSmoothing calculation time: 23.82 secs\n",
      "SimpleExpSmoothing calculation time: 24.13 secs\n",
      "SimpleExpSmoothing calculation time: 24.48 secs\n",
      "SimpleExpSmoothing calculation time: 24.80 secs\n",
      "SimpleExpSmoothing calculation time: 25.19 secs\n",
      "SimpleExpSmoothing calculation time: 25.52 secs\n",
      "SimpleExpSmoothing calculation time: 25.83 secs\n",
      "SimpleExpSmoothing calculation time: 26.15 secs\n",
      "SimpleExpSmoothing calculation time: 26.46 secs\n",
      "SimpleExpSmoothing calculation time: 26.77 secs\n",
      "Getting results for ExponentialSmoothing\n",
      "ExponentialSmoothing calculation time: 11.48 secs\n",
      "ExponentialSmoothing calculation time: 22.82 secs\n",
      "ExponentialSmoothing calculation time: 34.50 secs\n",
      "ExponentialSmoothing calculation time: 46.58 secs\n",
      "ExponentialSmoothing calculation time: 59.02 secs\n",
      "ExponentialSmoothing calculation time: 71.69 secs\n",
      "ExponentialSmoothing calculation time: 84.44 secs\n",
      "ExponentialSmoothing calculation time: 97.49 secs\n",
      "ExponentialSmoothing calculation time: 110.74 secs\n",
      "ExponentialSmoothing calculation time: 123.67 secs\n",
      "ExponentialSmoothing calculation time: 136.54 secs\n",
      "ExponentialSmoothing calculation time: 150.64 secs\n",
      "ExponentialSmoothing calculation time: 164.57 secs\n",
      "ExponentialSmoothing calculation time: 178.03 secs\n",
      "ExponentialSmoothing calculation time: 191.12 secs\n",
      "ExponentialSmoothing calculation time: 203.83 secs\n",
      "ExponentialSmoothing calculation time: 216.85 secs\n"
     ]
    }
   ],
   "source": [
    "models_list = ['persistence','yesterday','hourly_average' , 'VAR', 'SimpleExpSmoothing', 'ExponentialSmoothing',]\n",
    "\n",
    "MAE_results = dict.fromkeys(models_list)\n",
    "NLPD_results = dict.fromkeys(models_list)\n",
    "\n",
    "\n",
    "#FIXED WINDOW OF 5000 train and 24 test, the 5000 train slide forward\n",
    "length_window = 97 * 10\n",
    "max_t = 14000 #len(data_multiple) - length_window - 24\n",
    "#HERE BUILDING ARRAY OF STARTING ts\n",
    "data_multiple.index = pd.to_datetime(data_multiple.index)\n",
    "array_of_indices = data_multiple.reset_index()[(data_multiple.reset_index().datetime.dt.hour > 9) & (data_multiple.reset_index().datetime.dt.hour < 14)].index.values\n",
    "range_idx = array_of_indices[10000:max_t:50]\n",
    "        \n",
    "\n",
    "for model_type in models_list:\n",
    "    print(f'Getting results for {model_type}')\n",
    "    t1 = time.time()\n",
    "\n",
    "    errors = np.zeros((24, n_sys_VAR))\n",
    "\n",
    "    for t in range_idx:\n",
    "        data_multiple_iter = data_multiple.iloc[t:t+length_window + 24]\n",
    "        data_multiple_train = data_multiple_iter.iloc[:length_window] \n",
    "        data_multiple_test = data_multiple_iter[length_window:]  \n",
    "\n",
    "        if model_type == 'VAR':\n",
    "\n",
    "            data_VAR = data_multiple_train.diff().diff(97).dropna()\n",
    "\n",
    "            #CREATE MODEL AND PREDICT NEXT 24\n",
    "            model = VAR(data_VAR)\n",
    "            model_fit = model.fit()\n",
    "            lag_order = model_fit.k_ar\n",
    "            preds = model_fit.forecast(data_VAR.values[-lag_order:], 24)\n",
    "            if len(preds[preds>10]) > 0:\n",
    "                print('Careful, a prediction is higher than 10!')\n",
    "            #evaluate forecast\n",
    "            df_forecast = pd.DataFrame(preds, index=data_multiple_test.index, columns=data_VAR.columns)\n",
    "\n",
    "            data_total = pd.concat([data_VAR,df_forecast], axis=0).reindex(data_multiple_iter.index).reset_index().drop(columns = ['datetime'])\n",
    "\n",
    "            data_reset = data_total.iloc[1:].reset_index().drop(columns=['index'])\n",
    "            restored = restore_differenced(97, data_multiple_iter.diff().dropna(), data_reset)\n",
    "            restored = restored.reindex(data_multiple_iter.index).reset_index().drop(columns=['datetime'])\n",
    "            restored_twice = restore_differenced(1, data_multiple_iter, restored)\n",
    "\n",
    "            #CLIPPING PREDICTIONS BETWEEN 0 AND 1\n",
    "            restored_twice = restored_twice.clip(0,1)\n",
    "            predictions = restored_twice.iloc[-24:]    \n",
    "\n",
    "        elif model_type == 'persistence':\n",
    "            predictions = data_multiple_train.iloc[-1].values\n",
    "\n",
    "        elif model_type == 'yesterday':\n",
    "            predictions = np.zeros((1,n_sys_VAR))\n",
    "            previous_day = data_multiple_train.iloc[-97:].values\n",
    "            for i in range(24):\n",
    "                pred = previous_day[-97 + i][np.newaxis, :]\n",
    "                predictions = np.concatenate((predictions, pred))\n",
    "            predictions = predictions[1:]\n",
    "\n",
    "        elif model_type == 'hourly_average':\n",
    "            predictions = np.zeros((1,n_sys_VAR))\n",
    "            previous_hour = data_multiple_train.iloc[-12:].values\n",
    "            for i in range(24):\n",
    "                pred = previous_hour.mean(axis=0)[np.newaxis, :]\n",
    "                predictions = np.concatenate((predictions, pred))\n",
    "                #HERE I append the latest prediction and remove the oldest observation\n",
    "                previous_hour = np.concatenate((previous_hour, pred), axis=0)[1:]\n",
    "            predictions = predictions[1:]\n",
    "            \n",
    "            \n",
    "        elif model_type == 'SimpleExpSmoothing':\n",
    "            predictions = np.zeros((24, 1))\n",
    "            variances = np.zeros((24, 1))\n",
    "            for ts in range(data_multiple_train.shape[1]):\n",
    "                model = SimpleExpSmoothing(data_multiple_train.iloc[:,ts], initialization_method=\"estimated\")\n",
    "                model_fit = model.fit()\n",
    "                \n",
    "                fcast = model_fit.forecast(24).values[:, np.newaxis]\n",
    "                predictions = np.concatenate((predictions, fcast), axis=1)\n",
    "                \n",
    "                var = model_fit.simulate(nsimulations = 24, anchor = 'end', repetitions = 1000 ).var(axis=1).values[:, np.newaxis]\n",
    "                \n",
    "                var_low_bound = (fcast**2 / 4)\n",
    "                var_upper_bound = ((1-fcast)**2 / 4)\n",
    "                var = np.maximum(var_low_bound, var)\n",
    "                var = np.minimum(var_upper_bound, var)\n",
    "                \n",
    "                variances = np.concatenate((variances, var), axis=1)\n",
    "                \n",
    "                \n",
    "            predictions = predictions[:, 1:]\n",
    "            variances = variances[:, 1:]\n",
    "            \n",
    "            nlpd = log_score_function(data_multiple_iter.iloc[-24:].values, predictions, variances) \n",
    "            \n",
    "            \n",
    "        elif model_type == 'ExponentialSmoothing':\n",
    "            predictions = np.zeros((24, 1))\n",
    "            variances = np.zeros((24, 1))\n",
    "            for ts in range(data_multiple_train.shape[1]):\n",
    "                model = ExponentialSmoothing(data_multiple_train.iloc[:,ts], \n",
    "                                             seasonal_periods=97,\n",
    "                                             seasonal=\"add\",\n",
    "                                             initialization_method=\"estimated\")\n",
    "                model_fit = model.fit()\n",
    "                fcast = model_fit.forecast(24).values[:, np.newaxis]\n",
    "                predictions = np.concatenate((predictions, fcast), axis=1)\n",
    "                \n",
    "                var = model_fit.simulate(nsimulations = 24, anchor = 'end', repetitions = 1000 ).var(axis=1).values[:, np.newaxis]\n",
    "                \n",
    "                var_low_bound = (fcast**2 / 4)\n",
    "                var_upper_bound = ((1-fcast)**2 / 4)\n",
    "                var = np.maximum(var_low_bound, var)\n",
    "                var = np.minimum(var_upper_bound, var)\n",
    "                \n",
    "                variances = np.concatenate((variances, var), axis=1)\n",
    "                \n",
    "            predictions = predictions[:, 1:]\n",
    "            variances = variances[:, 1:]\n",
    "            \n",
    "            nlpd = log_score_function(data_multiple_iter.iloc[-24:].values, predictions, variances) \n",
    "\n",
    "            \n",
    "        #THIS WAY WE REDUCE THE ERROR FURTHER USING A SIMPLE TRICK OF CLIPPING PREDICTIONS OUTSIDE DOMAIN\n",
    "        predictions = predictions.clip(0,1)\n",
    "        #Get error\n",
    "        error = abs((predictions - data_multiple_iter.iloc[-24:]).values)\n",
    "        errors = np.concatenate((errors, error))\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print(f'{model_type} calculation time: %2.2f secs' % (t2-t1))\n",
    "\n",
    "    errors = errors.reshape(-1, 24, n_sys_VAR)[1:]\n",
    "    MAE_hsteps = np.mean(np.mean(errors, axis=0), axis=1)    \n",
    "    MAE_results[model_type] = MAE_hsteps\n",
    "    \n",
    "    if (model_type == 'SimpleExpSmoothing') or (model_type == 'ExponentialSmoothing'):\n",
    "        NLPD_results[model_type] = nlpd\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40db4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NLPD_df = pd.DataFrame.from_dict(NLPD_results)\n",
    "NLPD_df_dropped = NLPD_df.copy(deep=True)\n",
    "NLPD_df_dropped[NLPD_df_dropped.ExponentialSmoothing>10000] = 10000\n",
    "NLPD_df_dropped.plot()\n",
    "plt.figure(figsize=(12,8))\n",
    "NLPD_df_dropped.boxplot()\n",
    "NLPD_df.mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828128e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAE_df = pd.DataFrame.from_dict(MAE_results)\n",
    "MAE_df.plot()\n",
    "plt.figure(figsize=(12,8))\n",
    "MAE_df.boxplot()\n",
    "MAE_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270e493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred = model_fit.forecast(24).values.clip(0,1)\n",
    "# two_std = (model_fit.simulate(nsimulations = 24, anchor = 'end', repetitions = 1000 ).std(axis=1) * 2).values\n",
    "# var = model_fit.simulate(nsimulations = 24, anchor = 'end', repetitions = 1000 ).var(axis=1).values\n",
    "# upper_conf = (pred + two_std).clip(0,1)\n",
    "# lower_conf = (pred - two_std).clip(0,1)\n",
    "\n",
    "# plt.plot(pred)\n",
    "# plt.plot(lower_conf)\n",
    "# plt.plot(upper_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}