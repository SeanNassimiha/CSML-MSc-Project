{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e291ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import bayesnewton\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../../Utils')\n",
    "import model_utils as mutils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dddc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('../../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime').drop(columns=['2657', '2828']) #DROPPING FAULTY SYSTEMS\n",
    "uk_pv = pd.read_csv('../../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "\n",
    "lats = dict(uk_pv.set_index('ss_id')['latitude_noisy'])\n",
    "longs = dict(uk_pv.set_index('ss_id')['longitude_noisy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7feadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA VARIABLES\n",
    "# SYSTEMS_NUM = 400\n",
    "# TIMESTEPS_NUM = int(len(data) / 5)\n",
    "# TRAIN_FRAC = 0.9\n",
    "# TEST_STATIONS = 400\n",
    "\n",
    "\n",
    "# #DATA VARIABLES\n",
    "SYSTEMS_NUM = 450\n",
    "TIMESTEPS_NUM = int(len(data) / 500)\n",
    "TRAIN_FRAC = 0.9\n",
    "TEST_STATIONS = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12a3061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "data_multiple = data.iloc[:, :SYSTEMS_NUM][:TIMESTEPS_NUM].reset_index()\n",
    "\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "stacked = mutils.stack_dataframe(data_multiple, lats, longs)\n",
    "\n",
    "X = np.array(stacked[['epoch', 'longitude', 'latitude']])\n",
    "Y = np.array(stacked[['PV']])\n",
    "#Create a space-time grid from X and Y\n",
    "t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n",
    "\n",
    "#train test split for 3 dimensional data\n",
    "t_train, t_test, R_train, R_test, Y_train, Y_test = mutils.train_split_3d(t, R, Y, train_frac = TRAIN_FRAC, split_by_day = False)\n",
    "\n",
    "#Scale the data\n",
    "scaled_values = mutils.scale_2d_train_test_data(R, Y, R_train, R_test, Y_train, Y_test )\n",
    "R_scaler, R_scaled, R_train_scaled, R_test_scaled, _, _, _, _ = scaled_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d88b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen = data.iloc[:, SYSTEMS_NUM:SYSTEMS_NUM+TEST_STATIONS][:TIMESTEPS_NUM].reset_index()\n",
    "\n",
    "capacities_unseen = uk_pv[uk_pv.ss_id_string.isin(data_unseen.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "stacked_unseen = mutils.stack_dataframe(data_unseen, lats, longs)\n",
    "\n",
    "del data,uk_pv\n",
    "\n",
    "X_unseen = np.array(stacked_unseen[['epoch', 'longitude', 'latitude']])\n",
    "Y_unseen = np.array(stacked_unseen[['PV']])\n",
    "\n",
    "t, R_unseen, Y_unseen = bayesnewton.utils.create_spatiotemporal_grid(X_unseen, Y_unseen)\n",
    "\n",
    "R_scaled_unseen = np.tile(R_scaler.transform(R_unseen[0]), (R_unseen.shape[0],1, 1)) #renormalise R and project across time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686aa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_IDW(power, time_factor, neighbours_space, neighbours_time, t_train, R_train, Y_train, t_test, R_test, Y_test, capacities_test):\n",
    "    '''\n",
    "    Function that calculates the IWD prediction for a single helf out system\n",
    "    power - power of distance metric\n",
    "    time_factor - factor that governs the weighted sum between time and space dimension\n",
    "    \n",
    "    returns:\n",
    "    - MAE of the predictor (averages over all systems)\n",
    "    - prediction for that specific location and timestep\n",
    "    \n",
    "    '''\n",
    "    print('beginning IDW')\n",
    "    \n",
    "    print('get space neighbours')\n",
    "    nbrs_space = NearestNeighbors(n_neighbors=neighbours_space, algorithm='ball_tree').fit(R_train)\n",
    "    distances_neighbours_space, idx_neighbours_space = nbrs_space.kneighbors(R_test)\n",
    "    \n",
    "    print('get time neighbours')\n",
    "    nbrs_time = NearestNeighbors(n_neighbors=neighbours_time, algorithm = 'kd_tree', p=1).fit(t_train)\n",
    "    distances_neighbours_time, idx_neighbours_time = nbrs_time.kneighbors(t_test)\n",
    "\n",
    "    distances = np.add.outer(distances_neighbours_space.T, distances_neighbours_time.T).swapaxes(0,3)\n",
    "    del distances_neighbours_space, distances_neighbours_time\n",
    "    weights = (1 / distances)** power\n",
    "    del distances\n",
    "    norm_weights = weights / np.sum(weights, axis = (2,3))[:,:, np.newaxis, np.newaxis]\n",
    "    del weights\n",
    "    y_neighbours = Y_train[idx_neighbours_time][:,:, idx_neighbours_space].swapaxes(1,2)\n",
    "    del idx_neighbours_space, idx_neighbours_time\n",
    "    predictions = np.sum(norm_weights * y_neighbours, axis = (2,3)) \n",
    "    del norm_weights\n",
    "    Y_MW = Y_test * capacities_test\n",
    "    predicted_MW = predictions * capacities_test\n",
    "    MAE = np.sqrt(np.nanmean((Y_MW - predicted_MW)**2))\n",
    "    print('Terminated IDW')\n",
    "    return MAE, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9eeced",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_time = NearestNeighbors(n_neighbors=10, algorithm = 'kd_tree', p=1).fit(t_train)\n",
    "distances_neighbours_time, idx_neighbours_time = nbrs_time.kneighbors(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab7eb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 2., 3., 3., 4., 4., 5., 5.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(distances_neighbours_time.shape)\n",
    "distances_neighbours_time[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a356bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10, 11,  9,  8, 12,  7, 13,  6,  5, 14])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(idx_neighbours_time.shape)\n",
    "idx_neighbours_time[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39532b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125, 124, 123, 122, 121, 120, 119, 118, 117, 116])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_neighbours_time[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1477998d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b7df2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb06eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.], dtype=float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b0349b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.,\n",
       "             12., 13., 14., 15., 16., 17., 18., 19.], dtype=float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[(t>t_train[0] - 20 ) & (t<t_train[0] + 20) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power = 2\n",
    "# time_factor = 1/10\n",
    "# neighbours_space = 10\n",
    "# neighbours_time = 10\n",
    "# MAE, predictions = evaluate_IDW(power, time_factor, neighbours_space, neighbours_time, t_train, R_train_scaled[0], Y_train[:,:,0], t, R_scaled_unseen[0], Y_unseen[:,:,0], capacities_unseen)\n",
    "\n",
    "# plt.plot(predictions[:,10])\n",
    "# plt.plot(Y_unseen[:,10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_IDW(power, time_factor, n_space, n_time):\n",
    "    '''\n",
    "    Wrapper function for bayesian opt of evaluate IDW\n",
    "    '''\n",
    "    \n",
    "    neighbours_space = int(n_space)\n",
    "    neighbours_time = int(n_time)\n",
    "    \n",
    "    MAE, predictions = evaluate_IDW(power, time_factor, neighbours_space, neighbours_time, t_train, R_train_scaled[0], Y_train[:,:,0], t, R_scaled_unseen[0], Y_unseen[:,:,0], capacities_unseen)\n",
    "    #return the negative value \n",
    "    return - MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf408c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimiser = BayesianOptimization(\n",
    "        f = opt_IDW,\n",
    "        pbounds = {'power' : (0.01, 5), 'time_factor': (0.01, 1), 'n_space': (2, 20), 'n_time': (5, 100)},\n",
    "        verbose = 2\n",
    "        )\n",
    "optimiser.maximize(n_iter = 50, init_points = 6)\n",
    "print('final result',optimiser.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008516e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
