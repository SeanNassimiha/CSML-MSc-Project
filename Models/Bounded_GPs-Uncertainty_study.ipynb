{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dbb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import bayesnewton\n",
    "import jax\n",
    "import objax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import math   \n",
    "from scipy.stats import beta\n",
    "from jax import vmap\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import sys, os\n",
    "sys.path.append('../Utils')\n",
    "import model_utils as mutils\n",
    "import kernels_definitions as kerns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c004eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA VARIABLES\n",
    "SYSTEMS_NUM = 10\n",
    "TIMESTEPS_NUM = 2000 \n",
    "TRAIN_FRAC = 24\n",
    "GRID_PIXELS = 20\n",
    "\n",
    "#OPTIMISATION VARIABLES\n",
    "LR_ADAM = 0.05\n",
    "LR_NEWTON = 0.5\n",
    "ITERS = 3\n",
    "\n",
    "#GP Variables\n",
    "VAR_Y = 0.5\n",
    "VAR_F = 0.5\n",
    "LEN_TIME = 6  # step size = 1 (hour)\n",
    "LEN_SPACE = 1\n",
    "\n",
    "#Want to use a sparse approximation\n",
    "SPARSE = True\n",
    "#Should we optimise the inducing points\n",
    "OPT_Z = False  # will be set to False if SPARSE=SPARSE\n",
    "\n",
    "#use a mean field approximation?\n",
    "MEAN_FIELD = False\n",
    "MINI_BATCH_SIZE = None #none if you don't want them\n",
    "\n",
    "TEST_STATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime').drop(columns=['2657', '2828']) #DROPPING FAULTY SYSTEMS\n",
    "uk_pv = pd.read_csv('../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "#data_multiple.plot(legend=False)\n",
    "lats = dict(uk_pv.set_index('ss_id')['latitude_noisy'])\n",
    "longs = dict(uk_pv.set_index('ss_id')['longitude_noisy'])\n",
    "data_multiple = data.iloc[:, :SYSTEMS_NUM][:TIMESTEPS_NUM].reset_index()\n",
    "stacked = mutils.stack_dataframe(data_multiple, lats, longs)\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.columns)].set_index('ss_id_string')['kwp'].values * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc04a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(stacked[['epoch', 'longitude', 'latitude']])\n",
    "Y = np.array(stacked[['PV']])\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords = convert_bng(X[:, 1], X[:, 2])\n",
    "X = np.vstack([X[:, 0],\n",
    "              np.array(british_national_grid_coords[0]),\n",
    "              np.array(british_national_grid_coords[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457fd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/geopandas/array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Grid of initial inducing points')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train test split for 3 dimensional data\n",
    "t_train, t_test, R_train, R_test, Y_train, Y_test = mutils.train_split_3d(t, R, Y, train_frac = TRAIN_FRAC, split_type = 'Cutoff')\n",
    "\n",
    "#get the mask of the test points\n",
    "test_mask = np.in1d(t.squeeze(), t_test.squeeze())\n",
    "\n",
    "#Scale the data\n",
    "scaled_values = mutils.scale_2d_train_test_data(R, Y, R_train, R_test, Y_train, Y_test )\n",
    "R_scaler, R_scaled, R_train_scaled, R_test_scaled, _, _, _, _ = scaled_values\n",
    "\n",
    "#here get a list of scaled coordinates (frozen because at some point in time)\n",
    "R_scaled_frozen = R_scaled[0]\n",
    "\n",
    "# #Create a grid to perform prediction/interpolation on\n",
    "r1, r2, Rplot = mutils.create_grid_from_coords(R = R_scaled_frozen, t = t, R_scaler = R_scaler, N_pixels = GRID_PIXELS)\n",
    "\n",
    "z = R_scaled[2, ...] \n",
    "\n",
    "    \n",
    "plt.scatter(*zip(*z), marker='o', s=30, color='red')\n",
    "plt.title('Grid of initial inducing points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095fda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern = kerns.get_SpatioTemporal_combined(variance=VAR_F,\n",
    "#                                            lengthscale_time=LEN_TIME,\n",
    "#                                            lengthscale_space=[LEN_SPACE, LEN_SPACE],\n",
    "#                                            z=z,\n",
    "#                                            sparse=SPARSE,\n",
    "#                                            opt_z=OPT_Z,\n",
    "#                                            matern_order = '32',\n",
    "#                                            conditional='Full')\n",
    "\n",
    "kern = kerns.get_periodic_kernel(variance=VAR_F,\n",
    "                                               lengthscale_time=LEN_TIME,\n",
    "                                               lengthscale_space=[LEN_SPACE, LEN_SPACE], #[LEN_SPACE, LEN_SPACE, LEN_ALTITUDE]\n",
    "                                               z=z,\n",
    "                                               sparse=SPARSE,\n",
    "                                               opt_z=OPT_Z,\n",
    "                                               conditional='FIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6439c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:5373: UserWarning: 'kind' argument to argsort is ignored; only 'stable' sorts are supported.\n",
      "  warnings.warn(\"'kind' argument to argsort is ignored; only 'stable' sorts \"\n"
     ]
    }
   ],
   "source": [
    "if MEAN_FIELD:\n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 30, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalMeanFieldGP(kernel=kern, likelihood=lik, X=t_train, R=R_train_scaled, Y=Y_train, parallel = True)\n",
    "else:    \n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 30, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalGP(kernel = kern, likelihood = lik, X=t_train, Y=Y_train, R=R_train_scaled)\n",
    "    \n",
    "opt_hypers = objax.optimizer.Adam(model.vars())\n",
    "energy = objax.GradValues(model.energy, model.vars())\n",
    "\n",
    "@objax.Function.with_vars(model.vars() + opt_hypers.vars())\n",
    "def train_op(batch_ind = None):\n",
    "    model.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "    dE, E = energy()  # compute energy and its gradients w.r.t. hypers\n",
    "    opt_hypers(LR_ADAM, dE)\n",
    "    return E\n",
    "\n",
    "# train_op = objax.Jit(train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecba0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1d242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        if number_of_minibatches > 1:\n",
    "            print(f'Doing minibatch {mini_batch}')\n",
    "        loss = train_op(mini_batches_indices[mini_batch])\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[0]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b1182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate posterior predictive distribution via filtering and smoothing at train & test locations:\n",
    "t0 = time.time()\n",
    "print('calculating the posterior predictive distribution ...')\n",
    "posterior_mean, posterior_var = model.predict_y(X=t, R=Rplot)\n",
    "t1 = time.time()\n",
    "print('prediction time: %2.2f secs' % (t1-t0))\n",
    "\n",
    "t2 = time.time()\n",
    "print('calculating the negative log predictive density ...')\n",
    "nlpd = model.negative_log_predictive_density(X=t_test, R=R_test_scaled, Y=Y_test)\n",
    "t3 = time.time()\n",
    "print('nlpd calculation time: %2.2f secs' % (t3-t2))\n",
    "print('nlpd: %2.3f' % nlpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f458980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_opt = model.kernel.z.value\n",
    "# mu = Y_scaler.inverse_transform(posterior_mean.flatten()[:, np.newaxis]).reshape(-1, GRID_PIXELS, GRID_PIXELS)\n",
    "mu = posterior_mean.reshape(TIMESTEPS_NUM, GRID_PIXELS, GRID_PIXELS)\n",
    "Y = Y[:,:,0]\n",
    "\n",
    "#get lat-lon coordinates\n",
    "grid_coord = R_scaler.inverse_transform(np.array(np.c_[r1,r2]))\n",
    "longitude_grid, latitude_grid =  convert_lonlat(grid_coord[:, 0], grid_coord[:, 1])\n",
    "longitude_sys_train, latitude_sys_train = convert_lonlat(R_train[:,:,0][0], R_train[:,:,1][0])\n",
    "longitude_z, latitude_z = convert_lonlat(R_scaler.inverse_transform(z_opt)[:,0], R_scaler.inverse_transform(z_opt)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea771b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_result = False\n",
    "# del model, kern, Rplot  # , var\n",
    "\n",
    "print('plotting ...')\n",
    "cmap = cm.viridis\n",
    "vmin = np.nanpercentile(Y, 1)\n",
    "vmax = np.nanpercentile(Y, 99)\n",
    "#get the labels for the dates\n",
    "dates = pd.to_datetime(data_multiple.datetime).dt.date\n",
    "days_index = max(97, int(((len(t) / 5) // 97) * 97)) #number of time intervals to match 5 beginnings of days\n",
    "\n",
    "for time_step in range(t.shape[0])[:50]:\n",
    "    f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [20, 1]})\n",
    "    f.set_figheight(8)\n",
    "    # f.set_figwidth(8)\n",
    "    im = a0.imshow(mu[time_step], cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "                   extent=[longitude_grid[0], longitude_grid[-1], latitude_grid[0], latitude_grid[-1]], origin='lower')\n",
    "    if SPARSE:\n",
    "        a0.scatter(longitude_z, latitude_z, c='r', s=60, alpha=0.5)  # plot inducing inputs\n",
    "    a0.scatter(longitude_sys_train, latitude_sys_train, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "               c=np.squeeze(Y[time_step]), s=50, edgecolors='black')\n",
    "    plt.colorbar(im, fraction=0.0348, pad=0.03, aspect=30, ax=a0)\n",
    "    \n",
    "    a0.set_xlim(longitude_grid[0], longitude_grid[-1])\n",
    "    a0.set_ylim(latitude_grid[0], latitude_grid[-1])\n",
    "    a0.set_title(f'PVE at {data_multiple.datetime.unique()[time_step]}')\n",
    "    a0.set_ylabel('Latitude')\n",
    "    a0.set_xlabel('Longitude')\n",
    "    a1.vlines(t[time_step].item(), -1, 1, 'r')\n",
    "    a1.set_xlabel('time (days)')\n",
    "    a1.set_xlim(t[0], t[-1])\n",
    "    \n",
    "    a1.set_xticks(np.asarray(t[1:-1:days_index ][:,0].tolist()), \n",
    "                  labels = dates[0:-1:days_index].values,\n",
    "                     fontsize = 10)\n",
    "    plt.show()\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE SYSTEM SPECIFIC PREDICTIONS (NOT THE TOTAL INTERPOLATION)\n",
    "len_samples = len(t_test) + 500\n",
    "test_mask_shortened = test_mask[-len_samples:]\n",
    "\n",
    "f_mean, f_var = model.predict(X=t[-len_samples:], R=R_scaled[-len_samples:])\n",
    "\n",
    "#GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean = f_mean.reshape(f_mean.shape[0], -1, 1)\n",
    "f_var = f_var.reshape(f_var.shape[0], -1, 1)\n",
    "\n",
    "mean_y, var_y = vmap(model.likelihood.predict, (0, 0, None))(f_mean, f_var, None)\n",
    "posterior_mean_ts, posterior_var_ts = np.squeeze(mean_y), np.squeeze(var_y)# posterior_mean_rescaled = Y_scaler.inverse_transform(posterior_mean_ts)\n",
    "\n",
    "#GET THE PREDICTION INTERVALS AND CALCULATE ERRORS\n",
    "\n",
    "posterior_pos_twostd_rescaled = posterior_mean_ts + 1.96 * np.sqrt(posterior_var_ts)\n",
    "posterior_neg_twostd_rescaled = posterior_mean_ts - 1.96 * np.sqrt(posterior_var_ts)\n",
    "\n",
    "rescaled_Y = (Y ) #* capacities)\n",
    "rescaled_posterior = posterior_mean_ts#) #* capacities\n",
    "\n",
    "#adjust this for the correct quantities\n",
    "mae = np.nanmean(abs(np.squeeze(rescaled_Y[-len_samples:]) - np.squeeze(rescaled_posterior)))\n",
    "print(f'The MAE is {mae.round(3)}')\n",
    "\n",
    "mae_train = np.nanmean(abs(np.squeeze(rescaled_Y[-len_samples:][~test_mask_shortened]) - np.squeeze(rescaled_posterior[~test_mask_shortened])))\n",
    "print(f'The train MAE is {mae_train.round(3)}')\n",
    "\n",
    "mae_test = np.nanmean(abs(np.squeeze(rescaled_Y[-len_samples:][test_mask_shortened]) - np.squeeze(rescaled_posterior[test_mask_shortened])), axis=1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(mae_test)\n",
    "plt.title('Error as function of forecast distance for Gaussian Process on validation test')\n",
    "plt.xlabel('Number of steps ahead (5min ticks)')\n",
    "plt.ylabel('Average MW error')\n",
    "\n",
    "print(f'The average 2 hours test MAE is {mae_test[:24].mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f8002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SAMPLE THE UNCERTAINTY BOUNDS\n",
    "\n",
    "#Sample values of f at each point\n",
    "sampled_f = np.random.normal(f_mean[:,:,0], f_var[:,:,0], size=(10, f_var.shape[0], f_var.shape[1]))\n",
    "\n",
    "alpha_sampled = model.likelihood.link_fn(sampled_f) * model.likelihood.scale\n",
    "beta_sampled = model.likelihood.scale - alpha_sampled\n",
    "\n",
    "beta_samples = np.random.beta(alpha_sampled, beta_sampled, size=(alpha_sampled.shape[0], alpha_sampled.shape[1], alpha_sampled.shape[2]))\n",
    "lower_bounds_beta_MC = np.quantile(beta_samples, 0.025, axis=0)\n",
    "upper_bounds_beta_MC = np.quantile(beta_samples, 0.975, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4e41e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_index = max(97, int(((len_samples / 3) // 97) * 97)) #number of time intervals to match 5 beginnings of days\n",
    "\n",
    "for i in range(SYSTEMS_NUM):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "    plt.plot(np.arange(len(Y))[-len_samples:], Y[:,i][-len_samples:], \"xk\")\n",
    "    plt.plot(np.arange(len(Y))[-len_samples:], posterior_mean_ts[:,i][-len_samples:], c=\"C0\", lw=2, zorder=2)\n",
    "#     plt.plot(np.arange(len(Y))[-len_samples:], R[-len_samples:, i, 2], 'green', alpha = 0.1)\n",
    "    plt.vlines(t_train[-1], 0, 1, colors='k')\n",
    "\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y))[-len_samples:],\n",
    "        lower_bounds_beta_MC[:,i],\n",
    "        upper_bounds_beta_MC[:,i],\n",
    "        color=\"C1\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "    plt.xticks(ticks = np.arange(len(Y))[-len_samples:-1:days_index], labels = data_multiple.datetime[-len_samples:-1:days_index].values, size=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4dcf90",
   "metadata": {},
   "source": [
    "## Get the Uncertainty intervals\n",
    "\n",
    "There are 3 ways to get quantiles:\n",
    "\n",
    "- Using the mean_f and the inverse CDF \n",
    "- Using the mean_f and sampling from Beta(alpha, beta / f)\n",
    "- Sampling directly from f* ~ Gaussian(f) and sampling again from Beta(alpha, beta / f*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78bc4a4",
   "metadata": {},
   "source": [
    "### First Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the mean and var of f at each datapoint\n",
    "f_mean, f_var = model.predict(X=t, R=R_scaled)\n",
    "\n",
    "#Sample values of f at each point\n",
    "sampled_f = np.random.normal(f_mean, f_var, size=(500, f_var.shape[0], f_var.shape[1]))\n",
    "\n",
    "#get \n",
    "alpha_laplace = model.likelihood.link_fn(f_mean) * model.likelihood.scale\n",
    "beta_laplace = model.likelihood.scale - alpha_laplace\n",
    "\n",
    "lower_bounds_beta_laplace_cdf = beta.ppf(0.025, alpha_laplace, beta_laplace)\n",
    "upper_bounds_beta_laplace_cdf = beta.ppf(0.975, alpha_laplace, beta_laplace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630aeb6",
   "metadata": {},
   "source": [
    "### Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_beta_laplace = np.random.beta(alpha_laplace, beta_laplace, size=(1000, alpha_laplace.shape[0], alpha_laplace.shape[1]))\n",
    "lower_bounds_beta_laplace_sampled = np.quantile(sampled_beta_laplace, 0.025, axis=0)\n",
    "upper_bounds_beta_laplace_sampled  = np.quantile(sampled_beta_laplace, 0.975, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd5329",
   "metadata": {},
   "source": [
    "### Third Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sampled = model.likelihood.link_fn(sampled_f) * model.likelihood.scale\n",
    "beta_sampled = model.likelihood.scale - alpha_sampled\n",
    "\n",
    "beta_samples = np.random.beta(alpha_sampled, beta_sampled, size=(alpha_sampled.shape[0], alpha_sampled.shape[1], alpha_sampled.shape[2]))\n",
    "lower_bounds_beta_MC = np.quantile(beta_samples, 0.025, axis=0)\n",
    "upper_bounds_beta_MC = np.quantile(beta_samples, 0.975, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eaa0bd",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426263aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lower_bounds_beta_laplace_sampled[:,5]); \n",
    "plt.plot(lower_bounds_beta_laplace_cdf[:,5]);\n",
    "plt.plot(lower_bounds_beta_MC[:,5]); \n",
    "\n",
    "plt.plot(upper_bounds_beta_laplace_sampled[:,5]); \n",
    "plt.plot(upper_bounds_beta_laplace_cdf[:,5]);\n",
    "plt.plot(upper_bounds_beta_MC[:,5]); \n",
    "\n",
    "plt.plot(np.arange(len(Y)), posterior_mean_ts[:,5], c=\"k\", lw=2, zorder=2)\n",
    "\n",
    "# plt.xlim(0,300)\n",
    "# plt.ylim(0, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(SYSTEMS_NUM):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "    plt.plot(np.arange(len(Y)), Y[:,i], \"xk\")\n",
    "    plt.plot(np.arange(len(Y)), posterior_mean_ts[:,i], c=\"C0\", lw=2, zorder=2)\n",
    "#     plt.plot(np.arange(len(Y)), post_samp[:,:, i].T)\n",
    "\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        lower_bounds_beta_laplace_sampled[:,i],\n",
    "        upper_bounds_beta_laplace_sampled[:,i],\n",
    "        color=\"C1\",\n",
    "        alpha=0.5)\n",
    "    \n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        lower_bounds_beta_laplace_cdf[:,i],\n",
    "        upper_bounds_beta_laplace_cdf[:,i],\n",
    "        color=\"red\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        lower_bounds_beta_MC[:,i],\n",
    "        upper_bounds_beta_MC[:,i],\n",
    "        color=\"blue\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "    plt.xticks(ticks = np.arange(len(Y))[0:-1:days_index], labels = data_multiple.datetime[0:-1:days_index].values, size=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c34422",
   "metadata": {},
   "source": [
    "So we can see that as expected the red uncertainty (the one using the inverse CDF) is much smaller, since it does not take into account the uncertainty in the latent $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee207de",
   "metadata": {},
   "source": [
    "## Predict on Unseen Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c138f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen = data.iloc[:, SYSTEMS_NUM:SYSTEMS_NUM+TEST_STATIONS][:TIMESTEPS_NUM].reset_index()\n",
    "capacities_unseen = uk_pv[uk_pv.ss_id_string.isin(data_unseen.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "stacked_unseen = mutils.stack_dataframe(data_unseen, lats, longs)\n",
    "\n",
    "X_unseen = np.array(stacked_unseen[['epoch', 'longitude', 'latitude']])\n",
    "Y_unseen = np.array(stacked_unseen[['PV']])\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords_unseen = convert_bng(X_unseen[:, 1], X_unseen[:, 2])\n",
    "X_unseen = np.vstack([X_unseen[:, 0],\n",
    "              np.array(british_national_grid_coords_unseen[0]),\n",
    "              np.array(british_national_grid_coords_unseen[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R_unseen, Y_unseen = bayesnewton.utils.create_spatiotemporal_grid(X_unseen, Y_unseen)\n",
    "R_unseen_scaled = np.tile(R_scaler.transform(R_unseen[0]), (R_unseen.shape[0],1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################FIRST METHOD \n",
    "\n",
    "#Get the mean and var of f at each datapoint\n",
    "posterior_mean_unseen, posterior_var_unseen = model.predict_y(X=t, R=R_unseen_scaled)\n",
    "f_mean_unseen, f_var_unseen = model.predict(X=t, R=R_unseen_scaled)\n",
    "\n",
    "#Sample values of f at each point\n",
    "sampled_f_unseen = np.random.normal(f_mean_unseen, f_var_unseen, size=(N_SAMPLES_UNSEEN, f_var_unseen.shape[0], f_var_unseen.shape[1]))\n",
    "\n",
    "unseen_alpha_laplace = model.likelihood.link_fn(f_mean_unseen) * model.likelihood.scale\n",
    "unseen_beta_laplace = model.likelihood.scale - unseen_alpha_laplace\n",
    "\n",
    "unseen_lower_bounds_beta_laplace_cdf = beta.ppf(0.025, unseen_alpha_laplace, unseen_beta_laplace)\n",
    "unseen_upper_bounds_beta_laplace_cdf = beta.ppf(0.975, unseen_alpha_laplace, unseen_beta_laplace)\n",
    "\n",
    "############################SECOND METHOD \n",
    "\n",
    "unseen_sampled_beta_laplace = np.random.beta(unseen_alpha_laplace, unseen_beta_laplace, size=(1000, unseen_alpha_laplace.shape[0], unseen_alpha_laplace.shape[1]))\n",
    "unseen_lower_bounds_beta_laplace_sampled = np.quantile(unseen_sampled_beta_laplace, 0.025, axis=0)\n",
    "unseen_upper_bounds_beta_laplace_sampled  = np.quantile(unseen_sampled_beta_laplace, 0.975, axis=0)\n",
    "\n",
    "############################THIRD METHOD \n",
    "\n",
    "unseen_alpha_sampled = model.likelihood.link_fn(sampled_f_unseen) * model.likelihood.scale\n",
    "unseen_beta_sampled = model.likelihood.scale - unseen_alpha_sampled\n",
    "\n",
    "unseen_beta_samples = np.random.beta(unseen_alpha_sampled, unseen_beta_sampled, size=(unseen_alpha_sampled.shape[0], unseen_alpha_sampled.shape[1], unseen_alpha_sampled.shape[2]))\n",
    "unseen_lower_bounds_beta_MC = np.quantile(unseen_beta_samples, 0.025, axis=0)\n",
    "unseen_upper_bounds_beta_MC = np.quantile(unseen_beta_samples, 0.975, axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(SYSTEMS_NUM):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "    plt.plot(np.arange(len(Y)), Y_unseen[:,i], \"xk\")\n",
    "    plt.plot(np.arange(len(Y)), posterior_mean_unseen[:,i], c=\"C0\", lw=2, zorder=2)\n",
    "\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        unseen_lower_bounds_beta_laplace_sampled[:,i],\n",
    "        unseen_upper_bounds_beta_laplace_sampled[:,i],\n",
    "        color=\"C1\",\n",
    "        alpha=0.5)\n",
    "    \n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        unseen_lower_bounds_beta_laplace_cdf[:,i],\n",
    "        unseen_upper_bounds_beta_laplace_cdf[:,i],\n",
    "        color=\"red\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        unseen_lower_bounds_beta_MC[:,i],\n",
    "        unseen_upper_bounds_beta_MC[:,i],\n",
    "        color=\"blue\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "    plt.xticks(ticks = np.arange(len(Y))[0:-1:days_index], labels = data_multiple.datetime[0:-1:days_index].values, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_unseen = Y_unseen[:,:,0]\n",
    "rescaled_Y_unseen = (Y_unseen * capacities_unseen)\n",
    "rescaled_posterior_unseen = posterior_mean_unseen * capacities_unseen\n",
    "\n",
    "mae = np.nanmean(abs(np.squeeze(rescaled_Y_unseen) - np.squeeze(rescaled_posterior_unseen)))\n",
    "print(f'The MAE is {mae.round(3)}')\n",
    "\n",
    "mae_train = np.nanmean(abs(np.squeeze(rescaled_Y_unseen[~test_mask]) - np.squeeze(rescaled_posterior_unseen[~test_mask])))\n",
    "print(f'The train MAE is {mae_train.round(3)}')\n",
    "\n",
    "mae_test = np.nanmean(abs(np.squeeze(rescaled_Y_unseen[test_mask]) - np.squeeze(rescaled_posterior_unseen[test_mask])))\n",
    "print(f'The test MAE is {mae_test.round(3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
