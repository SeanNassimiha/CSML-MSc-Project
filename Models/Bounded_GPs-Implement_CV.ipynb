{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9408a59",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import bayesnewton\n",
    "import jax\n",
    "import objax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import math   \n",
    "from jax import vmap\n",
    "from scipy.stats import beta\n",
    "import wandb\n",
    "\n",
    "import cv2\n",
    "import sys, os\n",
    "sys.path.append('../Utils')\n",
    "import model_utils as mutils\n",
    "import kernels_definitions as kerns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437e0fc1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#DATA VARIABLES\n",
    "SYSTEMS_NUM = 600\n",
    "TIMESTEPS_NUM = 50000\n",
    "TRAIN_FRAC = 24  #IF TRAIN_FRAC > 1 THEN IT BECOMES THE LENGTH OF THE TEST SET\n",
    "GRID_PIXELS = 10\n",
    "\n",
    "#OPTIMISATION VARIABLES\n",
    "LR_ADAM = 0.05\n",
    "LR_NEWTON = 0.5\n",
    "ITERS = 25\n",
    "\n",
    "#GP Variables\n",
    "BETA_SCALE = 30\n",
    "LEN_SPACE = 0.3\n",
    "LEN_ALTITUDE = 0.3\n",
    "\n",
    "#PERIODIC KERNEL\n",
    "VAR_PERIOD = 0.8\n",
    "VAR_MATERN = 0.8\n",
    "LEN_MATERN = 24 /  (TIMESTEPS_NUM / 100) #48\n",
    "LEN_PERIOD = 400 /  (TIMESTEPS_NUM / 100)#24\n",
    "\n",
    "#Want to use a sparse approximation\n",
    "SPARSE = True\n",
    "#Should we optimise the inducing points\n",
    "OPT_Z = False  # will be set to False if SPARSE=SPARSE\n",
    "\n",
    "#use a mean field approximation?\n",
    "MEAN_FIELD = False\n",
    "MINI_BATCH_SIZE = None #none if you don't want them\n",
    "TEST_STATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcaa89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = dict (\n",
    "\n",
    "#                 SYSTEMS_NUM = 100,\n",
    "#                 TIMESTEPS_NUM = 50000,\n",
    "#                 TRAIN_FRAC = 24 , #IF TRAIN_FRAC > 1 THEN IT BECOMES THE LENGTH OF THE TEST SET\n",
    "#                 GRID_PIXELS = 10,\n",
    "\n",
    "#                 #OPTIMISATION VARIABLES\n",
    "#                 LR_ADAM = 0.01,\n",
    "#                 LR_NEWTON = 0.5,\n",
    "#                 ITERS = 3,\n",
    "\n",
    "#                 #GP Variables\n",
    "#                 VAR_Y = 0.1,\n",
    "#                 LEN_SPACE = 0.5,\n",
    "#                 LEN_ALTITUDE = 0.3,\n",
    "\n",
    "#                 #PERIODIC KERNEL\n",
    "#                 VAR_PERIOD = 1.5,\n",
    "#                 VAR_MATERN = 1,\n",
    "#                 LEN_MATERN = 24 /  (TIMESTEPS_NUM / 100),   \n",
    "#                 LEN_PERIOD = 400 /  (TIMESTEPS_NUM / 100),  \n",
    "\n",
    "#                 #Want to use a sparse approximation\n",
    "#                 SPARSE = True,\n",
    "#                 #Should we optimise the inducing points\n",
    "#                 OPT_Z = False,  # will be set to False if SPARSE=SPARSE\n",
    "\n",
    "#                 #use a mean field approximation?\n",
    "#                 MEAN_FIELD = True,\n",
    "#                 MINI_BATCH_SIZE = None, #none if you don't want them\n",
    "#                 TEST_STATIONS = 10,\n",
    "\n",
    "# )\n",
    "\n",
    "# wandb.init(project=\"Nowcasting\", entity=\"snassimiha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime')\n",
    "uk_pv = pd.read_csv('../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "#data_multiple.plot(legend=False)\n",
    "lats = dict(uk_pv.set_index('ss_id')['latitude_noisy'])\n",
    "longs = dict(uk_pv.set_index('ss_id')['longitude_noisy'])\n",
    "data_multiple = data.iloc[:, :SYSTEMS_NUM][:TIMESTEPS_NUM].reset_index()\n",
    "stacked = mutils.stack_dataframe(data_multiple, lats, longs)\n",
    "#EXTRACT AREAS AROUND LONDON\n",
    "stacked = stacked[(stacked.latitude < 52.5) & (stacked.latitude > 50.5) & (stacked.longitude > -1) & (stacked.longitude < 1)]\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc04a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(stacked[['epoch', 'longitude', 'latitude']])\n",
    "Y = np.array(stacked[['PV']])\n",
    "\n",
    "from suncalc import get_position, get_times\n",
    "date_solar = stacked.datetime.values\n",
    "lon_solar = stacked.longitude.values\n",
    "lat_solar = stacked.latitude.values\n",
    "\n",
    "solar_positions = get_position(date_solar, lon_solar, lat_solar)\n",
    "solar_altitude = solar_positions['altitude']\n",
    "\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords = convert_bng(X[:, 1], X[:, 2])\n",
    "X = np.vstack([X[:, 0],\n",
    "              np.array(british_national_grid_coords[0]),\n",
    "              np.array(british_national_grid_coords[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n",
    "#SCALING THE t HERE\n",
    "t = t / (TIMESTEPS_NUM / 100)\n",
    "\n",
    "solar_altitudes = solar_altitude.reshape(R.shape[1], R.shape[0], 1).swapaxes(0,1)\n",
    "R = np.append(R, solar_altitudes, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457fd888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing normalisation of additional inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/geopandas/array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Grid of initial inducing points')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train test split for 3 dimensional data\n",
    "t_train, t_test, R_train, R_test, Y_train, Y_test = mutils.train_split_3d(t, R, Y, train_frac = TRAIN_FRAC, split_type = 'Cutoff')\n",
    "\n",
    "#get the mask of the test points\n",
    "test_mask = np.in1d(t.squeeze(), t_test.squeeze())\n",
    "\n",
    "#Scale the data\n",
    "scaled_values = mutils.scale_2d_train_test_data(R, Y, R_train, R_test, Y_train, Y_test )\n",
    "R_scaler, R_scaled, R_train_scaled, R_test_scaled, _, _, _, _ = scaled_values\n",
    "\n",
    "#here get a list of scaled coordinates (frozen because at some point in time)\n",
    "R_scaled_frozen = R_scaled[0]\n",
    "\n",
    "# #Create a grid to perform prediction/interpolation on\n",
    "r1, r2, Rplot = mutils.create_grid_from_coords(R = R_scaled_frozen, t = t, R_scaler = R_scaler, N_pixels = GRID_PIXELS, date_solar = date_solar)\n",
    "\n",
    "# z = R_scaled[2, ...]\n",
    "z =  R_scaled[2, ::2]\n",
    "\n",
    "# #CHANGE THE INDUCING POINTS FOR THE SOLAR ALTITUDE TO BE EQUALLY SPACED ALONG THE TOTAL INTERVAL\n",
    "z[:,2] = np.linspace(solar_altitude.min(),solar_altitude.max(),  len(z))\n",
    "    \n",
    "    \n",
    "plt.scatter(*zip(*z[:, :2]), marker='o', s=30, color='red')\n",
    "plt.title('Grid of initial inducing points')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2ad582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXED WINDOW OF 5000 train and 24 test, the 5000 train slide forward\n",
    "length_window = 96 * 100\n",
    "max_t = len(data_multiple) - length_window - 24\n",
    "iter_step = 50\n",
    "#HERE BUILDING ARRAY OF STARTING ts\n",
    "data_multiple = data_multiple.set_index('datetime')\n",
    "data_multiple.index = pd.to_datetime(data_multiple.index)\n",
    "array_of_indices = data_multiple.reset_index()[(data_multiple.reset_index().datetime.dt.hour > 9) & (data_multiple.reset_index().datetime.dt.hour < 14)].index.values\n",
    "data_multiple = data_multiple.reset_index()\n",
    "array_of_indices = array_of_indices[array_of_indices<max_t]\n",
    "range_idx = array_of_indices[length_window + 96:max_t:iter_step][-80:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759066f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_idx = np.array([20248, 20347, 20446, 20545, 20644, 20743, 20842, 20941, 21040,\n",
    "#        21139, 21238, 21337, 21436, 21535, 21634, 21782, 21881, 21980,\n",
    "#        22079, 22178, 22277, 22376, 22475, 22574, 22673, 22772, 22871,\n",
    "#        22970, 23069, 23168, 23267, 23366, 23465, 23564, 23663, 23762,\n",
    "#        23861, 23960, 24059, 24207, 24306, 24405, 24504, 24603, 24702,\n",
    "#        24801, 24900, 24999, 25098, 25197, 25296, 25395, 25494, 25593,\n",
    "#        25692, 25791, 25890, 25989, 26088, 26187, 26335, 26434, 26533,\n",
    "#        26632, 26731, 26830, 26929, 27028, 27127, 27226, 27325, 27424,\n",
    "#        27523, 27622, 27721, 27820, 27919, 28018, 28166, 28241])\n",
    "\n",
    "# range_idx =  range_idx + (9700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7b8853e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for Gaussian Process\n",
      "NEW ITERATION WITH t: 32247\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 191076.3332\n",
      "iter  2, energy: 144448.7779\n",
      "iter  3, energy: 120657.7866\n",
      "iter  4, energy: 111279.3765\n",
      "iter  5, energy: 111558.9075\n",
      "iter  6, energy: 119179.3252\n",
      "iter  7, energy: 131227.3331\n",
      "iter  8, energy: 143806.7652\n",
      "iter  9, energy: 154081.5624\n",
      "iter 10, energy: 160986.8654\n",
      "iter 11, energy: 164886.5963\n",
      "iter 12, energy: 166132.1870\n",
      "iter 13, energy: 165328.7470\n",
      "iter 14, energy: 163166.4818\n",
      "iter 15, energy: 160260.1625\n",
      "iter 16, energy: 157089.3150\n",
      "iter 17, energy: 154082.3308\n",
      "iter 18, energy: 151405.9036\n",
      "iter 19, energy: 149260.5793\n",
      "iter 20, energy: 147675.0910\n",
      "iter 21, energy: 146578.0894\n",
      "iter 22, energy: 145840.1061\n",
      "iter 23, energy: 145389.4200\n",
      "iter 24, energy: 145175.0016\n",
      "iter 25, energy: 145302.7864\n",
      "optimisation time: 5801.68 secs\n",
      "Performing the predictions\n",
      "mae is 0.22749506376265902 \n",
      "\n",
      "NEW ITERATION WITH t: 32346\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 116403.3882\n",
      "iter  2, energy: 102058.9829\n",
      "iter  3, energy: 98924.9549\n",
      "iter  4, energy: 99582.4918\n",
      "iter  5, energy: 101196.1727\n",
      "iter  6, energy: 108358.0937\n",
      "iter  7, energy: 101692.5092\n",
      "iter  8, energy: 99455.7733\n",
      "iter  9, energy: 98436.8548\n",
      "iter 10, energy: 100442.7131\n",
      "iter 11, energy: 103320.4634\n",
      "iter 12, energy: 107004.7198\n",
      "optimisation time: 1321.74 secs\n",
      "Performing the predictions\n",
      "mae is 0.1971973915177788 \n",
      "\n",
      "NEW ITERATION WITH t: 32445\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 141284.1375\n",
      "iter  2, energy: 113123.9210\n",
      "iter  3, energy: 110673.6930\n",
      "iter  4, energy: 111869.9025\n",
      "iter  5, energy: 114373.1329\n",
      "iter  6, energy: 117889.4530\n",
      "iter  7, energy: 122973.9077\n",
      "iter  8, energy: 126337.6864\n",
      "iter  9, energy: 129057.0638\n",
      "iter 10, energy: 131359.9829\n",
      "iter 11, energy: 133157.4103\n",
      "iter 12, energy: 134789.0876\n",
      "optimisation time: 1291.38 secs\n",
      "Performing the predictions\n",
      "mae is 0.11987738491971595 \n",
      "\n",
      "NEW ITERATION WITH t: 32544\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 141108.0978\n",
      "iter  2, energy: 125254.1553\n",
      "iter  3, energy: 130999.3950\n",
      "iter  4, energy: 131556.1612\n",
      "iter  5, energy: 130948.9755\n",
      "iter  6, energy: 132405.5559\n",
      "iter  7, energy: 134711.3085\n",
      "iter  8, energy: 137403.9179\n",
      "iter  9, energy: 139589.0067\n",
      "iter 10, energy: 142077.2479\n",
      "iter 11, energy: 143493.2131\n",
      "iter 12, energy: 144437.9889\n",
      "optimisation time: 1288.08 secs\n",
      "Performing the predictions\n",
      "mae is 0.1876759719081662 \n",
      "\n",
      "NEW ITERATION WITH t: 32643\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 133481.6571\n",
      "iter  2, energy: 131385.0797\n",
      "iter  3, energy: 129273.7567\n",
      "iter  4, energy: 134942.8697\n",
      "iter  5, energy: 132637.2306\n",
      "iter  6, energy: 133482.6247\n",
      "iter  7, energy: 135643.7907\n",
      "iter  8, energy: 138308.0583\n",
      "iter  9, energy: 140357.8819\n",
      "iter 10, energy: 142394.7309\n",
      "iter 11, energy: 144196.1781\n",
      "iter 12, energy: 145620.9767\n",
      "optimisation time: 58268.42 secs\n",
      "Performing the predictions\n",
      "mae is 0.2227773521864905 \n",
      "\n",
      "NEW ITERATION WITH t: 32742\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 134848.3983\n",
      "iter  2, energy: 129278.1961\n",
      "iter  3, energy: 130164.5624\n",
      "iter  4, energy: 133694.6338\n",
      "iter  5, energy: 134358.1587\n",
      "iter  6, energy: 136008.8001\n",
      "iter  7, energy: 137503.0308\n",
      "iter  8, energy: 139499.7970\n",
      "iter  9, energy: 141120.9720\n",
      "iter 10, energy: 142634.0613\n",
      "iter 11, energy: 143878.1738\n",
      "iter 12, energy: 144836.5259\n",
      "optimisation time: 1464.41 secs\n",
      "Performing the predictions\n",
      "mae is 0.16746248192654953 \n",
      "\n",
      "NEW ITERATION WITH t: 32841\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 131916.2451\n",
      "iter  2, energy: 127591.4950\n",
      "iter  3, energy: 128982.0828\n",
      "iter  4, energy: 132673.2059\n",
      "iter  5, energy: 133075.4827\n",
      "iter  6, energy: 134515.6349\n",
      "iter  7, energy: 135790.8807\n",
      "iter  8, energy: 137339.6750\n",
      "iter  9, energy: 138722.5164\n",
      "iter 10, energy: 140691.6300\n",
      "iter 11, energy: 142323.5688\n",
      "iter 12, energy: 143907.9686\n",
      "optimisation time: 1643.38 secs\n",
      "Performing the predictions\n",
      "mae is 0.15418121446676525 \n",
      "\n",
      "NEW ITERATION WITH t: 32940\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 130946.2454\n",
      "iter  2, energy: 127876.4871\n",
      "iter  3, energy: 129190.8888\n",
      "iter  4, energy: 132901.3836\n",
      "iter  5, energy: 133156.9624\n",
      "iter  6, energy: 134862.6125\n",
      "iter  7, energy: 136279.9816\n",
      "iter  8, energy: 138064.1979\n",
      "iter  9, energy: 139987.9285\n",
      "iter 10, energy: 141227.3749\n",
      "iter 11, energy: 142366.7250\n",
      "iter 12, energy: 143368.8456\n",
      "optimisation time: 2016.42 secs\n",
      "Performing the predictions\n",
      "mae is 0.18825165845754777 \n",
      "\n",
      "NEW ITERATION WITH t: 33088\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 134774.9001\n",
      "iter  2, energy: 134157.6297\n",
      "iter  3, energy: 137343.1312\n",
      "iter  4, energy: 136596.2879\n",
      "iter  5, energy: 137387.6611\n",
      "iter  6, energy: 139181.0670\n",
      "iter  7, energy: 139520.7016\n",
      "iter  8, energy: 140403.2794\n",
      "iter  9, energy: 141081.1626\n",
      "iter 10, energy: 141821.3796\n",
      "iter 11, energy: 142168.9205\n",
      "iter 12, energy: 142814.6450\n",
      "optimisation time: 2536.78 secs\n",
      "Performing the predictions\n",
      "mae is 0.19598216249063616 \n",
      "\n",
      "NEW ITERATION WITH t: 33187\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 127164.5087\n",
      "iter  2, energy: 123851.7478\n",
      "iter  3, energy: 131249.1221\n",
      "iter  4, energy: 130141.6586\n",
      "iter  5, energy: 130215.3095\n",
      "iter  6, energy: 130509.9920\n",
      "iter  7, energy: 131808.6212\n",
      "iter  8, energy: 133065.5625\n",
      "iter  9, energy: 135032.5201\n",
      "iter 10, energy: 136847.0835\n",
      "iter 11, energy: 138544.7128\n",
      "iter 12, energy: 139463.9067\n",
      "optimisation time: 2311.31 secs\n",
      "Performing the predictions\n",
      "mae is 0.13190736499823386 \n",
      "\n",
      "NEW ITERATION WITH t: 33286\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 126076.0761\n",
      "iter  2, energy: 121383.6140\n",
      "iter  3, energy: 123248.9290\n",
      "iter  4, energy: 127340.9459\n",
      "iter  5, energy: 128048.6327\n",
      "iter  6, energy: 130035.7607\n",
      "iter  7, energy: 131940.4335\n",
      "iter  8, energy: 134199.6206\n",
      "iter  9, energy: 136046.0120\n",
      "iter 10, energy: 137839.3069\n",
      "iter 11, energy: 139324.6473\n",
      "iter 12, energy: 140633.2200\n",
      "optimisation time: 1523.71 secs\n",
      "Performing the predictions\n",
      "mae is 0.14430590660841638 \n",
      "\n",
      "NEW ITERATION WITH t: 33385\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 127048.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  2, energy: 123010.9295\n",
      "iter  3, energy: 125448.9975\n",
      "iter  4, energy: 128809.1239\n",
      "iter  5, energy: 129701.8955\n",
      "iter  6, energy: 131689.7750\n",
      "iter  7, energy: 133185.0359\n",
      "iter  8, energy: 135336.3693\n",
      "iter  9, energy: 136582.5439\n",
      "iter 10, energy: 137860.5725\n",
      "iter 11, energy: 139035.5848\n",
      "iter 12, energy: 140031.0465\n",
      "optimisation time: 1997.96 secs\n",
      "Performing the predictions\n",
      "mae is 0.12708834459290605 \n",
      "\n",
      "NEW ITERATION WITH t: 33484\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 125868.7161\n",
      "iter  2, energy: 122037.7128\n",
      "iter  3, energy: 124210.8567\n",
      "iter  4, energy: 127790.4582\n",
      "iter  5, energy: 128981.4877\n",
      "iter  6, energy: 130466.3246\n",
      "iter  7, energy: 131903.2127\n",
      "iter  8, energy: 133972.6003\n",
      "iter  9, energy: 135063.7299\n",
      "iter 10, energy: 136344.3405\n",
      "iter 11, energy: 137802.2270\n",
      "iter 12, energy: 138614.7400\n",
      "optimisation time: 2886.77 secs\n",
      "Performing the predictions\n",
      "mae is 0.14530614065109979 \n",
      "\n",
      "NEW ITERATION WITH t: 33583\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 130738.4470\n",
      "iter  2, energy: 123267.1872\n",
      "iter  3, energy: 124204.3324\n",
      "iter  4, energy: 126591.0693\n",
      "iter  5, energy: 127727.3535\n",
      "iter  6, energy: 128993.9653\n",
      "iter  7, energy: 130377.5726\n",
      "iter  8, energy: 132644.9767\n",
      "iter  9, energy: 133783.3989\n",
      "iter 10, energy: 134957.0440\n",
      "iter 11, energy: 136259.7896\n",
      "iter 12, energy: 137130.9773\n",
      "optimisation time: 1617.10 secs\n",
      "Performing the predictions\n",
      "mae is 0.18826688261880456 \n",
      "\n",
      "NEW ITERATION WITH t: 33682\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 122745.7435\n",
      "iter  2, energy: 119769.3240\n",
      "iter  3, energy: 121674.2926\n",
      "iter  4, energy: 124993.2881\n",
      "iter  5, energy: 126285.5269\n",
      "iter  6, energy: 128411.2574\n",
      "iter  7, energy: 129900.5999\n",
      "iter  8, energy: 131758.5930\n",
      "iter  9, energy: 132672.7112\n",
      "iter 10, energy: 133897.4230\n",
      "iter 11, energy: 135126.6974\n",
      "iter 12, energy: 136255.6538\n",
      "optimisation time: 1586.60 secs\n",
      "Performing the predictions\n",
      "mae is 0.20740400692990876 \n",
      "\n",
      "NEW ITERATION WITH t: 33781\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 121850.6296\n",
      "iter  2, energy: 117997.9683\n",
      "iter  3, energy: 119956.4812\n",
      "iter  4, energy: 122979.5993\n",
      "iter  5, energy: 124504.3815\n",
      "iter  6, energy: 126639.8323\n",
      "iter  7, energy: 128474.2616\n",
      "iter  8, energy: 130330.8017\n",
      "iter  9, energy: 131362.5164\n",
      "iter 10, energy: 132454.6575\n",
      "iter 11, energy: 133442.3813\n",
      "iter 12, energy: 134387.6038\n",
      "optimisation time: 1583.98 secs\n",
      "Performing the predictions\n",
      "mae is 0.1944290002744298 \n",
      "\n",
      "NEW ITERATION WITH t: 33880\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 120488.7929\n",
      "iter  2, energy: 116713.4093\n",
      "iter  3, energy: 118889.6521\n",
      "iter  4, energy: 122041.9006\n",
      "iter  5, energy: 123278.8672\n",
      "iter  6, energy: 125173.3259\n",
      "iter  7, energy: 127436.2000\n",
      "iter  8, energy: 129294.9142\n",
      "iter  9, energy: 130347.6227\n",
      "iter 10, energy: 131263.3435\n",
      "iter 11, energy: 132257.3027\n",
      "iter 12, energy: 133174.3275\n",
      "optimisation time: 1617.33 secs\n",
      "Performing the predictions\n",
      "mae is 0.17918735401385502 \n",
      "\n",
      "NEW ITERATION WITH t: 33979\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 118920.3574\n",
      "iter  2, energy: 115782.1432\n",
      "iter  3, energy: 118151.3962\n",
      "iter  4, energy: 120885.2761\n",
      "iter  5, energy: 122229.5874\n",
      "iter  6, energy: 124308.5994\n",
      "iter  7, energy: 125792.6766\n",
      "iter  8, energy: 128027.2730\n",
      "iter  9, energy: 129095.2736\n",
      "iter 10, energy: 130150.3936\n",
      "iter 11, energy: 131101.6461\n",
      "iter 12, energy: 132025.6916\n",
      "optimisation time: 116094.73 secs\n",
      "Performing the predictions\n",
      "mae is 0.17599701566983725 \n",
      "\n",
      "NEW ITERATION WITH t: 34078\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 119837.7436\n",
      "iter  2, energy: 115306.1816\n",
      "iter  3, energy: 116766.8843\n",
      "iter  4, energy: 119592.2579\n",
      "iter  5, energy: 120922.8579\n",
      "iter  6, energy: 122928.8376\n",
      "iter  7, energy: 124297.9061\n",
      "iter  8, energy: 126528.4942\n",
      "iter  9, energy: 127565.8193\n",
      "iter 10, energy: 128737.1938\n",
      "iter 11, energy: 129608.6466\n",
      "iter 12, energy: 130507.0324\n",
      "optimisation time: 57714.11 secs\n",
      "Performing the predictions\n",
      "mae is 0.14388059492477598 \n",
      "\n",
      "NEW ITERATION WITH t: 34177\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 115353.0367\n",
      "iter  2, energy: 112897.5292\n",
      "iter  3, energy: 115049.1151\n",
      "iter  4, energy: 118083.2139\n",
      "iter  5, energy: 119302.3442\n",
      "iter  6, energy: 121399.1713\n",
      "iter  7, energy: 122791.1169\n",
      "iter  8, energy: 124816.2313\n",
      "iter  9, energy: 126217.0077\n",
      "iter 10, energy: 127388.6317\n",
      "iter 11, energy: 128343.0880\n",
      "iter 12, energy: 129177.1849\n",
      "optimisation time: 91520.35 secs\n",
      "Performing the predictions\n",
      "mae is 0.1692898085773651 \n",
      "\n",
      "NEW ITERATION WITH t: 34276\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 117566.9036\n",
      "iter  2, energy: 113999.6828\n",
      "iter  3, energy: 114547.1852\n",
      "iter  4, energy: 116982.8900\n",
      "iter  5, energy: 117978.9886\n",
      "iter  6, energy: 120071.5355\n",
      "iter  7, energy: 121415.2826\n",
      "iter  8, energy: 123390.1510\n",
      "iter  9, energy: 124598.9604\n",
      "iter 10, energy: 125548.8592\n",
      "iter 11, energy: 126487.0570\n",
      "iter 12, energy: 127413.4529\n",
      "optimisation time: 1582.02 secs\n",
      "Performing the predictions\n",
      "mae is 0.1592203093919877 \n",
      "\n",
      "NEW ITERATION WITH t: 34375\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 112872.7170\n",
      "iter  2, energy: 110566.1071\n",
      "iter  3, energy: 113391.5141\n",
      "iter  4, energy: 116089.5830\n",
      "iter  5, energy: 117230.9748\n",
      "iter  6, energy: 119328.6397\n",
      "iter  7, energy: 120804.5980\n",
      "iter  8, energy: 122900.0322\n",
      "iter  9, energy: 124029.0676\n",
      "iter 10, energy: 125178.0382\n",
      "iter 11, energy: 125869.9333\n",
      "iter 12, energy: 126652.9869\n",
      "optimisation time: 4721.39 secs\n",
      "Performing the predictions\n",
      "mae is 0.14336326028142302 \n",
      "\n",
      "NEW ITERATION WITH t: 34474\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 112933.3768\n",
      "iter  2, energy: 109931.0676\n",
      "iter  3, energy: 112019.0735\n",
      "iter  4, energy: 114659.7239\n",
      "iter  5, energy: 115885.8533\n",
      "iter  6, energy: 118005.4536\n",
      "iter  7, energy: 119464.0646\n",
      "iter  8, energy: 121351.7938\n",
      "iter  9, energy: 122557.9387\n",
      "iter 10, energy: 123621.7967\n",
      "iter 11, energy: 124556.1036\n",
      "iter 12, energy: 125289.2672\n",
      "optimisation time: 1639.22 secs\n",
      "Performing the predictions\n",
      "mae is 0.20769977468535297 \n",
      "\n",
      "NEW ITERATION WITH t: 34573\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1, energy: 112093.7637\n",
      "iter  2, energy: 108467.0734\n",
      "iter  3, energy: 110690.4699\n",
      "iter  4, energy: 113452.3670\n",
      "iter  5, energy: 115129.8416\n",
      "iter  6, energy: 116824.2985\n",
      "iter  7, energy: 118345.5038\n",
      "iter  8, energy: 120090.2359\n",
      "iter  9, energy: 121368.3127\n",
      "iter 10, energy: 122641.4958\n",
      "iter 11, energy: 123353.0527\n",
      "iter 12, energy: 124120.4348\n",
      "optimisation time: 42945.79 secs\n",
      "Performing the predictions\n",
      "mae is 0.21217326857542837 \n",
      "\n",
      "NEW ITERATION WITH t: 34672\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 111882.0835\n",
      "iter  2, energy: 107703.4638\n",
      "iter  3, energy: 109371.3285\n",
      "iter  4, energy: 112262.2600\n",
      "iter  5, energy: 113370.1063\n",
      "iter  6, energy: 115401.6294\n",
      "iter  7, energy: 117093.7506\n",
      "iter  8, energy: 118808.9426\n",
      "iter  9, energy: 120172.7763\n",
      "iter 10, energy: 121460.7364\n",
      "iter 11, energy: 122281.1244\n",
      "iter 12, energy: 123009.5141\n",
      "optimisation time: 1693.42 secs\n",
      "Performing the predictions\n",
      "mae is 0.12504192277300522 \n",
      "\n",
      "NEW ITERATION WITH t: 34771\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 113289.1267\n",
      "iter  2, energy: 107514.1064\n",
      "iter  3, energy: 108464.0568\n",
      "iter  4, energy: 111003.4466\n",
      "iter  5, energy: 112029.7287\n",
      "iter  6, energy: 113964.8765\n",
      "iter  7, energy: 115624.7548\n",
      "iter  8, energy: 117721.8271\n",
      "iter  9, energy: 118607.0163\n",
      "iter 10, energy: 119773.1667\n",
      "iter 11, energy: 120570.8387\n",
      "iter 12, energy: 121445.1525\n",
      "optimisation time: 1684.13 secs\n",
      "Performing the predictions\n",
      "mae is 0.1454371233985149 \n",
      "\n",
      "NEW ITERATION WITH t: 34870\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 106489.8109\n",
      "iter  2, energy: 103727.6774\n",
      "iter  3, energy: 105911.0911\n",
      "iter  4, energy: 108966.0579\n",
      "iter  5, energy: 110266.3563\n",
      "iter  6, energy: 112505.2309\n",
      "iter  7, energy: 113931.8267\n",
      "iter  8, energy: 115881.0524\n",
      "iter  9, energy: 116968.3941\n",
      "iter 10, energy: 118139.8629\n",
      "iter 11, energy: 119368.1784\n",
      "iter 12, energy: 120048.7783\n",
      "optimisation time: 1539.63 secs\n",
      "Performing the predictions\n",
      "mae is 0.18429993979645345 \n",
      "\n",
      "NEW ITERATION WITH t: 34969\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 109919.1845\n",
      "iter  2, energy: 105086.4498\n",
      "iter  3, energy: 105252.0875\n",
      "iter  4, energy: 107861.5528\n",
      "iter  5, energy: 108904.9311\n",
      "iter  6, energy: 111241.5058\n",
      "iter  7, energy: 112509.0187\n",
      "iter  8, energy: 114181.6258\n",
      "iter  9, energy: 115258.7588\n",
      "iter 10, energy: 116458.3610\n",
      "iter 11, energy: 117667.3934\n",
      "iter 12, energy: 118751.4086\n",
      "optimisation time: 1612.81 secs\n",
      "Performing the predictions\n",
      "mae is 0.1655245813249528 \n",
      "\n",
      "NEW ITERATION WITH t: 35068\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 108801.6201\n",
      "iter  2, energy: 102643.4203\n",
      "iter  3, energy: 103591.1250\n",
      "iter  4, energy: 106476.5365\n",
      "iter  5, energy: 107685.1625\n",
      "iter  6, energy: 110097.5083\n",
      "iter  7, energy: 111502.5054\n",
      "iter  8, energy: 113382.6182\n",
      "iter  9, energy: 114615.6542\n",
      "iter 10, energy: 115820.1387\n",
      "iter 11, energy: 116881.0816\n",
      "iter 12, energy: 117680.1529\n",
      "optimisation time: 1585.32 secs\n",
      "Performing the predictions\n",
      "mae is 0.14208565773591353 \n",
      "\n",
      "NEW ITERATION WITH t: 35167\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 103533.7421\n",
      "iter  2, energy: 102275.1634\n",
      "iter  3, energy: 102448.3164\n",
      "iter  4, energy: 105642.0640\n",
      "iter  5, energy: 106986.9160\n",
      "iter  6, energy: 108907.0189\n",
      "iter  7, energy: 109907.6550\n",
      "iter  8, energy: 111608.0197\n",
      "iter  9, energy: 113392.0712\n",
      "iter 10, energy: 114379.0591\n",
      "iter 11, energy: 115658.1253\n",
      "iter 12, energy: 116979.6858\n",
      "optimisation time: 1542.88 secs\n",
      "Performing the predictions\n",
      "mae is 0.18677679023681323 \n",
      "\n",
      "NEW ITERATION WITH t: 35266\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 105283.7072\n",
      "iter  2, energy: 101185.5474\n",
      "iter  3, energy: 101059.0224\n",
      "iter  4, energy: 103378.7392\n",
      "iter  5, energy: 104235.5954\n",
      "iter  6, energy: 106495.3436\n",
      "iter  7, energy: 107758.1064\n",
      "iter  8, energy: 109428.5839\n",
      "iter  9, energy: 110681.9668\n",
      "iter 10, energy: 111945.1614\n",
      "iter 11, energy: 113166.2140\n",
      "iter 12, energy: 114201.1655\n",
      "optimisation time: 1611.24 secs\n",
      "Performing the predictions\n",
      "mae is 0.17602080009348212 \n",
      "\n",
      "NEW ITERATION WITH t: 35365\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 99377.2357\n",
      "iter  2, energy: 98251.4105\n",
      "iter  3, energy: 98288.4267\n",
      "iter  4, energy: 101142.6067\n",
      "iter  5, energy: 102516.8184\n",
      "iter  6, energy: 104355.2533\n",
      "iter  7, energy: 105572.6701\n",
      "iter  8, energy: 107143.9838\n",
      "iter  9, energy: 108604.2889\n",
      "iter 10, energy: 110074.5998\n",
      "iter 11, energy: 111535.4738\n",
      "iter 12, energy: 112795.9219\n",
      "optimisation time: 1591.58 secs\n",
      "Performing the predictions\n",
      "mae is 0.17453133122859268 \n",
      "\n",
      "NEW ITERATION WITH t: 35513\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 100367.1405\n",
      "iter  2, energy: 101016.2530\n",
      "iter  3, energy: 103705.5634\n",
      "iter  4, energy: 103633.9831\n",
      "iter  5, energy: 104430.8828\n",
      "iter  6, energy: 105958.5090\n",
      "iter  7, energy: 106640.6413\n",
      "iter  8, energy: 107628.0079\n",
      "iter  9, energy: 108854.8086\n",
      "iter 10, energy: 109687.4607\n",
      "iter 11, energy: 110512.4131\n",
      "iter 12, energy: 111373.9054\n",
      "optimisation time: 1569.98 secs\n",
      "Performing the predictions\n",
      "mae is 0.21114653475471212 \n",
      "\n",
      "NEW ITERATION WITH t: 35612\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 106940.6682\n",
      "iter  2, energy: 96746.1136\n",
      "iter  3, energy: 95849.7950\n",
      "iter  4, energy: 96962.2571\n",
      "iter  5, energy: 98359.1531\n",
      "iter  6, energy: 100190.2768\n",
      "iter  7, energy: 101979.7127\n",
      "iter  8, energy: 103123.3314\n",
      "iter  9, energy: 104524.1097\n",
      "iter 10, energy: 105920.3519\n",
      "iter 11, energy: 107413.9578\n",
      "iter 12, energy: 108504.2213\n",
      "optimisation time: 1684.15 secs\n",
      "Performing the predictions\n",
      "mae is 0.14750113214149496 \n",
      "\n",
      "NEW ITERATION WITH t: 35711\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 97709.0680\n",
      "iter  2, energy: 94299.0514\n",
      "iter  3, energy: 93697.4126\n",
      "iter  4, energy: 96455.5914\n",
      "iter  5, energy: 97764.0481\n",
      "iter  6, energy: 99239.1155\n",
      "iter  7, energy: 100216.3479\n",
      "iter  8, energy: 101785.2338\n",
      "iter  9, energy: 103102.8929\n",
      "iter 10, energy: 104342.8088\n",
      "iter 11, energy: 105597.3634\n",
      "iter 12, energy: 106783.5312\n",
      "optimisation time: 1684.64 secs\n",
      "Performing the predictions\n",
      "mae is 0.12828167420744266 \n",
      "\n",
      "NEW ITERATION WITH t: 35810\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1, energy: 91250.0827\n",
      "iter  2, energy: 90372.2689\n",
      "iter  3, energy: 91062.8668\n",
      "iter  4, energy: 93698.5901\n",
      "iter  5, energy: 94889.3629\n",
      "iter  6, energy: 96355.9657\n",
      "iter  7, energy: 97774.9234\n",
      "iter  8, energy: 99135.7535\n",
      "iter  9, energy: 100607.0303\n",
      "iter 10, energy: 102266.7600\n",
      "iter 11, energy: 103671.9344\n",
      "iter 12, energy: 104771.8896\n",
      "optimisation time: 1544.13 secs\n",
      "Performing the predictions\n",
      "mae is 0.10365862112274293 \n",
      "\n",
      "NEW ITERATION WITH t: 35909\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 93281.7349\n",
      "iter  2, energy: 90027.2695\n",
      "iter  3, energy: 89511.8395\n",
      "iter  4, energy: 91869.9158\n",
      "iter  5, energy: 92353.2633\n",
      "iter  6, energy: 94417.8859\n",
      "iter  7, energy: 95799.5430\n",
      "iter  8, energy: 97216.3336\n",
      "iter  9, energy: 98619.0686\n",
      "iter 10, energy: 99931.7429\n",
      "iter 11, energy: 101184.9692\n",
      "iter 12, energy: 102357.9386\n",
      "optimisation time: 1668.30 secs\n",
      "Performing the predictions\n",
      "mae is 0.15029767538117278 \n",
      "\n",
      "NEW ITERATION WITH t: 36008\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 87774.6269\n",
      "iter  2, energy: 86434.8950\n",
      "iter  3, energy: 86748.4318\n",
      "iter  4, energy: 91290.7418\n",
      "iter  5, energy: 90262.2871\n",
      "iter  6, energy: 91155.2938\n",
      "iter  7, energy: 92055.0257\n",
      "iter  8, energy: 93600.3565\n",
      "iter  9, energy: 94935.1723\n",
      "iter 10, energy: 96344.7780\n",
      "iter 11, energy: 97781.3623\n",
      "iter 12, energy: 99125.0360\n",
      "optimisation time: 1309.43 secs\n",
      "Performing the predictions\n",
      "mae is 0.16348404468055863 \n",
      "\n",
      "NEW ITERATION WITH t: 36107\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 88200.9300\n",
      "iter  2, energy: 90928.0293\n",
      "iter  3, energy: 86649.1109\n",
      "iter  4, energy: 87790.2694\n",
      "iter  5, energy: 87698.3191\n",
      "iter  6, energy: 88969.5344\n",
      "iter  7, energy: 89857.7407\n",
      "iter  8, energy: 91104.2635\n",
      "iter  9, energy: 92687.6411\n",
      "iter 10, energy: 94264.4783\n",
      "iter 11, energy: 95743.0595\n",
      "iter 12, energy: 97039.5423\n",
      "optimisation time: 63310.78 secs\n",
      "Performing the predictions\n",
      "mae is 0.15515833885599642 \n",
      "\n",
      "NEW ITERATION WITH t: 36206\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 84453.2923\n",
      "iter  2, energy: 82786.3918\n",
      "iter  3, energy: 82767.6734\n",
      "iter  4, energy: 85099.9085\n",
      "iter  5, energy: 85721.0076\n",
      "iter  6, energy: 86470.7682\n",
      "iter  7, energy: 87471.0852\n",
      "iter  8, energy: 88739.4475\n",
      "iter  9, energy: 89948.3048\n",
      "iter 10, energy: 91207.3524\n",
      "iter 11, energy: 92615.0662\n",
      "iter 12, energy: 93822.3815\n",
      "optimisation time: 1276.72 secs\n",
      "Performing the predictions\n",
      "mae is 0.12802092331218937 \n",
      "\n",
      "NEW ITERATION WITH t: 36305\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 80553.5785\n",
      "iter  2, energy: 78707.0759\n",
      "iter  3, energy: 80020.2778\n",
      "iter  4, energy: 82736.2740\n",
      "iter  5, energy: 82777.2590\n",
      "iter  6, energy: 84071.9302\n",
      "iter  7, energy: 85271.2219\n",
      "iter  8, energy: 86567.5875\n",
      "iter  9, energy: 87897.8832\n",
      "iter 10, energy: 89181.6312\n",
      "iter 11, energy: 90459.0798\n",
      "iter 12, energy: 91511.1000\n",
      "optimisation time: 1292.88 secs\n",
      "Performing the predictions\n",
      "mae is 0.1286830689857382 \n",
      "\n",
      "NEW ITERATION WITH t: 36404\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 78192.4366\n",
      "iter  2, energy: 76502.7244\n",
      "iter  3, energy: 78154.0506\n",
      "iter  4, energy: 80651.5154\n",
      "iter  5, energy: 80507.7847\n",
      "iter  6, energy: 81983.3498\n",
      "iter  7, energy: 82816.6867\n",
      "iter  8, energy: 84319.5216\n",
      "iter  9, energy: 85379.5576\n",
      "iter 10, energy: 86611.6880\n",
      "iter 11, energy: 87745.7651\n",
      "iter 12, energy: 88981.5367\n",
      "optimisation time: 1339.66 secs\n",
      "Performing the predictions\n",
      "mae is 0.09906125286543732 \n",
      "\n",
      "NEW ITERATION WITH t: 36503\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 75828.0900\n",
      "iter  2, energy: 74601.2170\n",
      "iter  3, energy: 75471.6927\n",
      "iter  4, energy: 77539.3878\n",
      "iter  5, energy: 77747.2378\n",
      "iter  6, energy: 78495.9853\n",
      "iter  7, energy: 79234.4869\n",
      "iter  8, energy: 80491.3018\n",
      "iter  9, energy: 81687.4487\n",
      "iter 10, energy: 82931.4741\n",
      "iter 11, energy: 84065.3820\n",
      "iter 12, energy: 85204.5753\n",
      "optimisation time: 1355.78 secs\n",
      "Performing the predictions\n",
      "mae is 0.14542369764754295 \n",
      "\n",
      "NEW ITERATION WITH t: 36602\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 73083.8661\n",
      "iter  2, energy: 71670.7504\n",
      "iter  3, energy: 73176.3411\n",
      "iter  4, energy: 75420.7663\n",
      "iter  5, energy: 75470.8815\n",
      "iter  6, energy: 76906.6980\n",
      "iter  7, energy: 77985.4690\n",
      "iter  8, energy: 79660.3987\n",
      "iter  9, energy: 80762.4333\n",
      "iter 10, energy: 82101.0821\n",
      "iter 11, energy: 83219.9035\n",
      "iter 12, energy: 84294.6030\n",
      "optimisation time: 1278.34 secs\n",
      "Performing the predictions\n",
      "mae is 0.16950322308240393 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/13kbd8ws0q1935vwt56pkc8w0000gn/T/ipykernel_49766/3089785851.py:119: RuntimeWarning: divide by zero encountered in log\n",
      "  NNL_hsteps = -np.sum(np.log(likelihoods.mean(axis=0)), axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW ITERATION WITH t: 36701\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 72424.3181\n",
      "iter  2, energy: 70241.8091\n",
      "iter  3, energy: 71403.5844\n",
      "iter  4, energy: 73118.2596\n",
      "iter  5, energy: 72888.2320\n",
      "iter  6, energy: 74090.9096\n",
      "iter  7, energy: 74780.1180\n",
      "iter  8, energy: 76229.0621\n",
      "iter  9, energy: 77335.5783\n",
      "iter 10, energy: 78740.0513\n",
      "iter 11, energy: 80048.7419\n",
      "iter 12, energy: 81250.0307\n",
      "optimisation time: 1274.00 secs\n",
      "Performing the predictions\n",
      "mae is 0.19574058477512848 \n",
      "\n",
      "NEW ITERATION WITH t: 36800\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 69730.6293\n",
      "iter  2, energy: 67480.6145\n",
      "iter  3, energy: 68795.4835\n",
      "iter  4, energy: 70203.1686\n",
      "iter  5, energy: 69847.2855\n",
      "iter  6, energy: 70980.3495\n",
      "iter  7, energy: 71789.8198\n",
      "iter  8, energy: 73218.6834\n",
      "iter  9, energy: 74338.9894\n",
      "iter 10, energy: 75795.8422\n",
      "iter 11, energy: 77043.9480\n",
      "iter 12, energy: 78326.3515\n",
      "optimisation time: 1321.63 secs\n",
      "Performing the predictions\n",
      "mae is 0.12805289679548024 \n",
      "\n",
      "NEW ITERATION WITH t: 36899\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 65150.0783\n",
      "iter  2, energy: 63452.8208\n",
      "iter  3, energy: 65183.9157\n",
      "iter  4, energy: 66491.3220\n",
      "iter  5, energy: 66344.1933\n",
      "iter  6, energy: 67431.8362\n",
      "iter  7, energy: 68419.8837\n",
      "iter  8, energy: 69925.7712\n",
      "iter  9, energy: 71198.9382\n",
      "iter 10, energy: 72671.1428\n",
      "iter 11, energy: 74107.0731\n",
      "iter 12, energy: 75439.1198\n",
      "optimisation time: 1246.13 secs\n",
      "Performing the predictions\n",
      "mae is 0.14544649331409965 \n",
      "\n",
      "NEW ITERATION WITH t: 36998\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 65551.2584\n",
      "iter  2, energy: 62709.5224\n",
      "iter  3, energy: 63910.8597\n",
      "iter  4, energy: 65817.0350\n",
      "iter  5, energy: 65014.2407\n",
      "iter  6, energy: 65841.8067\n",
      "iter  7, energy: 66623.5992\n",
      "iter  8, energy: 68368.6026\n",
      "iter  9, energy: 69500.5061\n",
      "iter 10, energy: 71674.3108\n",
      "iter 11, energy: 72617.4130\n",
      "iter 12, energy: 74110.6243\n",
      "optimisation time: 1278.09 secs\n",
      "Performing the predictions\n",
      "mae is 0.17891352382767564 \n",
      "\n",
      "NEW ITERATION WITH t: 37097\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 62011.9778\n",
      "iter  2, energy: 60585.7599\n",
      "iter  3, energy: 61974.6954\n",
      "iter  4, energy: 63153.5278\n",
      "iter  5, energy: 63483.3447\n",
      "iter  6, energy: 64565.0817\n",
      "iter  7, energy: 65656.1833\n",
      "iter  8, energy: 66815.7842\n",
      "iter  9, energy: 68374.8641\n",
      "iter 10, energy: 69716.0354\n",
      "iter 11, energy: 71132.3237\n",
      "iter 12, energy: 72488.0453\n",
      "optimisation time: 1274.63 secs\n",
      "Performing the predictions\n",
      "mae is 0.18096162727113543 \n",
      "\n",
      "NEW ITERATION WITH t: 37196\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 60681.7844\n",
      "iter  2, energy: 59255.6995\n",
      "iter  3, energy: 60212.2925\n",
      "iter  4, energy: 61731.1081\n",
      "iter  5, energy: 61941.4456\n",
      "iter  6, energy: 62656.8859\n",
      "iter  7, energy: 63896.7676\n",
      "iter  8, energy: 65095.1777\n",
      "iter  9, energy: 66565.1122\n",
      "iter 10, energy: 67810.3567\n",
      "iter 11, energy: 69179.0957\n",
      "iter 12, energy: 70498.4116\n",
      "optimisation time: 1277.05 secs\n",
      "Performing the predictions\n",
      "mae is 0.14203985605751487 \n",
      "\n",
      "NEW ITERATION WITH t: 37295\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 59641.3893\n",
      "iter  2, energy: 58414.1394\n",
      "iter  3, energy: 59432.6816\n",
      "iter  4, energy: 60893.3679\n",
      "iter  5, energy: 61182.0533\n",
      "iter  6, energy: 61882.2098\n",
      "iter  7, energy: 62969.8312\n",
      "iter  8, energy: 64188.6210\n",
      "iter  9, energy: 65556.7137\n",
      "iter 10, energy: 66947.7394\n",
      "iter 11, energy: 68396.8171\n",
      "iter 12, energy: 69646.7493\n",
      "optimisation time: 1384.90 secs\n",
      "Performing the predictions\n",
      "mae is 0.2517091617885224 \n",
      "\n",
      "NEW ITERATION WITH t: 37394\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 93393.4835\n",
      "iter  2, energy: 69994.0002\n",
      "iter  3, energy: 62677.5050\n",
      "iter  4, energy: 61262.2962\n",
      "iter  5, energy: 60661.1547\n",
      "iter  6, energy: 60924.2080\n",
      "iter  7, energy: 61901.6893\n",
      "iter  8, energy: 63107.8998\n",
      "iter  9, energy: 64395.5736\n",
      "iter 10, energy: 65825.6343\n",
      "iter 11, energy: 67181.3172\n",
      "iter 12, energy: 68476.4065\n",
      "optimisation time: 1329.25 secs\n",
      "Performing the predictions\n",
      "mae is 0.2393146090449947 \n",
      "\n",
      "NEW ITERATION WITH t: 37493\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 58189.8869\n",
      "iter  2, energy: 56894.9493\n",
      "iter  3, energy: 57650.4288\n",
      "iter  4, energy: 59065.7994\n",
      "iter  5, energy: 59137.0008\n",
      "iter  6, energy: 59589.0906\n",
      "iter  7, energy: 60636.2309\n",
      "iter  8, energy: 61744.0170\n",
      "iter  9, energy: 62986.4482\n",
      "iter 10, energy: 64336.4106\n",
      "iter 11, energy: 65669.9230\n",
      "iter 12, energy: 66916.0026\n",
      "optimisation time: 1615.32 secs\n",
      "Performing the predictions\n",
      "mae is 0.24063731729753712 \n",
      "\n",
      "NEW ITERATION WITH t: 37592\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 57802.7409\n",
      "iter  2, energy: 56191.3439\n",
      "iter  3, energy: 56785.6475\n",
      "iter  4, energy: 58407.6980\n",
      "iter  5, energy: 58254.1710\n",
      "iter  6, energy: 58638.1090\n",
      "iter  7, energy: 60122.8120\n",
      "iter  8, energy: 60926.6214\n",
      "iter  9, energy: 62036.9521\n",
      "iter 10, energy: 63402.6432\n",
      "iter 11, energy: 64731.4470\n",
      "iter 12, energy: 65990.9759\n",
      "optimisation time: 1520.59 secs\n",
      "Performing the predictions\n",
      "mae is 0.1364812745751909 \n",
      "\n",
      "NEW ITERATION WITH t: 37691\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 55404.3324\n",
      "iter  2, energy: 54381.2190\n",
      "iter  3, energy: 55191.3556\n",
      "iter  4, energy: 57013.8928\n",
      "iter  5, energy: 56655.8713\n",
      "iter  6, energy: 57149.7367\n",
      "iter  7, energy: 58951.3590\n",
      "iter  8, energy: 59548.7175\n",
      "iter  9, energy: 60584.7492\n",
      "iter 10, energy: 61955.8565\n",
      "iter 11, energy: 63312.3022\n",
      "iter 12, energy: 64590.4488\n",
      "optimisation time: 1315.70 secs\n",
      "Performing the predictions\n",
      "mae is 0.13980138077407803 \n",
      "\n",
      "NEW ITERATION WITH t: 37790\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 54819.3107\n",
      "iter  2, energy: 53678.7767\n",
      "iter  3, energy: 54429.5224\n",
      "iter  4, energy: 56223.7254\n",
      "iter  5, energy: 55887.9175\n",
      "iter  6, energy: 56360.3282\n",
      "iter  7, energy: 57948.8945\n",
      "iter  8, energy: 58673.6463\n",
      "iter  9, energy: 59797.6855\n",
      "iter 10, energy: 61226.0716\n",
      "iter 11, energy: 62609.2717\n",
      "iter 12, energy: 63918.3368\n",
      "optimisation time: 1267.95 secs\n",
      "Performing the predictions\n",
      "mae is 0.25458931074233987 \n",
      "\n",
      "NEW ITERATION WITH t: 37938\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 51682.4865\n",
      "iter  2, energy: 53951.6803\n",
      "iter  3, energy: 57024.5408\n",
      "iter  4, energy: 57363.2410\n",
      "iter  5, energy: 56606.5609\n",
      "iter  6, energy: 57653.1751\n",
      "iter  7, energy: 58183.6438\n",
      "iter  8, energy: 58845.5114\n",
      "iter  9, energy: 60101.0982\n",
      "iter 10, energy: 61188.7808\n",
      "iter 11, energy: 62526.6557\n",
      "iter 12, energy: 63777.9012\n",
      "optimisation time: 1297.81 secs\n",
      "Performing the predictions\n",
      "mae is 0.20367987317599368 \n",
      "\n",
      "NEW ITERATION WITH t: 38037\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 52495.7233\n",
      "iter  2, energy: 51196.8861\n",
      "iter  3, energy: 52070.6198\n",
      "iter  4, energy: 52738.9991\n",
      "iter  5, energy: 53517.1346\n",
      "iter  6, energy: 53991.1363\n",
      "iter  7, energy: 55199.0092\n",
      "iter  8, energy: 56618.7322\n",
      "iter  9, energy: 58133.4227\n",
      "iter 10, energy: 59723.8275\n",
      "iter 11, energy: 61262.5678\n",
      "iter 12, energy: 62667.5442\n",
      "optimisation time: 1301.86 secs\n",
      "Performing the predictions\n",
      "mae is 0.23061856973219208 \n",
      "\n",
      "NEW ITERATION WITH t: 38136\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 52864.3723\n",
      "iter  2, energy: 52026.9146\n",
      "iter  3, energy: 52651.9221\n",
      "iter  4, energy: 54188.3784\n",
      "iter  5, energy: 54270.2735\n",
      "iter  6, energy: 54674.0995\n",
      "iter  7, energy: 55692.8372\n",
      "iter  8, energy: 56915.5453\n",
      "iter  9, energy: 58230.4619\n",
      "iter 10, energy: 59624.1642\n",
      "iter 11, energy: 61042.7198\n",
      "iter 12, energy: 62354.7573\n",
      "optimisation time: 57859.42 secs\n",
      "Performing the predictions\n",
      "mae is 0.25448433069896925 \n",
      "\n",
      "NEW ITERATION WITH t: 38235\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n",
      "iter  1, energy: 52260.8552\n",
      "iter  2, energy: 51237.8138\n",
      "iter  3, energy: 51768.4597\n",
      "iter  4, energy: 53276.0035\n",
      "iter  5, energy: 53519.0518\n",
      "iter  6, energy: 53967.9443\n",
      "iter  7, energy: 54827.0639\n",
      "iter  8, energy: 56085.8394\n",
      "iter  9, energy: 57435.9096\n",
      "iter 10, energy: 58928.9129\n",
      "iter 11, energy: 60377.5783\n",
      "iter 12, energy: 61705.1198\n",
      "optimisation time: 1635.47 secs\n",
      "Performing the predictions\n",
      "mae is 0.23743043130376548 \n",
      "\n",
      "NEW ITERATION WITH t: 38334\n",
      "TRAIN SIZE IS: t_train_CV: (9700, 1), R_train_scaled_CV: (9700, 27, 3), Y_train_CV :(9700, 27)\n",
      "TEST SIZE IS: t_test_CV: (24, 1), R_test_scaled_CV: (24, 27, 3), Y_test_CV :(24, 27)\n",
      "Warm starting the training\n",
      "BEGIN TRAINING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         reduced_train_op(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m     loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_kl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter \u001b[39m\u001b[38;5;132;01m%2d\u001b[39;00m\u001b[38;5;124m, energy: \u001b[39m\u001b[38;5;132;01m%1.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i, loss[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     77\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Desktop/MSc Project/BayesNewtonPVE/bayesnewton/basemodels.py:659\u001b[0m, in \u001b[0;36mMarkovGaussianProcess.compute_kl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03mKL[q()|p()]\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    658\u001b[0m pseudo_y, pseudo_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_full_pseudo_lik()\n\u001b[0;32m--> 659\u001b[0m log_lik_pseudo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_log_lik\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpseudo_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpseudo_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m expected_density_pseudo \u001b[38;5;241m=\u001b[39m vmap(gaussian_expected_log_lik)(  \u001b[38;5;66;03m# parallel operation\u001b[39;00m\n\u001b[1;32m    662\u001b[0m     pseudo_y,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_mean\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_pseudo_y\n\u001b[1;32m    667\u001b[0m )\n\u001b[1;32m    669\u001b[0m kl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(expected_density_pseudo) \u001b[38;5;241m-\u001b[39m log_lik_pseudo  \u001b[38;5;66;03m# KL[approx_post || prior]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MSc Project/BayesNewtonPVE/bayesnewton/basemodels.py:679\u001b[0m, in \u001b[0;36mMarkovGaussianProcess.compute_log_lik\u001b[0;34m(self, pseudo_y, pseudo_var)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pseudo_y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    677\u001b[0m     pseudo_y, pseudo_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_full_pseudo_lik()\n\u001b[0;32m--> 679\u001b[0m log_lik_pseudo, (_, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpseudo_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpseudo_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_pseudo_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_lik_pseudo\n",
      "File \u001b[0;32m~/Desktop/MSc Project/BayesNewtonPVE/bayesnewton/basemodels.py:603\u001b[0m, in \u001b[0;36mMarkovGaussianProcess.filter\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkalman_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MSc Project/BayesNewtonPVE/bayesnewton/ops.py:304\u001b[0m, in \u001b[0;36mkalman_filter\u001b[0;34m(dt, kernel, y, noise_cov, mask, parallel, return_predict)\u001b[0m\n\u001b[1;32m    302\u001b[0m     ell, means, covs \u001b[38;5;241m=\u001b[39m _parallel_kf(As, Qs, H, y, noise_cov, minf, Pinf, mask, return_predict\u001b[38;5;241m=\u001b[39mreturn_predict)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     ell, means, covs \u001b[38;5;241m=\u001b[39m \u001b[43m_sequential_kf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPinf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ell, (means, covs)\n",
      "File \u001b[0;32m~/Desktop/MSc Project/BayesNewtonPVE/bayesnewton/ops.py:197\u001b[0m, in \u001b[0;36m_sequential_kf\u001b[0;34m(As, Qs, H, ys, noise_covs, m0, P0, masks, return_predict)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (m, P, ell), (m, P)\n\u001b[0;32m--> 197\u001b[0m (_, _, loglik), (fms, fPs) \u001b[38;5;241m=\u001b[39m \u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_covs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglik, fms, fPs\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lax/control_flow.py:1635\u001b[0m, in \u001b[0;36mscan\u001b[0;34m(f, init, xs, length, reverse, unroll)\u001b[0m\n\u001b[1;32m   1628\u001b[0m in_flat, jaxpr, consts, out_tree, out_tree_children \u001b[38;5;241m=\u001b[39m rest\n\u001b[1;32m   1630\u001b[0m _check_tree_and_avals(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan carry output and input\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1631\u001b[0m                       \u001b[38;5;66;03m# Extract the subtree and avals for the first element of the return tuple\u001b[39;00m\n\u001b[1;32m   1632\u001b[0m                       out_tree_children[\u001b[38;5;241m0\u001b[39m], carry_avals_out,\n\u001b[1;32m   1633\u001b[0m                       init_tree, carry_avals)\n\u001b[0;32m-> 1635\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mscan_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_consts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_carry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minit_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlinear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m                  \u001b[49m\u001b[43munroll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munroll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, out)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lax/control_flow.py:2212\u001b[0m, in \u001b[0;36mscan_bind\u001b[0;34m(*args, **params)\u001b[0m\n\u001b[1;32m   2210\u001b[0m   _scan_typecheck(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39mavals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m   2211\u001b[0m   core\u001b[38;5;241m.\u001b[39mcheck_jaxpr(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaxpr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mjaxpr)\n\u001b[0;32m-> 2212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAxisPrimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscan_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/core.py:2029\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2025\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2026\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2027\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2028\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/core.py:275\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 275\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/core.py:591\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 591\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/dispatch.py:94\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m compiled_fun \u001b[38;5;241m=\u001b[39m xla_primitive_callable(prim, \u001b[38;5;241m*\u001b[39munsafe_map(arg_spec, args),\n\u001b[1;32m     93\u001b[0m                                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/dispatch.py:444\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, output_buffer_counts, result_handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    441\u001b[0m device, \u001b[38;5;241m=\u001b[39m compiled\u001b[38;5;241m.\u001b[39mlocal_devices()\n\u001b[1;32m    442\u001b[0m input_bufs \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[1;32m    443\u001b[0m     device_put(x, device) \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m kept_var_idx)\n\u001b[0;32m--> 444\u001b[0m out_bufs \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m check_special(name, out_bufs)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_buffer_counts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(f'Getting results for Gaussian Process')\n",
    "\n",
    "errors = np.zeros((24, 1))\n",
    "NNLs = np.zeros((24, 1))\n",
    "\n",
    "forecast_size = 24\n",
    "for t_idx in range_idx: \n",
    "    print('NEW ITERATION WITH t:',t_idx)\n",
    "        \n",
    "    t_iter, R_iter, Y_iter = t[t_idx:t_idx+length_window + 24], R_scaled[t_idx:t_idx+length_window + 24], Y[t_idx:t_idx+length_window + 24]    \n",
    "    t_train_CV, R_train_scaled_CV, Y_train_CV = t_iter[:length_window] , R_iter[:length_window] , Y_iter[:length_window]  \n",
    "    t_test_CV, R_test_scaled_CV, Y_test_CV = t_iter[length_window:] , R_iter[length_window:] , Y_iter[length_window:]  \n",
    "    print(f'TRAIN SIZE IS: t_train_CV: {t_train_CV.shape}, R_train_scaled_CV: {R_train_scaled_CV.shape}, Y_train_CV :{Y_train_CV.shape}')\n",
    "    print(f'TEST SIZE IS: t_test_CV: {t_test_CV.shape}, R_test_scaled_CV: {R_test_scaled_CV.shape}, Y_test_CV :{Y_test_CV.shape}')\n",
    "\n",
    "    #IF WE ARE IN THE FIRST ITERATION\n",
    "    if t_idx == range_idx[0]:\n",
    "        \n",
    "        kern = kerns.get_periodic_kernel(variance_period = VAR_PERIOD, \n",
    "                                         variance_matern = VAR_MATERN, \n",
    "                                         lengthscale_time_period = LEN_PERIOD, \n",
    "                                         lengthscale_time_matern = LEN_MATERN,\n",
    "                                           lengthscale_space=[LEN_SPACE, LEN_SPACE, LEN_SPACE], #[LEN_SPACE, LEN_SPACE, LEN_ALTITUDE]\n",
    "                                           z=z,\n",
    "                                           sparse=SPARSE,\n",
    "                                           opt_z=OPT_Z,\n",
    "                                           conditional='Full',\n",
    "                                           matern_order = '32',\n",
    "                                           order= 2)\n",
    "\n",
    "        lik = bayesnewton.likelihoods.Beta(scale = BETA_SCALE, fix_scale=False, link='probit')\n",
    "    \n",
    "    model = bayesnewton.models.MarkovVariationalGP(kernel = kern, likelihood = lik, X=t_train_CV, Y=Y_train_CV, R=R_train_scaled_CV)\n",
    "    \n",
    "    #IF WE ARE NOT IN THE FIRST ITERATION, WARM-START THE TRAINING\n",
    "    if t_idx != range_idx[0]:\n",
    "        print('Warm starting the training')\n",
    "        #HERE I AM SUBSTITUTING THE PREDICTIONS ETC FROM THE MODEL IN THE TRAINING LOCATIONS\n",
    "        for key in model.vars().keys():\n",
    "            if model.vars()[key].shape  == ():\n",
    "                continue\n",
    "            else:\n",
    "                if model.vars()[key].shape[0] == len(t_train_CV):\n",
    "                    shared_var = model.vars()[key] \n",
    "                    init_array = jax.numpy.pad(previous_model.vars()[key][iter_step:], ((0,iter_step), (0,0), (0,0)))\n",
    "                    shared_var.assign(init_array) \n",
    "\n",
    "    \n",
    "    opt_hypers = objax.optimizer.Adam(model.vars())\n",
    "    energy = objax.GradValues(model.energy, model.vars())\n",
    "    \n",
    "    @objax.Function.with_vars(model.vars() + opt_hypers.vars())\n",
    "    def train_op(batch_ind = None):\n",
    "        model.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "        dE, E = energy()  # compute energy and its gradients w.r.t. hypers\n",
    "        opt_hypers(LR_ADAM, dE)\n",
    "    train_op = objax.Jit(train_op)\n",
    "\n",
    "    @objax.Function.with_vars(model.vars())\n",
    "    def reduced_train_op(batch_ind = None):\n",
    "        model.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "    reduced_train_op = objax.Jit(reduced_train_op)\n",
    "\n",
    "    print('BEGIN TRAINING')\n",
    "    t0 = time.time()\n",
    "    loss = []\n",
    "    #DOING HALF THE ITERATIONS WHEN UPDATING THE MODEL\n",
    "    iterations_n = ITERS if t_idx == range_idx[0] else int(ITERS/2) \n",
    "    for i in range(1, iterations_n + 1):\n",
    "        if t_idx == range_idx[0]:\n",
    "            train_op(None)\n",
    "        else:\n",
    "            reduced_train_op(None)\n",
    "        loss.append(model.compute_kl().item())\n",
    "        print('iter %2d, energy: %1.4f' % (i, loss[i-1]))\n",
    "    t1 = time.time()\n",
    "    print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "    \n",
    "    print('Performing the predictions')\n",
    "    #GET THE SYSTEM SPECIFIC PREDICTIONS (NOT THE TOTAL INTERPOLATION)\n",
    "\n",
    "    f_mean, f_var = model.predict(X=t_test_CV, R=R_test_scaled_CV)\n",
    "\n",
    "    #################GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "    f_mean = f_mean.reshape(f_mean.shape[0], -1, 1)\n",
    "    f_var = f_var.reshape(f_var.shape[0], -1, 1)\n",
    "\n",
    "    mean_y, var_y = vmap(model.likelihood.predict, (0, 0, None))(f_mean, f_var, None)\n",
    "    posterior_mean_ts, posterior_var_ts = np.squeeze(mean_y), np.squeeze(var_y)\n",
    "    \n",
    "    \n",
    "    ################## DELETE ANY PREDICTION THAT IS ALL 0.5 at 2 S.F.\n",
    "    faulty_systems_idx = np.where((round(posterior_mean_ts, 2) == 0.5).all(axis=0))\n",
    "    posterior_mean_ts = posterior_mean_ts.at[:, faulty_systems_idx].set(np.nan)\n",
    "\n",
    "    ##################GET THE ERRORS\n",
    "    error = np.nanmean(abs(np.squeeze(Y_test_CV) - np.squeeze(posterior_mean_ts)), axis=1)[:, np.newaxis]\n",
    "    print(f'mae is {error.mean()} \\n')\n",
    "    \n",
    "    errors = np.concatenate((errors, error), axis=1)  \n",
    "    \n",
    "    #################### GET THE NNL\n",
    "    \n",
    "    #SAMPLE THE LATENT VARIABLE AND GET THE SAMPLED DISTRIBUTIONS\n",
    "    N_samples = 1000\n",
    "    #Sample values of f at each point\n",
    "    sampled_f = np.random.normal(f_mean[:,:,0], f_var[:,:,0], size=(N_samples, f_var.shape[0], f_var.shape[1]))\n",
    "\n",
    "    alpha_sampled = model.likelihood.link_fn(sampled_f) * model.likelihood.scale\n",
    "    beta_sampled = model.likelihood.scale - alpha_sampled\n",
    "\n",
    "    #GET THE NEGATIVE LOG LIKELIHOOD GIVEN THE SAMPLED DISTRIBUTION AND THE OBSERVED Y VALUES\n",
    "    observed_repeated = np.repeat(Y_test_CV[np.newaxis, :, :], N_samples, axis=0)\n",
    "    observed_repeated = observed_repeated.at[observed_repeated==0].set(10e-6)\n",
    "    likelihoods = beta.pdf(observed_repeated,  alpha_sampled, beta_sampled)\n",
    "    NNL_hsteps = -np.sum(np.log(likelihoods.mean(axis=0)), axis=1)[:, np.newaxis]\n",
    "    \n",
    "    NNLs = np.concatenate((NNLs, NNL_hsteps), axis=1)  \n",
    "\n",
    "    #####################\n",
    "    \n",
    "    previous_model = model\n",
    "    \n",
    "    del t_iter, R_iter, Y_iter, t_train_CV, R_train_scaled_CV, Y_train_CV, t_test_CV, R_test_scaled_CV, Y_test_CV\n",
    "    del NNL_hsteps, observed_repeated, beta_sampled, alpha_sampled, sampled_f, error, posterior_mean_ts, posterior_var_ts\n",
    "    del mean_y, var_y, f_mean, f_var, #model\n",
    "    \n",
    "error_evolution = errors[:, 1:].mean(axis=0)\n",
    "MAE_hsteps = errors[:, 1:].mean(axis=1)\n",
    "NNLs_hsteps = np.quantile(NNLs[:, 1:], 0.5, axis=1)\n",
    "NNLs_hsteps_upper = np.quantile(NNLs[:, 1:], 0.975,  axis=1)\n",
    "NNLs_hsteps_lower = np.quantile(NNLs[:, 1:], 0.025,  axis=1)\n",
    "\n",
    "\n",
    "error_evolution = pd.DataFrame(error_evolution).rename(columns ={0:'error_evolution'} )\n",
    "MAE_hsteps = pd.DataFrame(MAE_hsteps).rename(columns ={0:'MAE_hsteps'} )\n",
    "NNLs_hsteps = pd.DataFrame(NNLs_hsteps).rename(columns ={0:'NNLs_hsteps'} )\n",
    "\n",
    "# wandb.log({\"error_evolution\": error_evolution,  \"MAE_hsteps\": MAE_hsteps, \"NNLs_hsteps\": NNLs_hsteps})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f30efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS TO PLOT THE PREDICTIONS FROM THE MODEL ITERATION\n",
    "\n",
    "t_iter, R_iter, Y_iter = t[t_idx:t_idx+length_window + 24], R_scaled[t_idx:t_idx+length_window + 24], Y[t_idx:t_idx+length_window + 24]    \n",
    "t_train_CV, R_train_scaled_CV, Y_train_CV = t_iter[:length_window] , R_iter[:length_window] , Y_iter[:length_window]  \n",
    "t_test_CV, R_test_scaled_CV, Y_test_CV = t_iter[length_window:] , R_iter[length_window:] , Y_iter[length_window:]  \n",
    "\n",
    "f_mean, f_var = model.predict(X=t_iter[-500:], R=R_iter[-500:])\n",
    "\n",
    "#################GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean = f_mean.reshape(f_mean.shape[0], -1, 1)\n",
    "f_var = f_var.reshape(f_var.shape[0], -1, 1)\n",
    "\n",
    "mean_y, var_y = vmap(model.likelihood.predict, (0, 0, None))(f_mean, f_var, None)\n",
    "posterior_mean_ts, posterior_var_ts = np.squeeze(mean_y), np.squeeze(var_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_mode(alpha, beta):\n",
    "    '''\n",
    "    Calcualte the mode of the beta distribution given values of alpha and beta\n",
    "    \n",
    "    Use:\n",
    "    (𝑎−1)/(𝑎+𝑏−2)=𝑚𝑜𝑑𝑒\n",
    "    '''\n",
    "    \n",
    "    return (alpha - 1) / (alpha + beta - 2)\n",
    "\n",
    "\n",
    "#Sample values of f at each point\n",
    "sampled_f = np.random.normal(f_mean[:,:,0], f_var[:,:,0], size=(500, f_var.shape[0], f_var.shape[1]))\n",
    "\n",
    "alpha_sampled = model.likelihood.link_fn(sampled_f) * model.likelihood.scale\n",
    "beta_sampled = model.likelihood.scale - alpha_sampled\n",
    "\n",
    "beta_samples = np.random.beta(alpha_sampled, beta_sampled, size=(alpha_sampled.shape[0], alpha_sampled.shape[1], alpha_sampled.shape[2]))\n",
    "lower_bounds_beta_MC = np.quantile(beta_samples, 0.01, axis=0)\n",
    "upper_bounds_beta_MC = np.quantile(beta_samples, 0.99, axis=0)\n",
    "median_MC = np.quantile(beta_samples, 0.5, axis=0)\n",
    "\n",
    "bounds_90_beta_MC = np.quantile(beta_samples, 0.90, axis=0)\n",
    "bounds_10_beta_MC = np.quantile(beta_samples, 0.10, axis=0)\n",
    "\n",
    "mode_beta_MC = beta_mode(alpha_sampled, beta_sampled).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8cb86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = 500\n",
    "\n",
    "for i in range(SYSTEMS_NUM)[:50]:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "\n",
    "    plt.plot(np.arange(len(Y_iter[-history:])), Y_iter[-history:,i], \"xk\", label='Ground truth')\n",
    "    plt.plot(np.arange(len(Y_iter[-history:])), posterior_mean_ts[-history:,i], c=\"C0\", lw=2, zorder=2, label='posterior mean')\n",
    "    plt.plot(np.arange(len(Y_iter[-history:])), median_MC[-history:,i], c=\"red\", lw=2, zorder=2, alpha = 0.5, label='sampled posterior median')\n",
    "#     plt.plot(np.arange(len(Y_iter[-history:])), mode_beta_MC[-history:,i], c=\"orange\", lw=2, zorder=2, alpha = 0.5, linestyle='-.', label='sampled posterior mode')\n",
    "\n",
    "    \n",
    "    plt.vlines(np.arange(len(Y_iter[-history:]))[-24], 0, max(Y_iter[-history:,i].max().item(), upper_bounds_beta_MC[-history:,i].max().item())+0.1, colors='k')\n",
    "\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y_iter[-history:])),\n",
    "        lower_bounds_beta_MC[-history:,i],\n",
    "        upper_bounds_beta_MC[-history:,i],\n",
    "        color=\"C1\",\n",
    "        alpha=0.2,\n",
    "        label = '1-99 quantiles')\n",
    "    \n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y_iter[-history:])),\n",
    "        bounds_10_beta_MC[-history:,i],\n",
    "        bounds_90_beta_MC[-history:,i],\n",
    "        color=\"green\",\n",
    "        alpha=0.4,\n",
    "        label = '10-90 quantiles')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel('time-step')\n",
    "    plt.ylabel('PVE Capacity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################GET THE ERRORS\n",
    "# error = np.nanmean(abs(np.squeeze(Y_test_CV) - np.squeeze(posterior_mean_ts)), axis=1)[:, np.newaxis]\n",
    "# print(f'mae is {error.mean()} \\n')\n",
    "\n",
    "# errors = np.concatenate((errors, error), axis=1)  \n",
    "\n",
    "# #################### GET THE NNL\n",
    "\n",
    "# #SAMPLE THE LATENT VARIABLE AND GET THE SAMPLED DISTRIBUTIONS\n",
    "# N_samples = 1000\n",
    "# #Sample values of f at each point\n",
    "# sampled_f = np.random.normal(f_mean[:,:,0], f_var[:,:,0], size=(N_samples, f_var.shape[0], f_var.shape[1]))\n",
    "\n",
    "# alpha_sampled = model.likelihood.link_fn(sampled_f) * model.likelihood.scale\n",
    "# beta_sampled = model.likelihood.scale - alpha_sampled\n",
    "\n",
    "# #GET THE NEGATIVE LOG LIKELIHOOD GIVEN THE SAMPLED DISTRIBUTION AND THE OBSERVED Y VALUES\n",
    "# observed_repeated = np.repeat(Y_test_CV[np.newaxis, :, :], N_samples, axis=0)\n",
    "# observed_repeated = observed_repeated.at[observed_repeated==0].set(10e-6)\n",
    "# likelihoods = beta.pdf(observed_repeated,  alpha_sampled, beta_sampled)\n",
    "# NNL_hsteps = -np.sum(np.log(likelihoods.mean(axis=0)), axis=1)[:, np.newaxis]\n",
    "\n",
    "# NNLs = np.concatenate((NNLs, NNL_hsteps), axis=1)  \n",
    "\n",
    "# #####################\n",
    "\n",
    "# previous_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3459baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(NNLs_hsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13db7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20384f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MAE_hsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(NNLs_hsteps).rename(columns ={0:'NNLs_hsteps'} ).to_csv('NNLs_hsteps')\n",
    "pd.DataFrame(error_evolution).rename(columns ={0:'error_evolution'} ).to_csv('error_evolution')\n",
    "pd.DataFrame(MAE_hsteps).rename(columns ={0:'MAE_hsteps'} ).to_csv('MAE_hsteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_iter, R_iter, Y_iter = t[t_idx:t_idx+length_window + 24], R_scaled[t_idx:t_idx+length_window + 24], Y[t_idx:t_idx+length_window + 24]    \n",
    "t_train_CV, R_train_scaled_CV, Y_train_CV = t_iter[:length_window] , R_iter[:length_window] , Y_iter[:length_window]  \n",
    "t_test_CV, R_test_scaled_CV, Y_test_CV = t_iter[length_window:] , R_iter[length_window:] , Y_iter[length_window:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39978f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE SYSTEM SPECIFIC PREDICTIONS (NOT THE TOTAL INTERPOLATION)\n",
    "len_samples = len(t_test_CV) + 50\n",
    "test_mask_shortened = test_mask[-len_samples:]\n",
    "\n",
    "f_mean, f_var = model.predict(X=t[-len_samples:], R=R_scaled[-len_samples:])\n",
    "\n",
    "#GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean = f_mean.reshape(f_mean.shape[0], -1, 1)\n",
    "f_var = f_var.reshape(f_var.shape[0], -1, 1)\n",
    "\n",
    "mean_y, var_y = vmap(model.likelihood.predict, (0, 0, None))(f_mean, f_var, None)\n",
    "posterior_mean_ts, posterior_var_ts = np.squeeze(mean_y), np.squeeze(var_y)\n",
    "\n",
    "#GET THE ERRORS\n",
    "print(f'testing using the next {len(Y[-len_samples:][test_mask_shortened])} datapoints')\n",
    "error = np.nanmean(abs(np.squeeze(Y[-len_samples:][test_mask_shortened]) - np.squeeze(posterior_mean_ts[test_mask_shortened])), axis=1)\n",
    "print(f'mae is {error}')\n",
    "\n",
    "# errors = np.concatenate((errors, error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2e555",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#GET THE SYSTEM SPECIFIC PREDICTIONS (NOT THE TOTAL INTERPOLATION)\n",
    "len_samples = len(t_test) + 500\n",
    "test_mask_shortened = test_mask[-len_samples:]\n",
    "\n",
    "f_mean, f_var = model.predict(X=t[-len_samples:], R=R_scaled[-len_samples:])\n",
    "\n",
    "#GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean = f_mean.reshape(f_mean.shape[0], -1, 1)\n",
    "f_var = f_var.reshape(f_var.shape[0], -1, 1)\n",
    "\n",
    "mean_y, var_y = vmap(model.likelihood.predict, (0, 0, None))(f_mean, f_var, None)\n",
    "posterior_mean_ts, posterior_var_ts = np.squeeze(mean_y), np.squeeze(var_y)\n",
    "\n",
    "t1 = time.time()\n",
    "print('prediction time: %2.2f secs' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16de01e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#GET THE PREDICTION INTERVALS AND CALCULATE ERRORS\n",
    "\n",
    "posterior_pos_twostd_rescaled = posterior_mean_ts + 1.96 * np.sqrt(posterior_var_ts)\n",
    "posterior_neg_twostd_rescaled = posterior_mean_ts - 1.96 * np.sqrt(posterior_var_ts)\n",
    "\n",
    "rescaled_Y = (Y ) #* capacities)\n",
    "rescaled_posterior = posterior_mean_ts#) #* capacities\n",
    "\n",
    "#adjust this for the correct quantities\n",
    "mae = np.nanmean(abs(np.squeeze(rescaled_Y[-len_samples:]) - np.squeeze(rescaled_posterior)))\n",
    "print(f'The MAE is {mae.round(3)}')\n",
    "\n",
    "mae_train = np.nanmean(abs(np.squeeze(rescaled_Y[-len_samples:][~test_mask_shortened]) - np.squeeze(rescaled_posterior[~test_mask_shortened])))\n",
    "print(f'The train MAE is {mae_train.round(3)}')\n",
    "\n",
    "mae_test = np.nanmean(abs(np.squeeze(rescaled_Y[-len_samples:][test_mask_shortened]) - np.squeeze(rescaled_posterior[test_mask_shortened])), axis=1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(mae_test)\n",
    "plt.title('Error as function of forecast distance for Gaussian Process on validation test')\n",
    "plt.xlabel('Number of steps ahead (5min ticks)')\n",
    "plt.ylabel('Average MW error')\n",
    "\n",
    "print(f'The average 2 hours test MAE is {mae_test[:24].mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abf5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8eb0b0",
   "metadata": {},
   "source": [
    "# Compare it to the case without warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST INITIALISE A SECOND MODEL\n",
    "#THIS INITIALISATION USES THE SAME KERNEL AND LIKELIHOOD!\n",
    "kern3 = kerns.get_periodic_kernel(variance=VAR_F,\n",
    "                                           lengthscale_time=LEN_TIME,\n",
    "                                           lengthscale_space=[LEN_SPACE, LEN_SPACE],\n",
    "                                           z=z,\n",
    "                                           sparse=SPARSE,\n",
    "                                           opt_z=OPT_Z,\n",
    "                                           conditional='FIC')\n",
    "\n",
    "lik3 = bayesnewton.likelihoods.Beta(scale = 30, fix_scale=False, link='probit')\n",
    "model3 = bayesnewton.models.MarkovVariationalGP(kernel = kern3, likelihood = lik3, X=t, Y=Y, R=R_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ef4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_hypers3 = objax.optimizer.Adam(model3.vars())\n",
    "energy3 = objax.GradValues(model3.energy, model3.vars())\n",
    "\n",
    "@objax.Function.with_vars(model3.vars())\n",
    "def train_op_model3(batch_ind = None):\n",
    "    model3.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "    dE, E = energy3()  # compute energy and its gradients w.r.t. hypers\n",
    "    opt_hypers3(LR_ADAM, dE)\n",
    "train_op_model3 = objax.Jit(train_op_model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bad32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "loss = []\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        if number_of_minibatches > 1:\n",
    "            print(f'Doing minibatch {mini_batch}')\n",
    "        train_op_model3(mini_batches_indices[mini_batch])\n",
    "        loss.append(model3.compute_kl().item())\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[i-1]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e923dc",
   "metadata": {},
   "source": [
    "# IMPLEMENT THE CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68662cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb5b5238",
   "metadata": {},
   "source": [
    "# TESTING JIT AND MINIBATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adfiheg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f12083",
   "metadata": {},
   "source": [
    "## JIT + no minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = None\n",
    "\n",
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bed763",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "t0 = time.time()\n",
    "loss = []\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "#         model.inference(lr=LR_NEWTON, batch_ind = mini_batches_indices[mini_batch])  #perform inference and update variational params\n",
    "        reduced_train_op(mini_batches_indices[mini_batch])\n",
    "        loss.append(model.compute_kl().item())\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[i-1]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c78324",
   "metadata": {},
   "source": [
    "## JIT + Time Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4749a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = 16\n",
    "\n",
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3b175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "t0 = time.time()\n",
    "loss = []\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "#         model.inference(lr=LR_NEWTON, batch_ind = mini_batches_indices[mini_batch])  #perform inference and update variational params\n",
    "        reduced_train_op(mini_batches_indices[mini_batch])\n",
    "        loss.append(model.compute_kl().item())\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[i-1]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c2d5b",
   "metadata": {},
   "source": [
    "## no JIT + time minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = 16\n",
    "\n",
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "t0 = time.time()\n",
    "loss = []\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        model.inference(lr=LR_NEWTON, batch_ind = mini_batches_indices[mini_batch])  #perform inference and update variational params\n",
    "#         reduced_train_op(mini_batches_indices[mini_batch])\n",
    "        loss.append(model.compute_kl().item())\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[i-1]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeca908",
   "metadata": {},
   "source": [
    "## no JIT + no minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = None\n",
    "\n",
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49110d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "t0 = time.time()\n",
    "loss = []\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        model.inference(lr=LR_NEWTON, batch_ind = mini_batches_indices[mini_batch])  #perform inference and update variational params\n",
    "#         reduced_train_op(mini_batches_indices[mini_batch])\n",
    "        loss.append(model.compute_kl().item())\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[i-1]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f5033",
   "metadata": {},
   "source": [
    "## JIT + space minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc03b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a6796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79357a05",
   "metadata": {},
   "source": [
    "## no JIT + space minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660a93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9be80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f5cd90d",
   "metadata": {},
   "source": [
    "# INFINITE HORIZON: ONLINE LEARNING?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206bf0c",
   "metadata": {},
   "source": [
    "## Validation for the model\n",
    "\n",
    "the Kalman filter usually has the following loop:\n",
    "\n",
    "- For i in infinity:\n",
    "    - Get values of t, R (just add one to t and maintain the same R)\n",
    "    - model.predict(X = t, R = R)\n",
    "    - model.some_update_fn(Y = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc0dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_test, var_test = model.predict_y(X = t_test[0:2], R = R_test[0:2])\n",
    "for i in range(2, 50, 2):\n",
    "    mean_test_i, var_test_i = model.predict_y(X = t_test[i:i+5], R = R_test[i:i+5])\n",
    "    mean_test = np.concatenate([mean_test, mean_test_i])\n",
    "    var_test = np.concatenate([var_test, var_test_i])\n",
    "    model.update_posterior()\n",
    "    model.update_variational_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1296b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posterior_mean_ts, posterior_var_ts = model.predict_y(X=t, R=R_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6f995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d190e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.posterior_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693228f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model.posterior_mean\n",
    "model.X = np.append(t_train, t_test[0])\n",
    "model.Y = np.append(Y_train, Y_test[0])\n",
    "model.R = np.append(R_train_scaled, R_test_scaled[0])\n",
    "model.update_posterior()\n",
    "b = model.posterior_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae831113",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a == b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c201e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.posterior_variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bc8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update_variational_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.filter(1, model.kernel, 0.5, model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad6de79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_mean = model.compute_full_pseudo_lik()[0]\n",
    "latent_var = model.compute_full_pseudo_lik()[1]\n",
    "\n",
    "predictive_pseudo = model.likelihood.predict(latent_mean, latent_var, model.mask_pseudo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS METHOD GETS PREDICTIONS DONE \n",
    "\n",
    "# lik = bayesnewton.likelihoods.Gaussian(variance=VAR_Y)\n",
    "# inf = bayesnewton.inference.Taylor\n",
    "# mod = bayesnewton.basemodels.MarkovGP\n",
    "# Mod = bayesnewton.build_model(mod, inf)\n",
    "# model = Mod(kernel=kern, likelihood=lik, X=t_train, Y=Y_train, R=R_train_scaled)\n",
    "\n",
    "# model.inference()\n",
    "# peudo_y = model.compute_full_pseudo_lik()[0]\n",
    "# noise_cov = model.compute_full_pseudo_lik()[1]\n",
    "# model.update_posterior()\n",
    "# log_lik, (filter_mean, filter_cov) = model.filter(model.dt, model.kernel, peudo_y, noise_cov)\n",
    "\n",
    "# filter_mean[:,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904558aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
