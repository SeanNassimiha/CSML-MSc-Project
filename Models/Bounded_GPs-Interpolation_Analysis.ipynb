{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dbb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import bayesnewton\n",
    "import jax\n",
    "import objax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import math   \n",
    "from jax import vmap\n",
    "from scipy.stats import beta\n",
    "\n",
    "\n",
    "import cv2\n",
    "import sys, os\n",
    "sys.path.append('../Utils')\n",
    "import model_utils as mutils\n",
    "import kernels_definitions as kerns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c004eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA VARIABLES\n",
    "SYSTEMS_NUM = 120\n",
    "TIMESTEPS_NUM = 35295  #THIS IS EXACTLY ONE YEAR\n",
    "TRAIN_FRAC = 2  #IF TRAIN_FRAC > 1 THEN IT BECOMES THE LENGTH OF THE TEST SET\n",
    "GRID_PIXELS = 15\n",
    "\n",
    "#OPTIMISATION VARIABLES\n",
    "LR_ADAM =  0.1095990416571735\n",
    "LR_NEWTON = 0.2944896882908768\n",
    "ITERS = 1000\n",
    "\n",
    "#GP Variables\n",
    "VAR_Y = 0.996641303535278\n",
    "LEN_SPACE = 1.1445954129246831\n",
    "\n",
    "#PERIODIC KERNEL\n",
    "VAR_PERIOD = 0.14694909160883585\n",
    "VAR_MATERN = 0.14694909160883585\n",
    "LEN_MATERN = 5\n",
    "\n",
    "#Want to use a sparse approximation\n",
    "SPARSE = True\n",
    "#Should we optimise the inducing points\n",
    "OPT_Z = True  # will be set to False if SPARSE=SPARSE\n",
    "\n",
    "#use a mean field approximation?\n",
    "MEAN_FIELD = False\n",
    "MINI_BATCH_SIZE = None #none if you don't want them\n",
    "TEST_STATIONS = 271 - 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_pv = pd.read_csv('../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "#data_multiple.plot(legend=False)\n",
    "lats = dict(uk_pv.set_index('ss_id')['latitude_noisy'])\n",
    "longs = dict(uk_pv.set_index('ss_id')['longitude_noisy'])\n",
    "\n",
    "data =  pd.read_csv('../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime')\n",
    "#I AM SHUFFLING HERE\n",
    "data_multiple = data.iloc[:,:SYSTEMS_NUM][:TIMESTEPS_NUM].reset_index()\n",
    "stacked = mutils.stack_dataframe(data_multiple, lats, longs)\n",
    "stacked = stacked[(stacked.latitude < 52.5) & (stacked.latitude > 50.5) & (stacked.longitude > -1) & (stacked.longitude < 1)]\n",
    "\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.columns)].set_index('ss_id_string')['kwp'].values * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc04a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(stacked[['epoch', 'longitude', 'latitude']])\n",
    "Y = np.array(stacked[['PV']])\n",
    "\n",
    "from suncalc import get_position, get_times\n",
    "date_solar = stacked.datetime.values\n",
    "lon_solar = stacked.longitude.values\n",
    "lat_solar = stacked.latitude.values\n",
    "\n",
    "solar_positions = get_position(date_solar, lon_solar, lat_solar)\n",
    "solar_altitude = solar_positions['altitude']\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords = convert_bng(X[:, 1], X[:, 2])\n",
    "X = np.vstack([X[:, 0],\n",
    "              np.array(british_national_grid_coords[0]),\n",
    "              np.array(british_national_grid_coords[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n",
    "\n",
    "# solar_altitudes = solar_altitude.reshape(R.shape[1], R.shape[0], 1).swapaxes(0,1)\n",
    "\n",
    "# R = np.append(R, solar_altitudes, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "457fd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/geopandas/array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Grid of initial inducing points')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train test split for 3 dimensional data\n",
    "t_train, t_test, R_train, R_test, Y_train, Y_test = mutils.train_split_3d(t, R, Y, train_frac = TRAIN_FRAC, split_type = 'Cutoff')\n",
    "# Y = Y[:,:,0]\n",
    "\n",
    "#get the mask of the test points\n",
    "test_mask = np.in1d(t.squeeze(), t_test.squeeze())\n",
    "\n",
    "#Scale the data\n",
    "scaled_values = mutils.scale_2d_train_test_data(R, Y, R_train, R_test, Y_train, Y_test )\n",
    "R_scaler, R_scaled, R_train_scaled, R_test_scaled, _, _, _, _ = scaled_values\n",
    "\n",
    "#here get a list of scaled coordinates (frozen because at some point in time)\n",
    "R_scaled_frozen = R_scaled[0]\n",
    "\n",
    "# #Create a grid to perform prediction/interpolation on\n",
    "r1, r2, Rplot = mutils.create_grid_from_coords(R = R_scaled_frozen, t = t, R_scaler = R_scaler, N_pixels = GRID_PIXELS, date_solar = date_solar)\n",
    "\n",
    "# z = R_scaled[2, ...]\n",
    "z = R_scaled[2, ::3]\n",
    "\n",
    "\n",
    "# #CHANGE THE INDUCING POINTS FOR THE SOLAR ALTITUDE TO BE EQUALLY SPACED ALONG THE TOTAL INTERVAL\n",
    "# z[:,2] = np.linspace(solar_altitude.min(),solar_altitude.max(),  len(z))\n",
    "    \n",
    "plt.scatter(*zip(*z[:, ...]), marker='o', s=30, color='red')\n",
    "plt.title('Grid of initial inducing points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "kern = kerns.get_SpatioTemporal_combined(variance = VAR_PERIOD, \n",
    "                                 lengthscale_time = LEN_MATERN,\n",
    "                                   lengthscale_space=[LEN_SPACE, LEN_SPACE], #[LEN_SPACE, LEN_SPACE, LEN_ALTITUDE]\n",
    "                                   z=z,\n",
    "                                   sparse=SPARSE,\n",
    "                                   opt_z=OPT_Z,\n",
    "                                   conditional='Full',\n",
    "                                   matern_order = '12')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEAN_FIELD:\n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 3, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalMeanFieldGP(kernel=kern, likelihood=lik, X=t_train, R=R_train_scaled, Y=Y_train)    \n",
    "else:    \n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 3, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalGP(kernel = kern, likelihood = lik, X=t_train, Y=Y_train, R=R_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_hypers = objax.optimizer.Adam(model.vars())\n",
    "energy = objax.GradValues(model.energy, model.vars())\n",
    "\n",
    "@objax.Function.with_vars(model.vars() + opt_hypers.vars())\n",
    "def train_op(batch_ind = None):\n",
    "    model.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "    dE, E = energy()  # compute energy and its gradients w.r.t. hypers\n",
    "    opt_hypers(LR_ADAM, dE)\n",
    "    return E\n",
    "train_op = objax.Jit(train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1d242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "model_vars = dict.fromkeys(range(ITERS))\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        if number_of_minibatches > 1:\n",
    "            print(f'Doing minibatch {mini_batch}')\n",
    "        loss = train_op(mini_batches_indices[mini_batch])\n",
    "        \n",
    "#         #LOG THE PARAMS\n",
    "#         data_var = [model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).temporal_kernel(Matern12).transformed_lengthscale'].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).temporal_kernel(Matern12).transformed_variance'].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).spatial_kernel(Matern12).transformed_lengthscale'][0].item(),\n",
    "#                 model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).spatial_kernel(Matern12).transformed_lengthscale'][1].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).spatial_kernel(Matern12).transformed_variance'].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).likelihood(Beta).transformed_scale'].item()]\n",
    "\n",
    "#         data_model_vars = copy.copy(data_var)\n",
    "#         model_vars[i] = data_model_vars\n",
    "        \n",
    "        \n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[0]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b1182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate posterior predictive distribution via filtering and smoothing at train & test locations:\n",
    "t0 = time.time()\n",
    "print('calculating the posterior predictive distribution ...')\n",
    "posterior_mean, posterior_var = model.predict_y(X=t, R=Rplot)\n",
    "t1 = time.time()\n",
    "print('prediction time: %2.2f secs' % (t1-t0))\n",
    "\n",
    "t2 = time.time()\n",
    "print('calculating the negative log predictive density ...')\n",
    "nlpd = model.negative_log_predictive_density(X=t_test, R=R_test_scaled, Y=Y_test)\n",
    "t3 = time.time()\n",
    "print('nlpd calculation time: %2.2f secs' % (t3-t2))\n",
    "print('nlpd: %2.3f' % nlpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f458980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z_opt = model.kernel.z.value\n",
    "# # mu = Y_scaler.inverse_transform(posterior_mean.flatten()[:, np.newaxis]).reshape(-1, GRID_PIXELS, GRID_PIXELS)\n",
    "# mu = posterior_mean.reshape(TIMESTEPS_NUM, GRID_PIXELS, GRID_PIXELS)\n",
    "\n",
    "# #get lat-lon coordinates\n",
    "# grid_coord = R_scaler.inverse_transform(np.array(np.c_[r1,r2]))\n",
    "# longitude_grid, latitude_grid =  convert_lonlat(grid_coord[:, 0], grid_coord[:, 1])\n",
    "# longitude_sys_train, latitude_sys_train = convert_lonlat(R_train[:,:,0][0], R_train[:,:,1][0])\n",
    "# longitude_z, latitude_z = convert_lonlat(R_scaler.inverse_transform(z_opt)[:,0], R_scaler.inverse_transform(z_opt)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea771b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_result = False\n",
    "# # del model, kern, Rplot  # , var\n",
    "\n",
    "# print('plotting ...')\n",
    "# cmap = cm.viridis\n",
    "# vmin = np.nanpercentile(Y, 1)\n",
    "# vmax = np.nanpercentile(Y, 99)\n",
    "# #get the labels for the dates\n",
    "# dates = pd.to_datetime(data_multiple.datetime).dt.date\n",
    "# days_index = max(96, int(((len(t) / 5) // 96) * 96)) #number of time intervals to match 5 beginnings of days\n",
    "\n",
    "# for time_step in range(t.shape[0])[:50]:\n",
    "#     f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [20, 1]})\n",
    "#     f.set_figheight(8)\n",
    "#     # f.set_figwidth(8)\n",
    "#     im = a0.imshow(mu[time_step], cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "#                    extent=[longitude_grid[0], longitude_grid[-1], latitude_grid[0], latitude_grid[-1]], origin='lower')\n",
    "#     if SPARSE:\n",
    "#         a0.scatter(longitude_z, latitude_z, c='r', s=60, alpha=0.5)  # plot inducing inputs\n",
    "#     a0.scatter(longitude_sys_train, latitude_sys_train, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "#                c=np.squeeze(Y[time_step]), s=50, edgecolors='black')\n",
    "#     plt.colorbar(im, fraction=0.0348, pad=0.03, aspect=30, ax=a0)\n",
    "    \n",
    "#     a0.set_xlim(longitude_grid[0], longitude_grid[-1])\n",
    "#     a0.set_ylim(latitude_grid[0], latitude_grid[-1])\n",
    "#     a0.set_title(f'PVE at {data_multiple.datetime.unique()[time_step]}')\n",
    "#     a0.set_ylabel('Latitude')\n",
    "#     a0.set_xlabel('Longitude')\n",
    "#     a1.vlines(t[time_step].item(), -1, 1, 'r')\n",
    "#     a1.set_xlabel('time (days)')\n",
    "#     a1.set_xlim(t[0], t[-1])\n",
    "    \n",
    "#     a1.set_xticks(np.asarray(t[1:-1:days_index ][:,0].tolist()), \n",
    "#                   labels = dates[0:-1:days_index].values,\n",
    "#                      fontsize = 10)\n",
    "#     plt.show()\n",
    "#     plt.close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee207de",
   "metadata": {},
   "source": [
    "## Predict on Unseen Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c138f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen = data.iloc[:, SYSTEMS_NUM:SYSTEMS_NUM+TEST_STATIONS][:TIMESTEPS_NUM].reset_index()\n",
    "capacities_unseen = uk_pv[uk_pv.ss_id_string.isin(data_unseen.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "stacked_unseen = mutils.stack_dataframe(data_unseen, lats, longs)\n",
    "stacked_unseen = stacked_unseen[(stacked_unseen.latitude < 52.5) & (stacked_unseen.latitude > 50.5) & (stacked_unseen.longitude > -1) & (stacked_unseen.longitude < 1)]\n",
    "\n",
    "X_unseen = np.array(stacked_unseen[['epoch', 'longitude', 'latitude']])\n",
    "Y_unseen = np.array(stacked_unseen[['PV']])\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords_unseen = convert_bng(X_unseen[:, 1], X_unseen[:, 2])\n",
    "X_unseen = np.vstack([X_unseen[:, 0],\n",
    "              np.array(british_national_grid_coords_unseen[0]),\n",
    "              np.array(british_national_grid_coords_unseen[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R_unseen, Y_unseen = bayesnewton.utils.create_spatiotemporal_grid(X_unseen, Y_unseen)\n",
    "t = t \n",
    "R_unseen_scaled = np.tile(R_scaler.transform(R_unseen[0]), (R_unseen.shape[0],1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean_unseen, f_var_unseen = model.predict(X=t, R=R_unseen_scaled)\n",
    "\n",
    "#CREATE A LOOP SO IT DOESN'T RUN OUT OF MEMORY\n",
    "\n",
    "# f_mean_unseen = []\n",
    "# f_var_unseen = []\n",
    "\n",
    "# for i in range(len(R_unseen_scaled)):\n",
    "#     f_m_un, f_var_un = model.predict(X=t, R=R_unseen_scaled[i])\n",
    "#     f_mean_unseen.append(f_m_un)\n",
    "#     f_var_unseen.uppend(f_var_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_UNSEEN = 100\n",
    "\n",
    "#Sample values of f at each point\n",
    "sampled_f_unseen = np.random.normal(f_mean_unseen, f_var_unseen, size=(N_SAMPLES_UNSEEN, f_var_unseen.shape[0], f_var_unseen.shape[1]))\n",
    "\n",
    "alpha_sampled_unseen = model.likelihood.link_fn(sampled_f_unseen) * model.likelihood.scale\n",
    "beta_sampled_unseen = model.likelihood.scale - alpha_sampled_unseen\n",
    "\n",
    "beta_samples_unseen = np.random.beta(alpha_sampled_unseen, beta_sampled_unseen, size=(alpha_sampled_unseen.shape[0], alpha_sampled_unseen.shape[1], alpha_sampled_unseen.shape[2]))\n",
    "lower_bounds_beta_MC_unseen = np.quantile(beta_samples_unseen, 0.025, axis=0)\n",
    "upper_bounds_beta_MC_unseen = np.quantile(beta_samples_unseen, 0.975, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean_unseen = f_mean_unseen.reshape(f_mean_unseen.shape[0], -1, 1)\n",
    "f_var_unseen = f_var_unseen.reshape(f_var_unseen.shape[0], -1, 1)\n",
    "\n",
    "mean_y_unseen, var_y_unseen = vmap(model.likelihood.predict, (0, 0, None))(f_mean_unseen, f_var_unseen, None)\n",
    "posterior_mean_unseen, posterior_var_unseen = np.squeeze(mean_y_unseen), np.squeeze(var_y_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636c601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_unseen = Y_unseen[:,:,0]\n",
    "\n",
    "#adjust this for the correct quantities\n",
    "mae = np.nanmean(abs(np.squeeze(Y_unseen) - np.squeeze(posterior_mean_unseen)))\n",
    "print(f'The MAE is {mae.round(3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcb37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(posterior_mean_unseen.shape[1]):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "\n",
    "    plt.plot(np.arange(len(Y[:1000])), Y_unseen[:1000,i], \"xk\")\n",
    "    plt.plot(np.arange(len(Y[:1000])), posterior_mean_unseen[:1000,i], c=\"C0\", lw=2, zorder=2)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y[:1000])),\n",
    "        lower_bounds_beta_MC_unseen[:1000,i],\n",
    "        upper_bounds_beta_MC_unseen[:1000,i],\n",
    "        color=\"C2\",\n",
    "        alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cd928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95230c25",
   "metadata": {},
   "source": [
    "## How much would it have produced?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_daily_prod(productions):\n",
    "    '''\n",
    "    Given an array of production data for each system, calculates the average daily production for each system in kWh\n",
    "    '''\n",
    "    n_days = productions.shape[0] / 96\n",
    "    avg_daily_prod = productions.sum(axis=0) / (n_days * 12)\n",
    "    return avg_daily_prod\n",
    "    \n",
    "avg_daily_prod_predicted = calc_avg_daily_prod(posterior_mean_unseen)\n",
    "avg_daily_prod_actual = calc_avg_daily_prod(Y_unseen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da87c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(avg_daily_prod_actual).hist()\n",
    "pd.Series(avg_daily_prod_predicted).hist()\n",
    "plt.show()\n",
    "pd.Series(avg_daily_prod_actual - avg_daily_prod_predicted).hist()\n",
    "MAE_yearly_avg = np.mean(abs(avg_daily_prod_actual - avg_daily_prod_predicted))\n",
    "print(f'The MAE on the average daily kWh over {round(posterior_mean_unseen.shape[0] / 96)} days is {round(MAE_yearly_avg, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250bea9",
   "metadata": {},
   "source": [
    "# Given coordinates and Capacity, how much will it produce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_production(lat, lon, capacity, historical_error, confidence_interval = 0.8):\n",
    "    \n",
    "    R_array_2d = np.array([[lat,lon]]) #[:, np.newaxis]\n",
    "    R_array_2d_scaled = R_scaler.transform(R_array_2d)\n",
    "    R_array_3d_scaled = np.repeat(R_array_2d_scaled, t.shape[0], axis=0)[:, np.newaxis]\n",
    "\n",
    "    #duplicating to avoid issues\n",
    "    mean_pred, var_pred = model.predict(X=t, R=np.repeat(R_array_3d_scaled, 2, axis = 1))\n",
    "    mean_pred, var_pred = mean_pred[:,0], var_pred[:,0]\n",
    "    N_SAMPLES_UNSEEN = 100\n",
    "\n",
    "    #Sample values of f at each point\n",
    "    sampled_f_pred = np.random.normal(mean_pred, var_pred, size=(N_SAMPLES_UNSEEN, var_pred.shape[0]))\n",
    "\n",
    "    alpha_sampled_pred = model.likelihood.link_fn(sampled_f_pred) * model.likelihood.scale\n",
    "    beta_sampled_pred = model.likelihood.scale - alpha_sampled_pred\n",
    "\n",
    "    beta_samples_pred = np.random.beta(alpha_sampled_pred, beta_sampled_pred, size=(alpha_sampled_pred.shape[0], alpha_sampled_pred.shape[1]))\n",
    "    lower_bounds_beta_MC_pred = np.quantile(beta_samples_pred,  (1 - confidence_interval)/2, axis=0)\n",
    "    upper_bounds_beta_MC_pred = np.quantile(beta_samples_pred, 1 -(1 - confidence_interval)/2, axis=0)\n",
    "    \n",
    "    #GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "    f_mean_pred = mean_pred.reshape(mean_pred.shape[0], -1, 1)\n",
    "    f_var_pred = var_pred.reshape(var_pred.shape[0], -1, 1)\n",
    "\n",
    "    mean_y_pred, var_y_pred = vmap(model.likelihood.predict, (0, 0, None))(f_mean_pred, f_var_pred, None)\n",
    "    posterior_mean_pred, posterior_var_pred = np.squeeze(mean_y_pred), np.squeeze(var_y_pred)\n",
    "    \n",
    "    avg_daily_prod_pred = calc_avg_daily_prod(posterior_mean_pred).item()\n",
    "    avg_daily_prod_pred_kWh = avg_daily_prod_pred * capacity\n",
    "    \n",
    "    avg_daily_prod_pred_lower = calc_avg_daily_prod(lower_bounds_beta_MC_pred).item()\n",
    "    avg_daily_prod_pred_kWh_lower = avg_daily_prod_pred_lower * capacity\n",
    "    \n",
    "    avg_daily_prod_pred_upper = calc_avg_daily_prod(upper_bounds_beta_MC_pred).item()\n",
    "    avg_daily_prod_pred_kWh_upper = avg_daily_prod_pred_upper * capacity\n",
    "    \n",
    "    #GET THE UNCERTAINTIES, GIVEN BOTH BY THE UNCETAINTY BARS BUT ALSO BY THE ERRORS IN THE TEST SET\n",
    "    \n",
    "    print(lower_bounds_beta_MC_pred.shape)\n",
    "    \n",
    "    error = historical_error * capacity\n",
    "    \n",
    "    return avg_daily_prod_pred_kWh, error, avg_daily_prod_pred_kWh_lower, avg_daily_prod_pred_kWh_upper\n",
    "\n",
    "cap = 0.2\n",
    "lat = 0\n",
    "lon = 52\n",
    "historical_error = MAE_yearly_avg.item()\n",
    "conf = 0.8\n",
    "avg_daily_prod, error, avg_daily_prod_pred_kWh_lower, avg_daily_prod_pred_kWh_upper = estimate_production(lat, lon, cap, historical_error, confidence_interval = conf)\n",
    "print(f'PAST ERROR: The Estimated Average daily production in kWh is {round(avg_daily_prod, 2)} ± {round(error, 2)} for a system of capacity {cap} kW')\n",
    "print(f'GP ERROR: The Estimated Average daily production in kWh is {round(avg_daily_prod, 2)} with {conf * 100}% confidence interval given by [{round(avg_daily_prod_pred_kWh_lower, 2)}, {round(avg_daily_prod_pred_kWh_upper, 2)}] for a system of capacity {cap} kW')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01bde6",
   "metadata": {},
   "source": [
    "# How much did parameters change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c73da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trajectories_transformed = pd.DataFrame(model_vars).T.dropna()\n",
    "param_trajectories_transformed.to_csv('param_trajectories_transformed_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trajectories_transformed = pd.read_csv('param_trajectories_transformed_3.csv').iloc[:, 1:]\n",
    "param_trajectories = np.log(1 + np.exp(param_trajectories_transformed))\n",
    "param_trajectories.columns = ['Temporal Lengthscale', 'Kernel Variance', 'Spatial Lengthscale 1', 'Spatial Lengthscale 2', 'Spatial Variance', 'Beta Scale']\n",
    "param_trajectories = param_trajectories.drop(columns = ['Spatial Variance',  'Spatial Lengthscale 2'])\n",
    "\n",
    "\n",
    "ax = param_trajectories.plot(subplots=True, sharex=True, sharey=False, figsize=(7.5, 14 /1.25 ),  legend = False, fontsize = 15)\n",
    "plt.suptitle('7 Optimised Points \\n', fontsize=20)\n",
    "ax[0].set_title('Temporal Lengthscale', fontsize = 15)\n",
    "ax[1].set_title('Kernel Variance', fontsize = 15)\n",
    "ax[2].set_title('Spatial Lengthscale 1', fontsize = 15)\n",
    "ax[3].set_title('Beta Scale', fontsize = 15)\n",
    "\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "ax[3].grid()\n",
    "\n",
    "ax[0].set_xlabel('Iteration', fontsize = 15)\n",
    "ax[1].set_xlabel('Iteration', fontsize = 15)\n",
    "ax[2].set_xlabel('Iteration', fontsize = 15)\n",
    "ax[3].set_xlabel('Iteration', fontsize = 15)\n",
    "\n",
    "ax[0].set_ylabel('Parameter Value', fontsize = 15)\n",
    "ax[1].set_ylabel('Parameter Value', fontsize = 15)\n",
    "ax[2].set_ylabel('Parameter Value', fontsize = 15)\n",
    "ax[3].set_ylabel('Parameter Value', fontsize = 15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/param_trajectories_3.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4353a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
