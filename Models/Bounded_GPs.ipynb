{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dbb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import bayesnewton\n",
    "import jax\n",
    "import objax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import math   \n",
    "from jax import vmap\n",
    "from scipy.stats import beta\n",
    "\n",
    "\n",
    "import cv2\n",
    "import sys, os\n",
    "sys.path.append('../Utils')\n",
    "import model_utils as mutils\n",
    "import kernels_definitions as kerns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c004eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA VARIABLES\n",
    "SYSTEMS_NUM = 10\n",
    "TIMESTEPS_NUM = 10300\n",
    "TRAIN_FRAC = 200  #IF TRAIN_FRAC > 1 THEN IT BECOMES THE LENGTH OF THE TEST SET\n",
    "GRID_PIXELS = 10\n",
    "\n",
    "#OPTIMISATION VARIABLES\n",
    "LR_ADAM = 0.01\n",
    "LR_NEWTON = 0.5\n",
    "ITERS = 3\n",
    "\n",
    "#GP Variables\n",
    "VAR_Y = 1\n",
    "VAR_F = 1\n",
    "LEN_TIME = 24  # step size = 1 (hour)\n",
    "LEN_SPACE = 0.5\n",
    "LEN_ALTITUDE = 0.3\n",
    "\n",
    "#PERIODIC KERNEL\n",
    "VAR_PERIOD = 1.5\n",
    "VAR_MATERN = 0.3\n",
    "LEN_MATERN = 24\n",
    "LEN_PERIOD = 24 * 6\n",
    "\n",
    "\n",
    "\n",
    "#Want to use a sparse approximation\n",
    "SPARSE = True\n",
    "#Should we optimise the inducing points\n",
    "OPT_Z = False  # will be set to False if SPARSE=SPARSE\n",
    "\n",
    "#use a mean field approximation?\n",
    "MEAN_FIELD = True\n",
    "MINI_BATCH_SIZE = None #none if you don't want them\n",
    "TEST_STATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_pv = pd.read_csv('../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "#data_multiple.plot(legend=False)\n",
    "lats = dict(uk_pv.set_index('ss_id')['latitude_noisy'])\n",
    "longs = dict(uk_pv.set_index('ss_id')['longitude_noisy'])\n",
    "\n",
    "data =  pd.read_csv('../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime')\n",
    "#I AM SHUFFLING HERE\n",
    "data_multiple = data.iloc[:,:SYSTEMS_NUM][:TIMESTEPS_NUM].reset_index()\n",
    "stacked = mutils.stack_dataframe(data_multiple, lats, longs)\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.columns)].set_index('ss_id_string')['kwp'].values * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc04a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(stacked[['epoch', 'longitude', 'latitude']])\n",
    "Y = np.array(stacked[['PV']])\n",
    "\n",
    "from suncalc import get_position, get_times\n",
    "date_solar = stacked.datetime.values\n",
    "lon_solar = stacked.longitude.values\n",
    "lat_solar = stacked.latitude.values\n",
    "\n",
    "solar_positions = get_position(date_solar, lon_solar, lat_solar)\n",
    "solar_altitude = solar_positions['altitude']\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords = convert_bng(X[:, 1], X[:, 2])\n",
    "X = np.vstack([X[:, 0],\n",
    "              np.array(british_national_grid_coords[0]),\n",
    "              np.array(british_national_grid_coords[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n",
    "\n",
    "# solar_altitudes = solar_altitude.reshape(R.shape[1], R.shape[0], 1).swapaxes(0,1)\n",
    "\n",
    "# R = np.append(R, solar_altitudes, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457fd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/geopandas/array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Grid of initial inducing points')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train test split for 3 dimensional data\n",
    "t_train, t_test, R_train, R_test, Y_train, Y_test = mutils.train_split_3d(t, R, Y, train_frac = TRAIN_FRAC, split_type = 'Cutoff')\n",
    "Y = Y[:,:,0]\n",
    "\n",
    "#get the mask of the test points\n",
    "test_mask = np.in1d(t.squeeze(), t_test.squeeze())\n",
    "\n",
    "#Scale the data\n",
    "scaled_values = mutils.scale_2d_train_test_data(R, Y, R_train, R_test, Y_train, Y_test )\n",
    "R_scaler, R_scaled, R_train_scaled, R_test_scaled, _, _, _, _ = scaled_values\n",
    "\n",
    "#here get a list of scaled coordinates (frozen because at some point in time)\n",
    "R_scaled_frozen = R_scaled[0]\n",
    "\n",
    "# #Create a grid to perform prediction/interpolation on\n",
    "r1, r2, Rplot = mutils.create_grid_from_coords(R = R_scaled_frozen, t = t, R_scaler = R_scaler, N_pixels = GRID_PIXELS, date_solar = date_solar)\n",
    "\n",
    "z = R_scaled[2, ...]\n",
    "\n",
    "# #CHANGE THE INDUCING POINTS FOR THE SOLAR ALTITUDE TO BE EQUALLY SPACED ALONG THE TOTAL INTERVAL\n",
    "# z[:,2] = np.linspace(solar_altitude.min(),solar_altitude.max(),  len(z))\n",
    "    \n",
    "plt.scatter(*zip(*z[:, :2]), marker='o', s=30, color='red')\n",
    "plt.title('Grid of initial inducing points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "095fda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern = kerns.get_SpatioTemporal_combined(variance=VAR_F,\n",
    "#                                            lengthscale_time=LEN_TIME,\n",
    "#                                            lengthscale_space=[LEN_SPACE, LEN_SPACE],\n",
    "#                                            z=z,\n",
    "#                                            sparse=SPARSE,\n",
    "#                                            opt_z=OPT_Z,\n",
    "#                                            matern_order = '32',\n",
    "#                                            conditional='Full')\n",
    "\n",
    "kern = kerns.get_periodic_kernel(variance_period = VAR_PERIOD, \n",
    "                                 variance_matern = VAR_MATERN, \n",
    "                                 lengthscale_time_period = LEN_PERIOD, \n",
    "                                 lengthscale_time_matern = LEN_MATERN,\n",
    "                                   lengthscale_space=[LEN_SPACE, LEN_SPACE], #[LEN_SPACE, LEN_SPACE, LEN_ALTITUDE]\n",
    "                                   z=z,\n",
    "                                   sparse=SPARSE,\n",
    "                                   opt_z=OPT_Z,\n",
    "                                   conditional='Full',\n",
    "                                   matern_order = '32',\n",
    "                                   order= 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6439c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:5373: UserWarning: 'kind' argument to argsort is ignored; only 'stable' sorts are supported.\n",
      "  warnings.warn(\"'kind' argument to argsort is ignored; only 'stable' sorts \"\n"
     ]
    }
   ],
   "source": [
    "if MEAN_FIELD:\n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 30, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalMeanFieldGP(kernel=kern, likelihood=lik, X=t_train, R=R_train_scaled, Y=Y_train)    \n",
    "else:    \n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 30, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalGP(kernel = kern, likelihood = lik, X=t_train, Y=Y_train, R=R_train_scaled)\n",
    "    \n",
    "opt_hypers = objax.optimizer.Adam(model.vars())\n",
    "energy = objax.GradValues(model.energy, model.vars())\n",
    "\n",
    "@objax.Function.with_vars(model.vars())\n",
    "def train_op(batch_ind = None):\n",
    "    model.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "    dE, E = energy()  # compute energy and its gradients w.r.t. hypers\n",
    "    opt_hypers(LR_ADAM, dE)\n",
    "    return E\n",
    "train_op = objax.Jit(train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecba0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e1d242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1, energy: nan\n",
      "iter  2, energy: nan\n",
      "iter  3, energy: nan\n",
      "optimisation time: 55.14 secs\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        if number_of_minibatches > 1:\n",
    "            print(f'Doing minibatch {mini_batch}')\n",
    "        loss = train_op(mini_batches_indices[mini_batch])\n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[0]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47b1182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # calculate posterior predictive distribution via filtering and smoothing at train & test locations:\n",
    "# t0 = time.time()\n",
    "# print('calculating the posterior predictive distribution ...')\n",
    "# posterior_mean, posterior_var = model.predict_y(X=t, R=Rplot)\n",
    "# t1 = time.time()\n",
    "# print('prediction time: %2.2f secs' % (t1-t0))\n",
    "\n",
    "# t2 = time.time()\n",
    "# print('calculating the negative log predictive density ...')\n",
    "# nlpd = model.negative_log_predictive_density(X=t_test, R=R_test_scaled, Y=Y_test)\n",
    "# t3 = time.time()\n",
    "# print('nlpd calculation time: %2.2f secs' % (t3-t2))\n",
    "# print('nlpd: %2.3f' % nlpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f458980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z_opt = model.kernel.z.value\n",
    "# # mu = Y_scaler.inverse_transform(posterior_mean.flatten()[:, np.newaxis]).reshape(-1, GRID_PIXELS, GRID_PIXELS)\n",
    "# mu = posterior_mean.reshape(TIMESTEPS_NUM, GRID_PIXELS, GRID_PIXELS)\n",
    "\n",
    "# #get lat-lon coordinates\n",
    "# grid_coord = R_scaler.inverse_transform(np.array(np.c_[r1,r2]))\n",
    "# longitude_grid, latitude_grid =  convert_lonlat(grid_coord[:, 0], grid_coord[:, 1])\n",
    "# longitude_sys_train, latitude_sys_train = convert_lonlat(R_train[:,:,0][0], R_train[:,:,1][0])\n",
    "# longitude_z, latitude_z = convert_lonlat(R_scaler.inverse_transform(z_opt)[:,0], R_scaler.inverse_transform(z_opt)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea771b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_result = False\n",
    "# # del model, kern, Rplot  # , var\n",
    "\n",
    "# print('plotting ...')\n",
    "# cmap = cm.viridis\n",
    "# vmin = np.nanpercentile(Y, 1)\n",
    "# vmax = np.nanpercentile(Y, 99)\n",
    "# #get the labels for the dates\n",
    "# dates = pd.to_datetime(data_multiple.datetime).dt.date\n",
    "# days_index = max(97, int(((len(t) / 5) // 97) * 97)) #number of time intervals to match 5 beginnings of days\n",
    "\n",
    "# for time_step in range(t.shape[0])[:50]:\n",
    "#     f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [20, 1]})\n",
    "#     f.set_figheight(8)\n",
    "#     # f.set_figwidth(8)\n",
    "#     im = a0.imshow(mu[time_step], cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "#                    extent=[longitude_grid[0], longitude_grid[-1], latitude_grid[0], latitude_grid[-1]], origin='lower')\n",
    "#     if SPARSE:\n",
    "#         a0.scatter(longitude_z, latitude_z, c='r', s=60, alpha=0.5)  # plot inducing inputs\n",
    "#     a0.scatter(longitude_sys_train, latitude_sys_train, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "#                c=np.squeeze(Y[time_step]), s=50, edgecolors='black')\n",
    "#     plt.colorbar(im, fraction=0.0348, pad=0.03, aspect=30, ax=a0)\n",
    "    \n",
    "#     a0.set_xlim(longitude_grid[0], longitude_grid[-1])\n",
    "#     a0.set_ylim(latitude_grid[0], latitude_grid[-1])\n",
    "#     a0.set_title(f'PVE at {data_multiple.datetime.unique()[time_step]}')\n",
    "#     a0.set_ylabel('Latitude')\n",
    "#     a0.set_xlabel('Longitude')\n",
    "#     a1.vlines(t[time_step].item(), -1, 1, 'r')\n",
    "#     a1.set_xlabel('time (days)')\n",
    "#     a1.set_xlim(t[0], t[-1])\n",
    "    \n",
    "#     a1.set_xticks(np.asarray(t[1:-1:days_index ][:,0].tolist()), \n",
    "#                   labels = dates[0:-1:days_index].values,\n",
    "#                      fontsize = 10)\n",
    "#     plt.show()\n",
    "#     plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE SYSTEM SPECIFIC PREDICTIONS (NOT THE TOTAL INTERPOLATION)\n",
    "len_samples = len(t_test) + 1500\n",
    "test_mask_shortened = test_mask[-len_samples:]\n",
    "\n",
    "f_mean, f_var = model.predict(X=t[-len_samples:], R=R_scaled[-len_samples:])\n",
    "\n",
    "#GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean = f_mean.reshape(f_mean.shape[0], -1, 1)\n",
    "f_var = f_var.reshape(f_var.shape[0], -1, 1)\n",
    "\n",
    "mean_y, var_y = vmap(model.likelihood.predict, (0, 0, None))(f_mean, f_var, None)\n",
    "posterior_mean_ts, posterior_var_ts = np.squeeze(mean_y), np.squeeze(var_y)\n",
    "\n",
    "#adjust this for the correct quantities\n",
    "mae = np.nanmean(abs(np.squeeze(Y[-len_samples:]) - np.squeeze(posterior_mean_ts)))\n",
    "print(f'The MAE is {mae.round(3)}')\n",
    "\n",
    "mae_train = np.nanmean(abs(np.squeeze(Y[-len_samples:][~test_mask_shortened]) - np.squeeze(posterior_mean_ts[~test_mask_shortened])))\n",
    "print(f'The train MAE is {mae_train.round(3)}')\n",
    "\n",
    "mae_test = np.nanmean(abs(np.squeeze(Y[-len_samples:][test_mask_shortened]) - np.squeeze(posterior_mean_ts[test_mask_shortened])))\n",
    "print(f'The test MAE is {mae_test.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f8002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sample values of f at each point\n",
    "sampled_f = np.random.normal(f_mean[:,:,0], f_var[:,:,0], size=(500, f_var.shape[0], f_var.shape[1]))\n",
    "\n",
    "alpha_sampled = model.likelihood.link_fn(sampled_f) * model.likelihood.scale\n",
    "beta_sampled = model.likelihood.scale - alpha_sampled\n",
    "\n",
    "beta_samples = np.random.beta(alpha_sampled, beta_sampled, size=(alpha_sampled.shape[0], alpha_sampled.shape[1], alpha_sampled.shape[2]))\n",
    "lower_bounds_beta_MC = np.quantile(beta_samples, 0.025, axis=0)\n",
    "upper_bounds_beta_MC = np.quantile(beta_samples, 0.975, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4e41e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_index = max(97, int(((len_samples / 3) // 97) * 97)) #number of time intervals to match 5 beginnings of days\n",
    "\n",
    "for i in range(SYSTEMS_NUM):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "    plt.plot(np.arange(len(Y))[-len_samples:], Y[:,i][-len_samples:], \"xk\")\n",
    "    plt.plot(np.arange(len(Y))[-len_samples:], posterior_mean_ts[:,i][-len_samples:], c=\"C0\", lw=2, zorder=2)\n",
    "    plt.vlines(t_train[-1], 0, 1, colors='k')\n",
    "\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y))[-len_samples:],\n",
    "        lower_bounds_beta_MC[:,i],\n",
    "        upper_bounds_beta_MC[:,i],\n",
    "        color=\"C1\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "    plt.xticks(ticks = np.arange(len(Y))[-len_samples:-1:days_index], labels = data_multiple.datetime[-len_samples:-1:days_index].values, size=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee207de",
   "metadata": {},
   "source": [
    "## Predict on Unseen Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c138f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen = data.iloc[:, SYSTEMS_NUM:SYSTEMS_NUM+TEST_STATIONS][:TIMESTEPS_NUM].reset_index()\n",
    "capacities_unseen = uk_pv[uk_pv.ss_id_string.isin(data_unseen.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "stacked_unseen = mutils.stack_dataframe(data_unseen, lats, longs)\n",
    "\n",
    "X_unseen = np.array(stacked_unseen[['epoch', 'longitude', 'latitude']])\n",
    "Y_unseen = np.array(stacked_unseen[['PV']])\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords_unseen = convert_bng(X_unseen[:, 1], X_unseen[:, 2])\n",
    "X_unseen = np.vstack([X_unseen[:, 0],\n",
    "              np.array(british_national_grid_coords_unseen[0]),\n",
    "              np.array(british_national_grid_coords_unseen[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R_unseen, Y_unseen = bayesnewton.utils.create_spatiotemporal_grid(X_unseen, Y_unseen)\n",
    "R_unseen_scaled = np.tile(R_scaler.transform(R_unseen[0]), (R_unseen.shape[0],1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cbf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_UNSEEN = 1000 \n",
    "\n",
    "posterior_mean_unseen, posterior_var_unseen = model.predict_y(X=t, R=R_unseen_scaled)\n",
    "f_mean_unseen, f_var_unseen = model.predict(X=t, R=R_unseen_scaled)\n",
    "sampled_f_unseen = np.random.normal(f_mean_unseen, f_var_unseen, size=(N_SAMPLES_UNSEEN, f_var_unseen.shape[0], f_var_unseen.shape[1]))\n",
    "\n",
    "samples_y_unseen = np.zeros_like(sampled_f_unseen)\n",
    "for sample in range(samples_y_unseen.shape[0]):\n",
    "    #FROM THE POSTERIOR SAMPLES, AND THE ACTUAL ESTIMATED VARIANCE, GET SAMPLES OF Y\n",
    "    sample_y_unseen = model.likelihood.predict(sampled_f_unseen[sample], posterior_var_unseen)[0].reshape(TIMESTEPS_NUM, -1)\n",
    "    samples_y_unseen[sample] = sample_y_unseen\n",
    "    \n",
    "#GET THE LOWER AND UPPER PERCENTILES WITH 95% CONFIDENCE\n",
    "lower_perc_unseen = np.percentile(samples_y_unseen, 2.5, axis=0)\n",
    "upper_perc_unseen = np.percentile(samples_y_unseen, 97.5, axis=0)\n",
    "\n",
    "# posterior_pos_twostd_rescaled_unseen = posterior_mean_unseen + 1.96 * np.sqrt(posterior_var_unseen)\n",
    "# posterior_neg_twostd_rescaled_unseen = posterior_mean_unseen - 1.96 * np.sqrt(posterior_var_unseen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_unseen = Y_unseen[:,:,0]\n",
    "rescaled_Y_unseen = (Y_unseen * capacities_unseen)\n",
    "rescaled_posterior_unseen = posterior_mean_unseen * capacities_unseen\n",
    "\n",
    "#adjust this for the correct quantities\n",
    "mae = np.nanmean(abs(np.squeeze(Y_unseen) - np.squeeze(posterior_mean_unseen)))\n",
    "print(f'The MAE is {mae.round(3)}')\n",
    "\n",
    "mae_train = np.nanmean(abs(np.squeeze(Y_unseen[~test_mask]) - np.squeeze(posterior_mean_unseen[~test_mask])))\n",
    "print(f'The train MAE is {mae_train.round(3)}')\n",
    "\n",
    "mae_test = np.nanmean(abs(np.squeeze(Y_unseen[test_mask]) - np.squeeze(posterior_mean_unseen[test_mask])))\n",
    "print(f'The test MAE is {mae_test.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcb37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(TEST_STATIONS):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "    plt.plot(np.arange(len(Y)), Y_unseen[:,i], \"xk\")\n",
    "    plt.plot(np.arange(len(Y)), posterior_mean_unseen[:,i], c=\"C0\", lw=2, zorder=2)\n",
    "#     plt.plot(np.arange(len(Y)), sampled_f_unseen[:,:, i].T)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y)),\n",
    "        lower_perc_unseen[:,i],\n",
    "        upper_perc_unseen[:,i],\n",
    "        color=\"C2\",\n",
    "        alpha=0.2)\n",
    "    \n",
    "#     plt.fill_between(\n",
    "#         np.arange(len(Y)),\n",
    "#         posterior_neg_twostd_rescaled_unseen[:,i],\n",
    "#         posterior_pos_twostd_rescaled_unseen[:,i],\n",
    "#         color=\"C1\",\n",
    "#         alpha=0.2)\n",
    "    \n",
    "    plt.xticks(ticks = np.arange(len(Y))[0:-1:days_index], labels = data_unseen.datetime[0:-1:days_index].values, size=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf267b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.prior_sample(X = t.flatten(), num_samps=3)[..., 0].shape\n",
    "# model.predict(X=t, R=R_scaled)[0].shape\n",
    "# post_samp = model.posterior_sample(X=t, R=R_scaled, num_samps=100)\n",
    "\n",
    "# model.prior_sample(X = t.flatten(), num_loc = 7, num_samps=3)\n",
    "# model.posterior_sample(X=t.flatten(), R=Rplot, num_samps=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977564f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b27ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
