{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dbb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import bayesnewton\n",
    "import jax\n",
    "import objax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import math   \n",
    "from jax import vmap\n",
    "from scipy.stats import beta\n",
    "\n",
    "\n",
    "import cv2\n",
    "import sys, os\n",
    "sys.path.append('../Utils')\n",
    "import model_utils as mutils\n",
    "import kernels_definitions as kerns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c004eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA VARIABLES\n",
    "SYSTEMS_NUM = 600 #120\n",
    "TIMESTEPS_NUM = 35295  #THIS IS EXACTLY ONE YEAR\n",
    "TRAIN_FRAC = 2  #IF TRAIN_FRAC > 1 THEN IT BECOMES THE LENGTH OF THE TEST SET\n",
    "GRID_PIXELS = 15\n",
    "\n",
    "#OPTIMISATION VARIABLES\n",
    "LR_ADAM =  0.1095990416571735\n",
    "LR_NEWTON = 0.2944896882908768\n",
    "ITERS = 1000\n",
    "\n",
    "#GP Variables\n",
    "VAR_Y = 0.996641303535278\n",
    "LEN_SPACE = 1.1445954129246831\n",
    "\n",
    "#PERIODIC KERNEL\n",
    "VAR_PERIOD = 0.14694909160883585\n",
    "VAR_MATERN = 0.14694909160883585\n",
    "LEN_MATERN = 5\n",
    "\n",
    "#Want to use a sparse approximation\n",
    "SPARSE = True\n",
    "#Should we optimise the inducing points\n",
    "OPT_Z = True  # will be set to False if SPARSE=SPARSE\n",
    "\n",
    "#use a mean field approximation?\n",
    "MEAN_FIELD = False\n",
    "MINI_BATCH_SIZE = None #none if you don't want them\n",
    "TEST_STATIONS = 271 - 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_pv = pd.read_csv('../../Data/system_metadata_location_rounded.csv')\n",
    "uk_pv['ss_id_string'] = uk_pv['ss_id'].astype('str')\n",
    "#data_multiple.plot(legend=False)\n",
    "lats = dict(uk_pv.set_index('ss_id')['latitude_noisy'])\n",
    "longs = dict(uk_pv.set_index('ss_id')['longitude_noisy'])\n",
    "\n",
    "data =  pd.read_csv('../../Data/pv_power_df_5day_capacity_scaled.csv', index_col='datetime')\n",
    "#I AM SHUFFLING HERE\n",
    "data_multiple = data.iloc[:,:SYSTEMS_NUM][:TIMESTEPS_NUM].reset_index()\n",
    "stacked = mutils.stack_dataframe(data_multiple, lats, longs)\n",
    "stacked = stacked[(stacked.latitude < 52.5) & (stacked.latitude > 50.5) & (stacked.longitude > -1) & (stacked.longitude < 1)]\n",
    "\n",
    "capacities = uk_pv[uk_pv.ss_id_string.isin(data_multiple.columns)].set_index('ss_id_string')['kwp'].values * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc04a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(stacked[['epoch', 'longitude', 'latitude']])\n",
    "Y = np.array(stacked[['PV']])\n",
    "\n",
    "from suncalc import get_position, get_times\n",
    "date_solar = stacked.datetime.values\n",
    "lon_solar = stacked.longitude.values\n",
    "lat_solar = stacked.latitude.values\n",
    "\n",
    "solar_positions = get_position(date_solar, lon_solar, lat_solar)\n",
    "solar_altitude = solar_positions['altitude']\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords = convert_bng(X[:, 1], X[:, 2])\n",
    "X = np.vstack([X[:, 0],\n",
    "              np.array(british_national_grid_coords[0]),\n",
    "              np.array(british_national_grid_coords[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n",
    "\n",
    "# solar_altitudes = solar_altitude.reshape(R.shape[1], R.shape[0], 1).swapaxes(0,1)\n",
    "\n",
    "# R = np.append(R, solar_altitudes, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457fd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanNassimiha/miniforge3/envs/mscjax_dev/lib/python3.8/site-packages/geopandas/array.py:275: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  return GeometryArray(vectorized.points_from_xy(x, y, z), crs=crs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Grid of initial inducing points')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train test split for 3 dimensional data\n",
    "t_train, t_test, R_train, R_test, Y_train, Y_test = mutils.train_split_3d(t, R, Y, train_frac = TRAIN_FRAC, split_type = 'Cutoff')\n",
    "# Y = Y[:,:,0]\n",
    "\n",
    "#get the mask of the test points\n",
    "test_mask = np.in1d(t.squeeze(), t_test.squeeze())\n",
    "\n",
    "#Scale the data\n",
    "scaled_values = mutils.scale_2d_train_test_data(R, Y, R_train, R_test, Y_train, Y_test )\n",
    "R_scaler, R_scaled, R_train_scaled, R_test_scaled, _, _, _, _ = scaled_values\n",
    "\n",
    "#here get a list of scaled coordinates (frozen because at some point in time)\n",
    "R_scaled_frozen = R_scaled[0]\n",
    "\n",
    "# #Create a grid to perform prediction/interpolation on\n",
    "r1, r2, Rplot = mutils.create_grid_from_coords(R = R_scaled_frozen, t = t, R_scaler = R_scaler, N_pixels = GRID_PIXELS, date_solar = date_solar)\n",
    "\n",
    "# z = R_scaled[2, ...]\n",
    "z = R_scaled[2, ::3]\n",
    "\n",
    "\n",
    "# #CHANGE THE INDUCING POINTS FOR THE SOLAR ALTITUDE TO BE EQUALLY SPACED ALONG THE TOTAL INTERVAL\n",
    "# z[:,2] = np.linspace(solar_altitude.min(),solar_altitude.max(),  len(z))\n",
    "    \n",
    "plt.scatter(*zip(*z[:, ...]), marker='o', s=30, color='red')\n",
    "plt.title('Grid of initial inducing points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "kern = kerns.get_SpatioTemporal_combined(variance = VAR_PERIOD, \n",
    "                                 lengthscale_time = LEN_MATERN,\n",
    "                                   lengthscale_space=[LEN_SPACE, LEN_SPACE], #[LEN_SPACE, LEN_SPACE, LEN_ALTITUDE]\n",
    "                                   z=z,\n",
    "                                   sparse=SPARSE,\n",
    "                                   opt_z=OPT_Z,\n",
    "                                   conditional='Full',\n",
    "                                   matern_order = '12')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEAN_FIELD:\n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 3, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalMeanFieldGP(kernel=kern, likelihood=lik, X=t_train, R=R_train_scaled, Y=Y_train)    \n",
    "else:    \n",
    "    lik = bayesnewton.likelihoods.Beta(scale = 3, fix_scale=False, link='probit')\n",
    "    model = bayesnewton.models.MarkovVariationalGP(kernel = kern, likelihood = lik, X=t_train, Y=Y_train, R=R_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_hypers = objax.optimizer.Adam(model.vars())\n",
    "energy = objax.GradValues(model.energy, model.vars())\n",
    "\n",
    "@objax.Function.with_vars(model.vars() + opt_hypers.vars())\n",
    "def train_op(batch_ind = None):\n",
    "    model.inference(lr=LR_NEWTON, batch_ind = batch_ind)  #perform inference and update variational params\n",
    "    dE, E = energy()  # compute energy and its gradients w.r.t. hypers\n",
    "    opt_hypers(LR_ADAM, dE)\n",
    "    return E\n",
    "train_op = objax.Jit(train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MINI_BATCH_SIZE == None:\n",
    "    number_of_minibatches = 1\n",
    "    mini_batches_indices = [None] * number_of_minibatches\n",
    "else:\n",
    "    number_of_minibatches = int(len(t_train) / MINI_BATCH_SIZE)\n",
    "    idx_set = np.arange(len(t_train))\n",
    "    np.random.shuffle(idx_set)\n",
    "    mini_batches_indices = np.array_split(idx_set, number_of_minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1d242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "model_vars = dict.fromkeys(range(ITERS))\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(1, ITERS + 1):\n",
    "    for mini_batch in range(number_of_minibatches):\n",
    "        if number_of_minibatches > 1:\n",
    "            print(f'Doing minibatch {mini_batch}')\n",
    "        loss = train_op(mini_batches_indices[mini_batch])\n",
    "        \n",
    "#         #LOG THE PARAMS\n",
    "#         data_var = [model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).temporal_kernel(Matern12).transformed_lengthscale'].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).temporal_kernel(Matern12).transformed_variance'].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).spatial_kernel(Matern12).transformed_lengthscale'][0].item(),\n",
    "#                 model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).spatial_kernel(Matern12).transformed_lengthscale'][1].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).kernel(SpatioTemporalMatern12).spatial_kernel(Matern12).transformed_variance'].item(),\n",
    "#                  model.vars()['(MarkovVariationalGP).likelihood(Beta).transformed_scale'].item()]\n",
    "\n",
    "#         data_model_vars = copy.copy(data_var)\n",
    "#         model_vars[i] = data_model_vars\n",
    "        \n",
    "        \n",
    "    print('iter %2d, energy: %1.4f' % (i, loss[0]))\n",
    "t1 = time.time()\n",
    "print('optimisation time: %2.2f secs' % (t1-t0))\n",
    "avg_time_taken = (t1-t0)/ITERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b1182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate posterior predictive distribution via filtering and smoothing at train & test locations:\n",
    "t0 = time.time()\n",
    "print('calculating the posterior predictive distribution ...')\n",
    "posterior_mean, posterior_var = model.predict_y(X=t, R=Rplot)\n",
    "t1 = time.time()\n",
    "print('prediction time: %2.2f secs' % (t1-t0))\n",
    "\n",
    "t2 = time.time()\n",
    "print('calculating the negative log predictive density ...')\n",
    "nlpd = model.negative_log_predictive_density(X=t_test, R=R_test_scaled, Y=Y_test)\n",
    "t3 = time.time()\n",
    "print('nlpd calculation time: %2.2f secs' % (t3-t2))\n",
    "print('nlpd: %2.3f' % nlpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f458980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z_opt = model.kernel.z.value\n",
    "# # mu = Y_scaler.inverse_transform(posterior_mean.flatten()[:, np.newaxis]).reshape(-1, GRID_PIXELS, GRID_PIXELS)\n",
    "# mu = posterior_mean.reshape(TIMESTEPS_NUM, GRID_PIXELS, GRID_PIXELS)\n",
    "\n",
    "# #get lat-lon coordinates\n",
    "# grid_coord = R_scaler.inverse_transform(np.array(np.c_[r1,r2]))\n",
    "# longitude_grid, latitude_grid =  convert_lonlat(grid_coord[:, 0], grid_coord[:, 1])\n",
    "# longitude_sys_train, latitude_sys_train = convert_lonlat(R_train[:,:,0][0], R_train[:,:,1][0])\n",
    "# longitude_z, latitude_z = convert_lonlat(R_scaler.inverse_transform(z_opt)[:,0], R_scaler.inverse_transform(z_opt)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea771b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_result = False\n",
    "# # del model, kern, Rplot  # , var\n",
    "\n",
    "# print('plotting ...')\n",
    "# cmap = cm.viridis\n",
    "# vmin = np.nanpercentile(Y, 1)\n",
    "# vmax = np.nanpercentile(Y, 99)\n",
    "# #get the labels for the dates\n",
    "# dates = pd.to_datetime(data_multiple.datetime).dt.date\n",
    "# days_index = max(96, int(((len(t) / 5) // 96) * 96)) #number of time intervals to match 5 beginnings of days\n",
    "\n",
    "# for time_step in range(t.shape[0])[:50]:\n",
    "#     f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [20, 1]})\n",
    "#     f.set_figheight(8)\n",
    "#     # f.set_figwidth(8)\n",
    "#     im = a0.imshow(mu[time_step], cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "#                    extent=[longitude_grid[0], longitude_grid[-1], latitude_grid[0], latitude_grid[-1]], origin='lower')\n",
    "#     if SPARSE:\n",
    "#         a0.scatter(longitude_z, latitude_z, c='r', s=60, alpha=0.5)  # plot inducing inputs\n",
    "#     a0.scatter(longitude_sys_train, latitude_sys_train, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "#                c=np.squeeze(Y[time_step]), s=50, edgecolors='black')\n",
    "#     plt.colorbar(im, fraction=0.0348, pad=0.03, aspect=30, ax=a0)\n",
    "    \n",
    "#     a0.set_xlim(longitude_grid[0], longitude_grid[-1])\n",
    "#     a0.set_ylim(latitude_grid[0], latitude_grid[-1])\n",
    "#     a0.set_title(f'PVE at {data_multiple.datetime.unique()[time_step]}')\n",
    "#     a0.set_ylabel('Latitude')\n",
    "#     a0.set_xlabel('Longitude')\n",
    "#     a1.vlines(t[time_step].item(), -1, 1, 'r')\n",
    "#     a1.set_xlabel('time (days)')\n",
    "#     a1.set_xlim(t[0], t[-1])\n",
    "    \n",
    "#     a1.set_xticks(np.asarray(t[1:-1:days_index ][:,0].tolist()), \n",
    "#                   labels = dates[0:-1:days_index].values,\n",
    "#                      fontsize = 10)\n",
    "#     plt.show()\n",
    "#     plt.close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee207de",
   "metadata": {},
   "source": [
    "## Predict on Unseen Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c138f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen = data.iloc[:, SYSTEMS_NUM:SYSTEMS_NUM+TEST_STATIONS][:TIMESTEPS_NUM].reset_index()\n",
    "capacities_unseen = uk_pv[uk_pv.ss_id_string.isin(data_unseen.columns)].set_index('ss_id_string')['kwp'].values * 1000\n",
    "stacked_unseen = mutils.stack_dataframe(data_unseen, lats, longs)\n",
    "stacked_unseen = stacked_unseen[(stacked_unseen.latitude < 52.5) & (stacked_unseen.latitude > 50.5) & (stacked_unseen.longitude > -1) & (stacked_unseen.longitude < 1)]\n",
    "\n",
    "X_unseen = np.array(stacked_unseen[['epoch', 'longitude', 'latitude']])\n",
    "Y_unseen = np.array(stacked_unseen[['PV']])\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords_unseen = convert_bng(X_unseen[:, 1], X_unseen[:, 2])\n",
    "X_unseen = np.vstack([X_unseen[:, 0],\n",
    "              np.array(british_national_grid_coords_unseen[0]),\n",
    "              np.array(british_national_grid_coords_unseen[1])]).T\n",
    "\n",
    "#Create a space-time grid from X and Y\n",
    "t, R_unseen, Y_unseen = bayesnewton.utils.create_spatiotemporal_grid(X_unseen, Y_unseen)\n",
    "t = t \n",
    "R_unseen_scaled = np.tile(R_scaler.transform(R_unseen[0]), (R_unseen.shape[0],1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean_unseen, f_var_unseen = model.predict(X=t, R=R_unseen_scaled)\n",
    "\n",
    "#CREATE A LOOP SO IT DOESN'T RUN OUT OF MEMORY\n",
    "\n",
    "# f_mean_unseen = []\n",
    "# f_var_unseen = []\n",
    "\n",
    "# for i in range(len(R_unseen_scaled)):\n",
    "#     f_m_un, f_var_un = model.predict(X=t, R=R_unseen_scaled[i])\n",
    "#     f_mean_unseen.append(f_m_un)\n",
    "#     f_var_unseen.uppend(f_var_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_UNSEEN = 100\n",
    "\n",
    "#Sample values of f at each point\n",
    "sampled_f_unseen = np.random.normal(f_mean_unseen, f_var_unseen, size=(N_SAMPLES_UNSEEN, f_var_unseen.shape[0], f_var_unseen.shape[1]))\n",
    "\n",
    "alpha_sampled_unseen = model.likelihood.link_fn(sampled_f_unseen) * model.likelihood.scale\n",
    "beta_sampled_unseen = model.likelihood.scale - alpha_sampled_unseen\n",
    "\n",
    "beta_samples_unseen = np.random.beta(alpha_sampled_unseen, beta_sampled_unseen, size=(alpha_sampled_unseen.shape[0], alpha_sampled_unseen.shape[1], alpha_sampled_unseen.shape[2]))\n",
    "lower_bounds_beta_MC_unseen = np.quantile(beta_samples_unseen, 0.025, axis=0)\n",
    "upper_bounds_beta_MC_unseen = np.quantile(beta_samples_unseen, 0.975, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "f_mean_unseen = f_mean_unseen.reshape(f_mean_unseen.shape[0], -1, 1)\n",
    "f_var_unseen = f_var_unseen.reshape(f_var_unseen.shape[0], -1, 1)\n",
    "\n",
    "mean_y_unseen, var_y_unseen = vmap(model.likelihood.predict, (0, 0, None))(f_mean_unseen, f_var_unseen, None)\n",
    "posterior_mean_unseen, posterior_var_unseen = np.squeeze(mean_y_unseen), np.squeeze(var_y_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636c601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_unseen = Y_unseen[:,:,0]\n",
    "\n",
    "#adjust this for the correct quantities\n",
    "mae = np.nanmean(abs(np.squeeze(Y_unseen) - np.squeeze(posterior_mean_unseen)))\n",
    "print(f'The MAE is {mae.round(3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcb37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(posterior_mean_unseen.shape[1]):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f'Prediction for system {i}')\n",
    "\n",
    "    plt.plot(np.arange(len(Y[:1000])), Y_unseen[:1000,i], \"xk\")\n",
    "    plt.plot(np.arange(len(Y[:1000])), posterior_mean_unseen[:1000,i], c=\"C0\", lw=2, zorder=2)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(Y[:1000])),\n",
    "        lower_bounds_beta_MC_unseen[:1000,i],\n",
    "        upper_bounds_beta_MC_unseen[:1000,i],\n",
    "        color=\"C2\",\n",
    "        alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cd928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95230c25",
   "metadata": {},
   "source": [
    "## How much would it have produced?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_daily_prod(productions):\n",
    "    '''\n",
    "    Given an array of production data for each system, calculates the average daily production for each system in kWh\n",
    "    '''\n",
    "    n_days = productions.shape[0] / 96\n",
    "    avg_daily_prod = productions.sum(axis=0) / (n_days * 12)\n",
    "    return avg_daily_prod\n",
    "    \n",
    "avg_daily_prod_predicted = calc_avg_daily_prod(posterior_mean_unseen)\n",
    "avg_daily_prod_actual = calc_avg_daily_prod(Y_unseen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da87c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(avg_daily_prod_actual).hist()\n",
    "pd.Series(avg_daily_prod_predicted).hist()\n",
    "plt.show()\n",
    "pd.Series(avg_daily_prod_actual - avg_daily_prod_predicted).hist()\n",
    "MAE_yearly_avg = np.mean(abs(avg_daily_prod_actual - avg_daily_prod_predicted))\n",
    "print(f'The MAE on the average daily kWh over {round(posterior_mean_unseen.shape[0] / 96)} days is {round(MAE_yearly_avg, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250bea9",
   "metadata": {},
   "source": [
    "# Given coordinates and Capacity, how much will it produce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_production(lat, lon, capacity, historical_error, confidence_interval = 0.8):\n",
    "    \n",
    "    R_array_2d = np.array([[lat,lon]]) #[:, np.newaxis]\n",
    "    R_array_2d_scaled = R_scaler.transform(R_array_2d)\n",
    "    R_array_3d_scaled = np.repeat(R_array_2d_scaled, t.shape[0], axis=0)[:, np.newaxis]\n",
    "\n",
    "    #duplicating to avoid issues\n",
    "    mean_pred, var_pred = model.predict(X=t, R=np.repeat(R_array_3d_scaled, 2, axis = 1))\n",
    "    mean_pred, var_pred = mean_pred[:,0], var_pred[:,0]\n",
    "    N_SAMPLES_UNSEEN = 100\n",
    "\n",
    "    #Sample values of f at each point\n",
    "    sampled_f_pred = np.random.normal(mean_pred, var_pred, size=(N_SAMPLES_UNSEEN, var_pred.shape[0]))\n",
    "\n",
    "    alpha_sampled_pred = model.likelihood.link_fn(sampled_f_pred) * model.likelihood.scale\n",
    "    beta_sampled_pred = model.likelihood.scale - alpha_sampled_pred\n",
    "\n",
    "    beta_samples_pred = np.random.beta(alpha_sampled_pred, beta_sampled_pred, size=(alpha_sampled_pred.shape[0], alpha_sampled_pred.shape[1]))\n",
    "    lower_bounds_beta_MC_pred = np.quantile(beta_samples_pred,  (1 - confidence_interval)/2, axis=0)\n",
    "    upper_bounds_beta_MC_pred = np.quantile(beta_samples_pred, 1 -(1 - confidence_interval)/2, axis=0)\n",
    "    \n",
    "    #GET THE Y PREDICTIONS FROM THE F VALUES\n",
    "    f_mean_pred = mean_pred.reshape(mean_pred.shape[0], -1, 1)\n",
    "    f_var_pred = var_pred.reshape(var_pred.shape[0], -1, 1)\n",
    "\n",
    "    mean_y_pred, var_y_pred = vmap(model.likelihood.predict, (0, 0, None))(f_mean_pred, f_var_pred, None)\n",
    "    posterior_mean_pred, posterior_var_pred = np.squeeze(mean_y_pred), np.squeeze(var_y_pred)\n",
    "    \n",
    "    avg_daily_prod_pred = calc_avg_daily_prod(posterior_mean_pred).item()\n",
    "    avg_daily_prod_pred_kWh = avg_daily_prod_pred * capacity\n",
    "    \n",
    "    avg_daily_prod_pred_lower = calc_avg_daily_prod(lower_bounds_beta_MC_pred).item()\n",
    "    avg_daily_prod_pred_kWh_lower = avg_daily_prod_pred_lower * capacity\n",
    "    \n",
    "    avg_daily_prod_pred_upper = calc_avg_daily_prod(upper_bounds_beta_MC_pred).item()\n",
    "    avg_daily_prod_pred_kWh_upper = avg_daily_prod_pred_upper * capacity\n",
    "    \n",
    "    #GET THE UNCERTAINTIES, GIVEN BOTH BY THE UNCETAINTY BARS BUT ALSO BY THE ERRORS IN THE TEST SET\n",
    "    \n",
    "    print(lower_bounds_beta_MC_pred.shape)\n",
    "    \n",
    "    error = historical_error * capacity\n",
    "    \n",
    "    return avg_daily_prod_pred_kWh, error, avg_daily_prod_pred_kWh_lower, avg_daily_prod_pred_kWh_upper\n",
    "\n",
    "cap = 0.2\n",
    "lat = 0\n",
    "lon = 52\n",
    "historical_error = MAE_yearly_avg.item()\n",
    "conf = 0.8\n",
    "avg_daily_prod, error, avg_daily_prod_pred_kWh_lower, avg_daily_prod_pred_kWh_upper = estimate_production(lat, lon, cap, historical_error, confidence_interval = conf)\n",
    "print(f'PAST ERROR: The Estimated Average daily production in kWh is {round(avg_daily_prod, 2)} Â± {round(error, 2)} for a system of capacity {cap} kW')\n",
    "print(f'GP ERROR: The Estimated Average daily production in kWh is {round(avg_daily_prod, 2)} with {conf * 100}% confidence interval given by [{round(avg_daily_prod_pred_kWh_lower, 2)}, {round(avg_daily_prod_pred_kWh_upper, 2)}] for a system of capacity {cap} kW')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01bde6",
   "metadata": {},
   "source": [
    "# How much did parameters change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c73da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trajectories_transformed = pd.DataFrame(model_vars).T.dropna()\n",
    "param_trajectories_transformed.to_csv('param_trajectories_transformed_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trajectories_transformed = pd.read_csv('param_trajectories_transformed_3.csv').iloc[:, 1:]\n",
    "param_trajectories = np.log(1 + np.exp(param_trajectories_transformed))\n",
    "param_trajectories.columns = ['Temporal Lengthscale', 'Kernel Variance', 'Spatial Lengthscale 1', 'Spatial Lengthscale 2', 'Spatial Variance', 'Beta Scale']\n",
    "param_trajectories = param_trajectories.drop(columns = ['Spatial Variance',  'Spatial Lengthscale 2'])\n",
    "\n",
    "\n",
    "ax = param_trajectories.plot(subplots=True, sharex=True, sharey=False, figsize=(7.5, 14 /1.25 ),  legend = False, fontsize = 15)\n",
    "plt.suptitle('7 Optimised Points \\n', fontsize=20)\n",
    "ax[0].set_title('Temporal Lengthscale', fontsize = 15)\n",
    "ax[1].set_title('Kernel Variance', fontsize = 15)\n",
    "ax[2].set_title('Spatial Lengthscale 1', fontsize = 15)\n",
    "ax[3].set_title('Beta Scale', fontsize = 15)\n",
    "\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "ax[3].grid()\n",
    "\n",
    "ax[0].set_xlabel('Iteration', fontsize = 15)\n",
    "ax[1].set_xlabel('Iteration', fontsize = 15)\n",
    "ax[2].set_xlabel('Iteration', fontsize = 15)\n",
    "ax[3].set_xlabel('Iteration', fontsize = 15)\n",
    "\n",
    "ax[0].set_ylabel('Parameter Value', fontsize = 15)\n",
    "ax[1].set_ylabel('Parameter Value', fontsize = 15)\n",
    "ax[2].set_ylabel('Parameter Value', fontsize = 15)\n",
    "ax[3].set_ylabel('Parameter Value', fontsize = 15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/param_trajectories_3.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4353a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
